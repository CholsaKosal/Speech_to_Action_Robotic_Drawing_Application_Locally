.
├── README.md
├── backend
│   ├── README.md
│   ├── api_server.py
│   ├── config.py
│   ├── image_processing_engine.py
│   ├── main.py
│   ├── main_orchestrator.py
│   ├── rapid_code_for_controlling_the_robot_movement.txt
│   ├── requirements.txt
│   ├── robot_interface.py
│   └── voice_assistant.py
└── frontend
    ├── README.md
    └── s2a-drawing-ui
        ├── README.md
        ├── dist-electron
        │   ├── main.js
        │   └── preload.mjs
        ├── electron
        │   ├── electron-env.d.ts
        │   ├── main.ts
        │   └── preload.ts
        ├── electron-builder.json5
        ├── index.html
        ├── package.json
        ├── src
        │   ├── App.css
        │   ├── App.tsx
        │   ├── index.css
        │   ├── main.tsx
        │   └── vite-env.d.ts
        ├── tsconfig.json
        ├── tsconfig.node.json
        └── vite.config.ts

7 directories, 29 files


=======================================
          FILE CONTENTS START HERE         
=======================================

--- START OF FILE: .gitignore ---
# Python
################################################################################
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib6022/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Python Virtual Environment
backend/venv/

# Jupyter Notebook
.ipynb_checkpoints

# pyenv
.python-version

# Mypy cache
.mypy_cache/
.dmypy.json
dmypy.json

# PyInstaller
# Usually these files are written by a CI, but they pollute the project root if not
*.manifest
*.spec

# User-specific uploads and models (uncomment if you decide not to track them)
backend/qr_uploads/
backend/models/
backend/audio_tmp/
backend/drawing_history.json

# Log files
*.log
logs/

# Frontend (Electron/Vite project located at frontend/s2a-drawing-ui/)
################################################################################
frontend/s2a-drawing-ui/node_modules/
frontend/s2a-drawing-ui/dist/
frontend/s2a-drawing-ui/dist-electron/ # Electron-vite specific build output for main/preload
frontend/s2a-drawing-ui/out/           # Often used by electron-builder
frontend/s2a-drawing-ui/release/       # Often used by electron-builder for packaged app
frontend/s2a-drawing-ui/.vite/
frontend/s2a-drawing-ui/.electron/
frontend/s2a-drawing-ui/coverage/
frontend/s2a-drawing-ui/npm-debug.log*
frontend/s2a-drawing-ui/yarn-debug.log*
frontend/s2a-drawing-ui/yarn-error.log*
frontend/s2a-drawing-ui/pnpm-debug.log*
frontend/s2a-drawing-ui/lerna-debug.log*
frontend/s2a-drawing-ui/*.local


# If you decide to use Tauri in the future for the frontend
# frontend/s2a-drawing-ui/src-tauri/target/
# frontend/s2a-drawing-ui/src-tauri/Cargo.lock

# IDE / Editor specific
################################################################################
.vscode/
!.vscode/settings.json
!.vscode/tasks.json
!.vscode/launch.json
!.vscode/extensions.json
.idea/
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

# OS specific
################################################################################
.DS_Store
Thumbs.db
Desktop.ini

# Temporary script files (if any, from your generate_code_base.sh)
# temp_all_contents.txt
# filter_rules.sed
# code_base.txt # Usually you don't commit the output of this script

# Firebase (if you were to use it later)
# .firebase/
# firebase-debug.log
# firebase.json # Only if it doesn't contain sensitive project IDs you want public
# .firebaserc   # Only if it doesn't contain sensitive project IDs you want public
--- END OF FILE: .gitignore ---
--- START OF FILE: backend/api_server.py ---
# backend/api_server.py
from flask import Flask, request, render_template_string, jsonify, send_file
from flask_socketio import SocketIO, emit
# The RobotInterface class definition will be included/updated here
# as it's not a separate immersive in this context.
import config 
from image_processing_engine import process_image_to_robot_commands_pipeline, get_canny_edges_array 
from voice_assistant import transcribe_audio, load_whisper_model, load_llm_model, process_command_with_llm_stream 

import os
import uuid
import qrcode
from io import BytesIO
import base64 
import socket
import time 
import logging 
import cv2 
import numpy as np 
import json 
from datetime import datetime

# Configure basic logging
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(name)s - %(module)s - %(funcName)s - %(lineno)d - %(message)s'
)
logging.getLogger('engineio.server').setLevel(logging.WARNING) 
logging.getLogger('socketio.server').setLevel(logging.WARNING) 
logging.getLogger('werkzeug').setLevel(logging.WARNING) 

# --- RobotInterface Class Definition (Effectively an update to robot_interface.py) ---
class RobotInterface:
    def __init__(self):
        self.robot_socket = None
        self.is_connected = False
        # target_host and target_port will be set dynamically in connect_robot
        self.current_target_host = None
        self.current_target_port = None

    def _format_command(self, x, z, y):
        return f"{x:.2f},{z:.2f},{y:.2f}"

    def connect_robot(self, use_real=False): # Added use_real parameter
        if self.is_connected:
            logging.info("Robot already connected.")
            return True, f"Already connected to {self.current_target_host}:{self.current_target_port}"

        if use_real:
            host = config.REAL_ROBOT_HOST
            port = config.REAL_ROBOT_PORT
            logging.info(f"Attempting to connect to REAL ROBOT at {host}:{port}...")
        else:
            host = config.SIMULATION_HOST
            port = config.SIMULATION_PORT
            logging.info(f"Attempting to connect to SIMULATION at {host}:{port}...")
        
        self.current_target_host = host # Store current target
        self.current_target_port = port

        try:
            self.robot_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.robot_socket.settimeout(5) # Connection timeout
            self.robot_socket.connect((host, port))
            self.robot_socket.settimeout(None) # Reset to blocking for operations
            self.is_connected = True
            logging.info(f"Successfully connected to {host}:{port}.")
            return True, f"Successfully connected to {('Real Robot' if use_real else 'Simulation')} at {host}:{port}"
        except socket.error as e:
            self.robot_socket = None
            self.is_connected = False
            self.current_target_host = None
            self.current_target_port = None
            logging.error(f"Error connecting to {host}:{port} - {e}")
            return False, f"Error connecting to {('Real Robot' if use_real else 'Simulation')}: {e}"

    def disconnect_robot(self, graceful=True):
        if not self.is_connected:
            logging.info("Robot is not connected.")
            return True, "Was not connected."

        if graceful:
            logging.info("Attempting graceful disconnect (going home first)...")
            if self.is_connected: 
                home_success, home_msg = self.go_home() 
                if not home_success:
                    logging.warning(f"Warning: Failed to go home before disconnecting: {home_msg}")
                else:
                    logging.info("Successfully moved to home position.")
                    logging.info("Waiting for 2 seconds before closing socket...") # Reduced wait time
                    time.sleep(2)
            else: 
                logging.warning("Cannot go home for graceful disconnect, robot is not connected.")

        if self.robot_socket:
            try:
                self.robot_socket.close()
            except socket.error as e:
                logging.error(f"Error closing socket: {e}")
            finally:
                self.robot_socket = None
                self.is_connected = False
                logging.info(f"Socket closed. Disconnected from {self.current_target_host}:{self.current_target_port}.")
                self.current_target_host = None
                self.current_target_port = None
        else: 
            self.is_connected = False 
            logging.info("No active socket to close. Marked as disconnected.")
            self.current_target_host = None
            self.current_target_port = None
            
        return True, "Disconnected from robot."

    def send_command_raw(self, command_str):
        if not self.is_connected or not self.robot_socket:
            return False, "Not connected"
        try:
            logging.info(f"Sending command to {self.current_target_host}: {command_str}")
            self.robot_socket.sendall(command_str.encode('utf-8'))
            
            # Set a timeout for receiving responses
            self.robot_socket.settimeout(10) # 10-second timeout for R
            response_r = self.robot_socket.recv(1024).decode('utf-8').strip()
            logging.info(f"Received R-phase: '{response_r}'")
            
            self.robot_socket.settimeout(20) # 20-second timeout for D/E
            response_d_or_e = self.robot_socket.recv(1024).decode('utf-8').strip()
            logging.info(f"Received D/E-phase: '{response_d_or_e}'")
            
            self.robot_socket.settimeout(None) # Reset to blocking

            if response_r.upper() != "R":
                return False, f"Robot did not acknowledge (R). Got: {response_r}"
            if response_d_or_e.upper() == "D":
                return True, f"Command '{command_str}' successful."
            elif response_d_or_e.upper() == "E":
                return False, f"Command '{command_str}' failed: Robot reported error (E)."
            else:
                return False, f"Robot did not signal done (D) or error (E). Got: {response_d_or_e}"
                
        except socket.timeout:
            logging.error(f"Socket timeout during send/recv for command: {command_str}")
            self.disconnect_robot(graceful=False) # Force disconnect on timeout
            return False, "Socket timeout"
        except socket.error as e:
            logging.error(f"Socket error during send/recv: {e}")
            self.disconnect_robot(graceful=False) # Force disconnect
            return False, f"Socket error: {e}"
        except Exception as e:
            logging.error(f"An unexpected error occurred: {e}")
            self.disconnect_robot(graceful=False) # Force disconnect
            return False, f"Unexpected error: {e}"

    def go_home(self):
        if not self.is_connected:
            # Attempt to connect using default (simulation) if not connected,
            # or let the calling function handle pre-connection.
            # For now, assume connect_robot was called with user's choice.
            logging.warning("go_home called but robot not connected. Frontend should ensure connection first.")
            return False, "Cannot go home. Robot not connected."
        
        logging.info("Sending robot to home position...")
        x, z, y = config.ROBOT_HOME_POSITION_PY
        cmd_str = self._format_command(x, z, y)
        return self.send_command_raw(cmd_str)

    def move_to_position_py(self, x_py, z_py, y_py):
        if not self.is_connected:
            logging.warning("move_to_position_py called but robot not connected.")
            return False, "Cannot move. Robot not connected."

        cmd_str = self._format_command(x_py, z_py, y_py)
        return self.send_command_raw(cmd_str)
# --- End RobotInterface Class ---


app = Flask(__name__)
app.config['SECRET_KEY'] = 'your_very_secret_key_here!' 
BASE_DIR = os.path.dirname(__file__)
app.config['UPLOAD_FOLDER'] = os.path.join(BASE_DIR, config.QR_UPLOAD_FOLDER)
app.config['AUDIO_TEMP_FOLDER_PATH'] = os.path.join(BASE_DIR, config.AUDIO_TEMP_FOLDER)
ASSETS_DIR = os.path.join(BASE_DIR, config.ASSETS_FOLDER_NAME) 

DRAWING_HISTORY_FILE = os.path.join(BASE_DIR, "drawing_history.json")
MAX_DRAWING_HISTORY = 5


for folder_path in [app.config['UPLOAD_FOLDER'], app.config['AUDIO_TEMP_FOLDER_PATH'], ASSETS_DIR]:
    if not os.path.exists(folder_path):
        os.makedirs(folder_path)
        logging.info(f"Created folder at: {folder_path}")

SIGNATURE_IMAGE_FULL_PATH = os.path.join(ASSETS_DIR, config.SIGNATURE_IMAGE_FILENAME)

logging.info("--- Initializing AI Models ---")
if load_whisper_model(): logging.info("Whisper model loaded successfully.")
else: logging.error("Whisper model FAILED to load.")
if load_llm_model(): logging.info("LLM model loaded successfully.")
else: logging.error("LLM model FAILED to load.")
logging.info("--- AI Model Initialization Complete ---")

socketio = SocketIO(app, cors_allowed_origins="*", async_mode='eventlet', max_http_buffer_size=10 * 1024 * 1024) 
robot = RobotInterface() # Instantiate the robot interface

current_upload_session_id = None
is_drawing_active_flag = False 
drawing_history = [] 
active_drawing_session_id = None 

# ... (get_ui_history_summary, save_drawing_history, load_drawing_history, etc. remain the same)
def get_ui_history_summary(history_list):
    """Converts raw history items to the summary structure expected by UI."""
    ui_summary = []
    for item in history_list:
        total_commands = item.get('total_commands', 0)
        current_index = item.get('current_command_index', 0)
        status = item.get('status', 'unknown')
        
        progress_val = 0
        if total_commands > 0:
            progress_val = (current_index / total_commands) * 100
        elif status == 'completed':
            progress_val = 100
            
        ui_summary.append({
            'drawing_id': item.get('drawing_id'),
            'original_filename': item.get('original_filename'),
            'status': status,
            'progress': progress_val,
            'last_updated': item.get('last_updated')
        })
    return ui_summary

def save_drawing_history():
    """Saves the drawing history to a file."""
    global drawing_history
    try:
        with open(DRAWING_HISTORY_FILE, 'w') as f:
            json.dump(drawing_history, f, indent=4)
        logging.info(f"Drawing history saved to {DRAWING_HISTORY_FILE}")
    except IOError as e:
        logging.error(f"Error saving drawing history: {e}")

def load_drawing_history():
    """Loads drawing history from file if it exists."""
    global drawing_history
    if os.path.exists(DRAWING_HISTORY_FILE):
        try:
            with open(DRAWING_HISTORY_FILE, 'r') as f:
                history_data = json.load(f)
                if isinstance(history_data, list):
                    valid_history = []
                    for state in history_data:
                        if isinstance(state, dict) and all(k in state for k in ['drawing_id', 'original_filename', 'status']):
                            valid_history.append(state)
                        else:
                            logging.warning(f"Invalid entry found in {DRAWING_HISTORY_FILE}, skipping: {state}")
                    drawing_history = valid_history[:MAX_DRAWING_HISTORY] 
                    logging.info(f"Drawing history loaded with {len(drawing_history)} entries from {DRAWING_HISTORY_FILE}.")
                else:
                    logging.warning(f"Invalid data format in {DRAWING_HISTORY_FILE}. Initializing empty history.")
                    drawing_history = []
                    if os.path.exists(DRAWING_HISTORY_FILE): os.remove(DRAWING_HISTORY_FILE) 
        except (IOError, json.JSONDecodeError) as e:
            logging.error(f"Error loading drawing history: {e}. Initializing empty history.")
            drawing_history = []
            if os.path.exists(DRAWING_HISTORY_FILE): os.remove(DRAWING_HISTORY_FILE) 
    else:
        logging.info("No previous drawing history file found. Initializing empty history.")
        drawing_history = []

def clear_drawing_history_file(save=True):
    """Deletes the drawing history file and optionally saves an empty history."""
    if os.path.exists(DRAWING_HISTORY_FILE):
        try:
            os.remove(DRAWING_HISTORY_FILE)
            logging.info(f"Drawing history file {DRAWING_HISTORY_FILE} deleted.")
        except OSError as e:
            logging.error(f"Error deleting drawing history file: {e}")
    if save: 
        global drawing_history
        drawing_history = [] 
        save_drawing_history() 

def add_or_update_drawing_in_history(drawing_data):
    global drawing_history, active_drawing_session_id
    if 'drawing_id' not in drawing_data:
        drawing_data['drawing_id'] = f"draw_{int(time.time())}_{uuid.uuid4().hex[:6]}"
    drawing_data['last_updated'] = datetime.now().isoformat()
    found_index = next((i for i, item in enumerate(drawing_history) if item.get('drawing_id') == drawing_data['drawing_id']), -1)
    
    if found_index != -1: 
        drawing_history[found_index] = drawing_data
    else: 
        drawing_history.insert(0, drawing_data) 
        drawing_history = drawing_history[:MAX_DRAWING_HISTORY]
    
    active_drawing_session_id = drawing_data['drawing_id'] 
    save_drawing_history()
    return drawing_data

def get_drawing_from_history(drawing_id):
    global drawing_history
    return next((item for item in drawing_history if item.get('drawing_id') == drawing_id), None)

def update_drawing_status_in_history(drawing_id, status, current_command_index=None):
    global drawing_history, active_drawing_session_id
    item = get_drawing_from_history(drawing_id)
    if item:
        item['status'] = status
        item['last_updated'] = datetime.now().isoformat()
        if current_command_index is not None:
            item['current_command_index'] = current_command_index
        if status in ["completed", "aborted_manual_override", "aborted_new_drawing", "aborted_new_action"]:
            if active_drawing_session_id == drawing_id:
                active_drawing_session_id = None 
        save_drawing_history()
        logging.info(f"Updated status of drawing '{drawing_id}' to '{status}'.")
        return True
    return False

load_drawing_history()

UPLOAD_PAGE_TEMPLATE = """
<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Upload Image</title><style>body{font-family:sans-serif;display:flex;flex-direction:column;align-items:center;justify-content:center;height:100vh;margin:0;background-color:#f0f0f0}.container{background-color:white;padding:20px;border-radius:8px;box-shadow:0 0 10px rgba(0,0,0,.1);text-align:center}input[type=file]{margin-bottom:15px;display:block;margin-left:auto;margin-right:auto}button{padding:10px 15px;background-color:#007bff;color:white;border:none;border-radius:4px;cursor:pointer;font-size:1em}button:hover{background-color:#0056b3}#message{margin-top:15px;font-weight:700}h2{margin-top:0}</style></head><body><div class=container><h2>Select Image to Upload</h2><form id=uploadForm method=post enctype=multipart/form-data><input type=file name=image id=imageFile accept=image/* required><button type=submit>Upload</button></form><div id=message></div></div><script>document.getElementById("uploadForm").addEventListener("submit",async function(e){e.preventDefault();const t=new FormData(this),s=document.getElementById("message"),a=this.querySelector('button[type="submit"]'),i=this.querySelector('input[type="file"]');s.textContent="Uploading...",a.disabled=!0,i.disabled=!0;try{const e=await fetch(window.location.href,{method:"POST",body:t}),n=await e.json();e.ok?(s.textContent="Success: "+n.message+". You can close this page.",s.style.color="green"):(s.textContent="Error: "+(n.error||"Upload failed. Please try again."),s.style.color="red",a.disabled=!1,i.disabled=!1)}catch(e){s.textContent="Network Error: "+e.message+". Please try again.",s.style.color="red",a.disabled=!1,i.disabled=!1}})</script></body></html>
"""

@app.route('/qr_upload_page/<session_id>', methods=['GET', 'POST'])
def handle_qr_upload_page(session_id):
    global current_upload_session_id, active_drawing_session_id
    if session_id != current_upload_session_id:
        return "Invalid or expired upload session.", 403
    if request.method == 'POST':
        if 'image' not in request.files: return jsonify({"error": "No image file part"}), 400
        file = request.files['image']
        if file.filename == '': return jsonify({"error": "No selected file"}), 400
        if file:
            original_filename = file.filename
            _, f_ext = os.path.splitext(original_filename)
            if f_ext.lower() not in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']:
                 return jsonify({"error": "Invalid file type."}), 400
            filename_on_server = str(uuid.uuid4()) + f_ext
            filepath_on_server = os.path.join(app.config['UPLOAD_FOLDER'], filename_on_server)
            try:
                file.save(filepath_on_server)
                if active_drawing_session_id:
                    update_drawing_status_in_history(active_drawing_session_id, "aborted_new_action")
                    active_drawing_session_id = None
                socketio.emit('qr_image_received', { 
                    'success': True, 'message': f"Image '{original_filename}' uploaded via QR.",
                    'original_filename': original_filename, 'filepath_on_server': filepath_on_server
                })
                socketio.emit('drawing_history_updated', get_ui_history_summary(drawing_history))
                current_upload_session_id = None 
                return jsonify({"message": f"Image '{original_filename}' uploaded successfully!"}), 200
            except Exception as e:
                logging.error(f"Error saving QR uploaded file: {e}", exc_info=True)
                socketio.emit('qr_image_received', {'success': False, 'message': f"Error saving '{original_filename}' on server.", 'original_filename': original_filename })
                return jsonify({"error": "Failed to save file on server."}), 500
    return render_template_string(UPLOAD_PAGE_TEMPLATE)

@socketio.on('connect')
def handle_connect():
    global drawing_history, is_drawing_active_flag, active_drawing_session_id
    logging.info(f"Client connected: {request.sid}")
    emit('response', {'data': 'Connected to Python backend!'})
    # Send current robot connection status (might be connected from a previous session if server didn't restart)
    emit('robot_connection_status', {
        'success': robot.is_connected, 
        'message': f"Connected to {robot.current_target_host}" if robot.is_connected else 'Not connected to robot'
    })
    emit('drawing_history_updated', get_ui_history_summary(drawing_history))

    current_active_drawing = get_drawing_from_history(active_drawing_session_id) if active_drawing_session_id else None
    if is_drawing_active_flag and current_active_drawing:
         emit('drawing_status_update', {
            'active': True, 
            'message': f"Drawing of '{current_active_drawing['original_filename']}' is in progress.",
            'resumable': True, 
            'drawing_id': current_active_drawing['drawing_id'],
            'original_filename': current_active_drawing['original_filename'],
            'progress': (current_active_drawing.get('current_command_index', 0) / current_active_drawing.get('total_commands', 1)) * 100 if current_active_drawing.get('total_commands', 0) > 0 else 0
        })
    else: 
        last_interrupt = next((item for item in drawing_history if item.get('status') and 'interrupted' in item.get('status')), None)
        if last_interrupt:
            emit('drawing_status_update', {
                'active': False, 
                'message': f"Interrupted drawing of '{last_interrupt['original_filename']}' is available.",
                'resumable': True,
                'drawing_id': last_interrupt['drawing_id'],
                'original_filename': last_interrupt['original_filename'],
                'progress': (last_interrupt.get('current_command_index', 0) / last_interrupt.get('total_commands', 1)) * 100 if last_interrupt.get('total_commands', 0) > 0 else 0
            })
        else:
            emit('drawing_status_update', {'active': False, 'message': 'Idle', 'resumable': False})

@socketio.on('disconnect')
def handle_disconnect(): logging.info(f"Client disconnected: {request.sid}")

@socketio.on('robot_connect_request')
def handle_robot_connect_request(data): # Data from client
    global is_drawing_active_flag
    if is_drawing_active_flag: 
        emit('robot_connection_status', {'success': robot.is_connected, 'message': 'Cannot connect/disconnect robot while drawing is active.'})
        return
    
    # Get the client's preference for real robot vs simulation
    use_real = data.get('use_real_robot', config.USE_REAL_ROBOT_DEFAULT) # Default from config if not provided
    logging.info(f"Robot connect request received. use_real_robot: {use_real}")
    
    success, message = robot.connect_robot(use_real=use_real)
    emit('robot_connection_status', {'success': success, 'message': message})

@socketio.on('robot_disconnect_request')
def handle_robot_disconnect_request(json_data):
    global is_drawing_active_flag
    if is_drawing_active_flag: 
        emit('robot_connection_status', {'success': robot.is_connected, 'message': 'Cannot connect/disconnect robot while drawing is active.'})
        return
    success, message = robot.disconnect_robot(graceful=True)
    emit('robot_connection_status', {'success': robot.is_connected, 'message': message if success else "Failed to disconnect"})

# ... (check_and_abort_active_drawing, handle_send_robot_command, etc. remain mostly the same)
# Minor adjustment in handle_send_robot_command for initial connection if needed.
def check_and_abort_active_drawing(command_description="Manual command"):
    global active_drawing_session_id, is_drawing_active_flag, drawing_history
    if active_drawing_session_id:
        logging.warning(f"{command_description} received, aborting active drawing '{active_drawing_session_id}'.")
        update_drawing_status_in_history(active_drawing_session_id, "aborted_manual_override")
        is_drawing_active_flag = False
        emit('drawing_status_update', {'active': False, 'message': f"Drawing aborted due to {command_description}.", 'resumable': False, 'drawing_id': active_drawing_session_id}) 
        emit('drawing_history_updated', get_ui_history_summary(drawing_history)) 
        return True 
    return False

@socketio.on('send_robot_command') 
def handle_send_robot_command(json_data, triggered_by_llm=False): 
    global is_drawing_active_flag
    if is_drawing_active_flag:
        if triggered_by_llm:
            logging.warning(f"LLM command received while drawing active. Aborting current drawing: {active_drawing_session_id}")
            check_and_abort_active_drawing(f"LLM command '{json_data.get('type', 'N/A')}'")
        else: 
            emit('command_response', {'success': False, 'message': 'Cannot send manual commands while drawing is active.', 'command_sent': json_data.get('type', 'N/A')})
            return False, "Drawing is active."
    elif not triggered_by_llm : 
        check_and_abort_active_drawing(f"Manual command '{json_data.get('type', 'N/A')}'")
    
    command_type = json_data.get('type', 'raw')
    command_str = json_data.get('command_str') 
    
    # If robot is not connected and command is not 'go_home', attempt connection
    # using the default from config, as specific choice is made via 'robot_connect_request'
    if not robot.is_connected and command_type not in ['go_home']: 
        logging.info("Robot not connected. Attempting to connect with default settings before sending command.")
        # For direct commands like this, it might be better to enforce connection first via UI
        # Or, if we want to auto-connect, decide which target (real/sim) to use.
        # For now, let's assume the user should connect first via the dedicated button.
        # If RobotInterface.connect_robot() is called without 'use_real', it uses its internal default.
        conn_success, conn_message = robot.connect_robot(use_real=config.USE_REAL_ROBOT_DEFAULT) # Use server default
        if not conn_success:
            if not triggered_by_llm: emit('command_response', {'success': False, 'message': f'Robot not connected & connection failed: {conn_message}', 'command_sent': command_type})
            return False, f'Robot not connected & connection failed: {conn_message}' 
        emit('robot_connection_status', {'success': True, 'message': conn_message}) # Update client
        
    success, message = False, "Invalid command type"
    actual_command_sent = command_type
    if command_type == 'go_home':
        success, message = robot.go_home()
        x_h, z_h, y_h = config.ROBOT_HOME_POSITION_PY
        actual_command_sent = robot._format_command(x_h, z_h, y_h) + " (Home)"
    elif command_type == 'move_to_safe_center':
        x_s, z_s, y_s = config.SAFE_ABOVE_CENTER_PY
        success, message = robot.move_to_position_py(x_s, z_s, y_s)
        actual_command_sent = robot._format_command(x_s, z_s, y_s) + " (Safe Center)"
    elif command_type == 'raw' and command_str:
        success, message = robot.send_command_raw(command_str)
        actual_command_sent = command_str
        
    if not triggered_by_llm: emit('command_response', {'success': success, 'message': message, 'command_sent': actual_command_sent})
    if not robot.is_connected: emit('robot_connection_status', {'success': False, 'message': 'Disconnected'}) # Update if disconnect happened
    return success, message 

# ... (handle_direct_image_upload, handle_audio_chunk, handle_submit_text_to_llm, etc. remain the same)
@socketio.on('direct_image_upload')
def handle_direct_image_upload(data):
    global active_drawing_session_id
    check_and_abort_active_drawing("New direct image upload") 
    original_filename = data.get('filename')
    base64_data = data.get('fileData')
    if not original_filename or not base64_data: 
        emit('direct_image_upload_response', {'success': False, 'message': 'Missing filename or file data.'})
        return
    try:
        image_data = base64.b64decode(base64_data)
        _, f_ext = os.path.splitext(original_filename)
        if f_ext.lower() not in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']: 
            emit('direct_image_upload_response', {'success': False, 'message': f"Invalid file type: {f_ext}", 'original_filename': original_filename})
            return
        filename_on_server = str(uuid.uuid4()) + f_ext
        filepath_on_server = os.path.join(app.config['UPLOAD_FOLDER'], filename_on_server)
        with open(filepath_on_server, 'wb') as f: f.write(image_data)
        emit('direct_image_upload_response', { 'success': True, 'message': f"Image '{original_filename}' uploaded.", 'original_filename': original_filename, 'filepath_on_server': filepath_on_server })
    except Exception as e: 
        logging.error(f"Error in direct_image_upload: {e}", exc_info=True)
        emit('direct_image_upload_response', {'success': False, 'message': f"Server error: {e}", 'original_filename': original_filename})

@socketio.on('audio_chunk') 
def handle_audio_chunk(data):
    logging.info(f"--- API: Event 'audio_chunk' RECEIVED with data keys: {list(data.keys())} ---")
    audio_data_b64 = data.get('audioData')
    mime_type = data.get('mimeType', 'audio/webm') 
    if not audio_data_b64: logging.error("API: No audio data (audioData key) in received chunk."); emit('transcription_result', {'error': 'No audio data received.'}); return
    logging.info(f"API: Received audio data. Mime type: {mime_type}. Data length (chars): {len(audio_data_b64)}")
    try:
        audio_bytes = base64.b64decode(audio_data_b64)
        file_extension = ".webm"; mime_type_lower = mime_type.lower()
        if 'wav' in mime_type_lower: file_extension = ".wav"
        elif 'mp3' in mime_type_lower: file_extension = ".mp3"
        temp_audio_filename = f"voice_cmd_{uuid.uuid4()}{file_extension}"
        temp_audio_filepath = os.path.join(app.config['AUDIO_TEMP_FOLDER_PATH'], temp_audio_filename)
        with open(temp_audio_filepath, 'wb') as f: f.write(audio_bytes)
        transcribed_text = transcribe_audio(temp_audio_filepath) 
        if transcribed_text is not None: emit('transcription_result', {'text': transcribed_text}) 
        else: emit('transcription_result', {'error': 'Transcription failed on server.'})
        try: os.remove(temp_audio_filepath)
        except Exception as e: logging.warning(f"API Warning: Error removing temporary audio file {temp_audio_filepath}: {e}")
    except Exception as e: logging.error(f"API Error: Error processing audio chunk: {e}", exc_info=True); emit('transcription_result', {'error': f'Server error processing audio.'})


@socketio.on('submit_text_to_llm')
def handle_submit_text_to_llm(data):
    global is_drawing_active_flag, active_drawing_session_id 
    logging.info(f"--- API: Event 'submit_text_to_llm' RECEIVED with data: {data} ---") 
    text_command = data.get('text_command')
    if not text_command: 
        logging.error("API: No text_command in 'submit_text_to_llm' event.")
        emit('llm_response_chunk', {'error': 'No text command received by server.', 'done': True})
        return
    logging.info(f"API: Processing text command for LLM: '{text_command}'")
    parsed_action_command_from_llm = None
    try:
        for llm_response_part in process_command_with_llm_stream(text_command): 
            emit('llm_response_chunk', llm_response_part) 
            if llm_response_part.get("done"):
                if llm_response_part.get("parsed_action"):
                    parsed_action_command_from_llm = llm_response_part["parsed_action"]
                break 
        if parsed_action_command_from_llm:
            action_type = parsed_action_command_from_llm.get("type")
            if action_type in ["move", "move_to_coords"]: 
                 if check_and_abort_active_drawing(f"LLM command '{action_type}'"):
                    logging.info(f"LLM command '{action_type}' aborted a previous drawing.")
            parameters = parsed_action_command_from_llm.get("parameters", {})
            if action_type == "move":
                target = parameters.get("target")
                if target == "home": handle_send_robot_command({'type': 'go_home'}, triggered_by_llm=True)
                elif target == "center": handle_send_robot_command({'type': 'move_to_safe_center'}, triggered_by_llm=True)
            elif action_type == "move_to_coords":
                x,y,z = parameters.get("x"), parameters.get("y"), parameters.get("z")
                if x is not None and y is not None and z is not None:
                    handle_send_robot_command({'type': 'raw', 'command_str': robot._format_command(x, y, z)}, triggered_by_llm=True)
    except Exception as e: 
        logging.error(f"API Error in handle_submit_text_to_llm: {e}", exc_info=True)
        emit('llm_response_chunk', {'error': f'Server error: {e}', 'done': True})


@socketio.on('send_custom_coordinates')
def handle_send_custom_coordinates_event(data):
    logging.info(f"--- API: Event 'send_custom_coordinates' RECEIVED with data: {data} ---")
    check_and_abort_active_drawing("Manual coordinate input")
    if not robot.is_connected: 
        emit('command_response', {'success': False, 'message': 'Robot not connected.'})
        return
    try:
        x_py, z_py, y_py = float(data.get('x_py')), float(data.get('z_py')), float(data.get('y_py'))
        success, message = robot.move_to_position_py(x_py, z_py, y_py)
        emit('command_response', {'success': success, 'message': message, 'command_sent': f'Custom Coords: X={x_py}, Depth={z_py}, Side={y_py}'})
        if not robot.is_connected: emit('robot_connection_status', {'success': False, 'message': 'Disconnected'})
    except Exception as e: 
        logging.error(f"API Error in handle_send_custom_coordinates_event: {e}", exc_info=True)
        emit('command_response', {'success': False, 'message': f'Server error: {e}'})

@socketio.on('request_threshold_preview')
def handle_request_threshold_preview(data):
    logging.info(f"--- API: Event 'request_threshold_preview' RECEIVED with data: {data} ---")
    filepath, t1, t2 = data.get('filepath'), data.get('t1'), data.get('t2')
    if not filepath or not os.path.exists(filepath) or t1 is None or t2 is None: 
        emit('threshold_preview_image_response', {'error': 'Invalid data for preview.'})
        return
    try:
        edges_array = get_canny_edges_array(filepath, int(t1), int(t2)) 
        if edges_array is not None:
            _, buffer = cv2.imencode('.png', edges_array)
            img_base64 = base64.b64encode(buffer).decode('utf-8')
            emit('threshold_preview_image_response', {'image_base64': img_base64})
        else: 
            emit('threshold_preview_image_response', {'error': 'Failed to generate preview.'})
    except Exception as e: 
        logging.error(f"API Error generating threshold preview: {e}", exc_info=True)
        emit('threshold_preview_image_response', {'error': f'Server error: {e}'})

# _execute_drawing_commands and subsequent functions remain the same as the previous version
# (process_image_for_drawing, resume_drawing_request, restart_drawing_request)
def _execute_drawing_commands(drawing_session_id_to_execute):
    global is_drawing_active_flag, active_drawing_session_id, drawing_history

    session_data = get_drawing_from_history(drawing_session_id_to_execute)
    if not session_data:
        logging.error(f"Drawing session {drawing_session_id_to_execute} not found in history for execution.")
        emit('drawing_status_update', {'active': False, 'message': "Error: Drawing session not found.", 'resumable': False, 'drawing_id': drawing_session_id_to_execute})
        is_drawing_active_flag = False
        if active_drawing_session_id == drawing_session_id_to_execute: active_drawing_session_id = None
        return

    is_drawing_active_flag = True
    active_drawing_session_id = drawing_session_id_to_execute 
    
    original_filename = session_data['original_filename']
    commands_to_execute = list(session_data['robot_commands_tuples']) 

    if session_data.get('is_image_drawing', True): 
        if not os.path.exists(SIGNATURE_IMAGE_FULL_PATH):
            logging.error(f"Signature image not found at {SIGNATURE_IMAGE_FULL_PATH}. Skipping signature.")
            emit('command_response', {'success': False, 'message': f"Signature image missing. Drawing '{original_filename}' without signature."})
        else:
            logging.info(f"Processing signature image from: {SIGNATURE_IMAGE_FULL_PATH}")
            try:
                signature_robot_commands = process_image_to_robot_commands_pipeline(
                    SIGNATURE_IMAGE_FULL_PATH, 
                    config.SIGNATURE_CANNY_THRESHOLD1, 
                    config.SIGNATURE_CANNY_THRESHOLD2,
                    optimize=True 
                )
                if signature_robot_commands:
                    logging.info(f"Appending {len(signature_robot_commands)} signature commands (from image) to drawing '{original_filename}'.")
                    commands_to_execute.extend(signature_robot_commands)
                    session_data['total_commands'] = len(commands_to_execute) 
                else:
                    logging.warning(f"No commands generated from signature image '{config.SIGNATURE_IMAGE_FILENAME}'. Drawing without signature.")
                    emit('command_response', {'success': False, 'message': f"Could not process signature image. Drawing '{original_filename}' without signature."})
            except Exception as sig_e:
                logging.error(f"Error processing signature image '{config.SIGNATURE_IMAGE_FILENAME}': {sig_e}", exc_info=True)
                emit('command_response', {'success': False, 'message': f"Error processing signature image. Drawing '{original_filename}' without signature."})

    start_index = session_data['current_command_index']
    total_commands = session_data['total_commands'] 
    
    logging.info(f"Executing/Resuming drawing '{original_filename}' (ID: {active_drawing_session_id}) from command {start_index + 1}/{total_commands}")
    update_drawing_status_in_history(active_drawing_session_id, "in_progress" if start_index == 0 else "in_progress_resumed", start_index)
    emit('drawing_history_updated', get_ui_history_summary(drawing_history))


    try:
        if not robot.is_connected:
            # Attempt to connect using the choice made by the user during the initial "Connect" action
            # This assumes robot.current_target_host/port are set if a previous connection attempt was made.
            # If they are None, it means no connection attempt was made, so use default.
            use_real_for_reconnect = config.USE_REAL_ROBOT_DEFAULT
            if robot.current_target_host == config.REAL_ROBOT_HOST:
                 use_real_for_reconnect = True
            
            logging.info(f"Robot not connected. Attempting to reconnect for drawing (use_real={use_real_for_reconnect})...")
            conn_success, conn_msg = robot.connect_robot(use_real=use_real_for_reconnect)
            if not conn_success:
                emit('command_response', {'success': False, 'message': f"Robot connection failed: {conn_msg}"})
                is_drawing_active_flag = False; active_drawing_session_id = None
                update_drawing_status_in_history(drawing_session_id_to_execute, "interrupted", start_index)
                emit('drawing_status_update', {'active': False, 'message': f"Drawing of '{original_filename}' interrupted (robot connection failed).", 'resumable': True, 'drawing_id': drawing_session_id_to_execute, 'original_filename': original_filename, 'progress': (start_index / total_commands) * 100 if total_commands > 0 else 0})
                emit('drawing_history_updated', get_ui_history_summary(drawing_history))
                return
            emit('robot_connection_status', {'success': True, 'message': conn_msg})
        
        if start_index == 0: 
            safe_x, safe_z, safe_y = config.SAFE_ABOVE_CENTER_PY
            success_safe, msg_safe = robot.move_to_position_py(safe_x, safe_z, safe_y)
            if not success_safe:
                is_drawing_active_flag = False; active_drawing_session_id = None
                update_drawing_status_in_history(drawing_session_id_to_execute, "interrupted", 0)
                emit('drawing_status_update', {'active': False, 'message': f"Drawing of '{original_filename}' aborted (safe start failed).", 'resumable': True, 'drawing_id': drawing_session_id_to_execute, 'original_filename': original_filename, 'progress': 0})
                emit('drawing_history_updated', get_ui_history_summary(drawing_history))
                robot.go_home(); return

        for i in range(start_index, total_commands):
            session_data['current_command_index'] = i 
            add_or_update_drawing_in_history(session_data.copy()) 
            
            x_py, z_py, y_py = commands_to_execute[i] 
            formatted_cmd_str = robot._format_command(x_py, z_py, y_py) 
            progress_message = f"Drawing '{original_filename}': Cmd {i+1}/{total_commands}"
            emit('drawing_status_update', {'active': True, 'message': progress_message, 'progress': ((i+1)/total_commands) * 100, 'resumable': True, 'drawing_id': active_drawing_session_id, 'original_filename': original_filename})
            
            success, msg = robot.send_command_raw(formatted_cmd_str)
            if not success:
                is_drawing_active_flag = False; # Keep active_drawing_session_id for resume
                update_drawing_status_in_history(drawing_session_id_to_execute, "interrupted", i)
                emit('drawing_status_update', {'active': False, 'message': f"Drawing of '{original_filename}' interrupted. Ready to resume.", 'resumable': True, 'drawing_id': drawing_session_id_to_execute, 'original_filename': original_filename, 'progress': (i / total_commands) * 100 if total_commands > 0 else 0})
                emit('drawing_history_updated', get_ui_history_summary(drawing_history))
                return 
            socketio.sleep(0.0005) 
            
        update_drawing_status_in_history(drawing_session_id_to_execute, "completed", total_commands)
        emit('command_response', {'success': True, 'message': f"Sent all {total_commands} commands for '{original_filename}'."})
        emit('drawing_status_update', {'active': False, 'message': f"Drawing of '{original_filename}' complete.", 'resumable': False, 'drawing_id': drawing_session_id_to_execute}) # Ensure active:False is sent
        emit('drawing_history_updated', get_ui_history_summary(drawing_history))
        robot.go_home() 
        is_drawing_active_flag = False
        active_drawing_session_id = None # Clear active session ID on completion

    except Exception as e:
        logging.error(f"Error during drawing execution for '{original_filename}': {e}", exc_info=True)
        is_drawing_active_flag = False # Keep active_drawing_session_id for resume
        current_idx = session_data.get('current_command_index', start_index) 
        update_drawing_status_in_history(drawing_session_id_to_execute, "interrupted_error", current_idx)
        emit('command_response', {'success': False, 'message': f"Error during drawing: {e}"})
        emit('drawing_status_update', {'active': False, 'message': f"Drawing of '{original_filename}' failed with server error. Ready to resume.", 'resumable': True, 'drawing_id': drawing_session_id_to_execute, 'original_filename': original_filename, 'progress': (current_idx / total_commands) * 100 if total_commands > 0 else 0})
        emit('drawing_history_updated', get_ui_history_summary(drawing_history))
    finally:
        # This check is important: only clear active_drawing_session_id if the drawing truly finished or was unrecoverably aborted.
        # If it was interrupted for resume, active_drawing_session_id should persist.
        # The 'completed' status or an explicit abort signal should lead to clearing it.
        current_status = get_drawing_from_history(drawing_session_id_to_execute)
        if current_status and current_status['status'] == 'completed':
             active_drawing_session_id = None
        # If is_drawing_active_flag is false but it wasn't a clean completion, active_drawing_session_id might still be set for resume.
        logging.info(f"Drawing execution for '{original_filename}' (ID: {drawing_session_id_to_execute}) ended. Active flag: {is_drawing_active_flag}, Active ID: {active_drawing_session_id}")


@socketio.on('process_image_for_drawing')
def handle_process_image_for_drawing(data):
    global is_drawing_active_flag, active_drawing_session_id
    
    if is_drawing_active_flag: 
        emit('command_response', {'success': False, 'message': "Another drawing is already in progress or active."})
        return

    if active_drawing_session_id: 
        update_drawing_status_in_history(active_drawing_session_id, "aborted_new_drawing")
    active_drawing_session_id = None 

    filepath_on_server = data.get('filepath')
    original_filename = data.get('original_filename', os.path.basename(filepath_on_server or "unknown_image"))
    if not filepath_on_server or not os.path.exists(filepath_on_server): 
        emit('command_response', {'success': False, 'message': f"File not found: {filepath_on_server}"}); return
    
    canny_t1, canny_t2 = data.get('canny_t1', config.DEFAULT_CANNY_THRESHOLD1), data.get('canny_t2', config.DEFAULT_CANNY_THRESHOLD2)
    logging.info(f"API: Processing image for new drawing: '{original_filename}' with T1={canny_t1}, T2={canny_t2}")
    emit('drawing_status_update', {'active': True, 'message': f"Processing '{original_filename}'...", 'resumable': False}) 

    try:
        robot_commands_tuples = process_image_to_robot_commands_pipeline(filepath_on_server, canny_t1, canny_t2)
        if not robot_commands_tuples: 
            emit('command_response', {'success': False, 'message': f"No drawing commands for '{original_filename}'."})
            emit('drawing_status_update', {'active': False, 'message': f"Failed to process '{original_filename}'.", 'resumable': False})
            return
        
        drawing_id = f"draw_{int(time.time())}_{uuid.uuid4().hex[:6]}"
        
        new_drawing_data = {
            'drawing_id': drawing_id,
            'filepath_on_server': filepath_on_server,
            'original_filename': original_filename,
            'robot_commands_tuples': robot_commands_tuples, 
            'current_command_index': 0,
            'total_commands': len(robot_commands_tuples), 
            'canny_t1': canny_t1,
            'canny_t2': canny_t2,
            'status': 'pending_execution', 
            'timestamp': datetime.now().isoformat(),
            'is_image_drawing': True 
        }
        add_or_update_drawing_in_history(new_drawing_data) 
        
        emit('drawing_status_update', {'active': True, 'message': f"Generated {len(robot_commands_tuples)} image commands. Preparing to draw '{original_filename}'.", 'resumable': True, 'drawing_id': drawing_id, 'original_filename': original_filename, 'progress': 0})
        emit('drawing_history_updated', get_ui_history_summary(drawing_history))
        
        _execute_drawing_commands(drawing_id) 

    except Exception as e: 
        logging.error(f"Error in initial processing for drawing '{original_filename}': {e}", exc_info=True)
        emit('command_response', {'success': False, 'message': f"Error processing image: {e}"})
        emit('drawing_status_update', {'active': False, 'message': f"Error processing '{original_filename}'.", 'resumable': False})
        active_drawing_session_id = None 
        is_drawing_active_flag = False

@socketio.on('resume_drawing_request')
def handle_resume_drawing_request(data):
    global is_drawing_active_flag, active_drawing_session_id
    drawing_id_to_resume = data.get('drawing_id')
    logging.info(f"--- API: Event 'resume_drawing_request' RECEIVED for drawing_id: {drawing_id_to_resume} ---")

    if is_drawing_active_flag:
        logging.warning(f"Resume requested for {drawing_id_to_resume}, but a drawing ('{active_drawing_session_id}') is already active.")
        emit('drawing_status_update', {'active': True, 'message': "Cannot resume, another drawing is currently active.", 'resumable': True if active_drawing_session_id else False, 'drawing_id': active_drawing_session_id})
        return

    session_to_resume = get_drawing_from_history(drawing_id_to_resume)

    if session_to_resume:
        if session_to_resume.get('status') == 'completed':
            logging.info(f"Drawing '{session_to_resume['original_filename']}' is already completed. Cannot resume.")
            emit('drawing_status_update', {'active': False, 'message': f"Drawing '{session_to_resume['original_filename']}' is already completed.", 'resumable': False, 'drawing_id': drawing_id_to_resume})
            return
        
        logging.info(f"Attempting to resume drawing of '{session_to_resume['original_filename']}' from command {session_to_resume['current_command_index'] + 1}")
        emit('drawing_status_update', {
            'active': True, 
            'message': f"Resuming drawing of '{session_to_resume['original_filename']}'...",
            'resumable': True,
            'drawing_id': drawing_id_to_resume,
            'original_filename': session_to_resume['original_filename'],
            'progress': (session_to_resume['current_command_index'] / session_to_resume['total_commands']) * 100 if session_to_resume['total_commands'] > 0 else 0
        })
        _execute_drawing_commands(drawing_id_to_resume) 
    else:
        logging.warning(f"Resume requested for drawing_id {drawing_id_to_resume}, but no such drawing state found in history.")
        emit('drawing_status_update', {'active': False, 'message': "Drawing session to resume not found.", 'resumable': False})

@socketio.on('restart_drawing_request')
def handle_restart_drawing_request(data):
    global is_drawing_active_flag, active_drawing_session_id, drawing_history
    drawing_id_to_restart = data.get('drawing_id')
    logging.info(f"--- API: Event 'restart_drawing_request' RECEIVED for drawing_id: {drawing_id_to_restart} ---")

    if is_drawing_active_flag:
        logging.warning(f"Restart requested for {drawing_id_to_restart}, but a drawing ('{active_drawing_session_id}') is already active.")
        emit('drawing_status_update', {'active': True, 'message': "Cannot restart, another drawing is currently active.", 'resumable': True if active_drawing_session_id else False, 'drawing_id': active_drawing_session_id})
        return

    session_to_restart = get_drawing_from_history(drawing_id_to_restart)
    if session_to_restart:
        logging.info(f"Restarting drawing of '{session_to_restart['original_filename']}' from the beginning.")
        session_to_restart['current_command_index'] = 0
        session_to_restart['status'] = 'pending_restart' 
        
        add_or_update_drawing_in_history(session_to_restart.copy()) 

        emit('drawing_status_update', {
            'active': True, 
            'message': f"Restarting drawing of '{session_to_restart['original_filename']}'...",
            'resumable': True, 
            'drawing_id': drawing_id_to_restart,
            'original_filename': session_to_restart['original_filename'],
            'progress': 0
        })
        emit('drawing_history_updated', get_ui_history_summary(drawing_history))
        _execute_drawing_commands(drawing_id_to_restart)
    else:
        logging.warning(f"Restart requested for drawing_id {drawing_id_to_restart}, but no such drawing state found in history.")
        emit('drawing_status_update', {'active': False, 'message': "Drawing session to restart not found.", 'resumable': False})


if __name__ == '__main__':
    server_port = 5555 
    app.config['SERVER_PORT'] = server_port 
    logging.info(f"Starting Python backend server (SocketIO with Flask) on port {server_port}...")
    socketio.run(app, host='0.0.0.0', port=server_port, debug=True, use_reloader=False)

--- END OF FILE: backend/api_server.py ---
--- START OF FILE: backend/config.py ---
# backend/config.py

import os 

# --- Robot Connection Settings ---
SIMULATION_HOST = '127.0.0.1'
SIMULATION_PORT = 55000
REAL_ROBOT_HOST = '192.168.125.1' # Your actual robot IP
REAL_ROBOT_PORT = 1025          # Your actual robot port

# The USE_REAL_ROBOT constant is now primarily a server-side default
# if the client doesn't specify. The client's choice will take precedence.
# It can also be used by other backend modules if they need a default
# robot type assumption without client input.
USE_REAL_ROBOT_DEFAULT = False # Default to simulation if not specified by client

# --- QR Code Upload Settings ---
QR_UPLOAD_FOLDER = 'qr_uploads' # Relative to the backend directory


# --- Robot Predefined Positions ---
# These are (X, Z_depth, Y_left_right) tuples as sent from Python
# Z is typically the pen height/depth axis for drawing.
# Y is typically the left/right axis on the paper for drawing.

ROBOT_HOME_POSITION_PY = (300, -350.922061873, 300)
SAFE_ABOVE_CENTER_PY = (0.00, -150.0, 0.00)

# --- Drawing Constants (adapted from original main.py) ---
# These define the target drawing area in mm for scaling.
# The (X,Y,Z) offsets sent to the robot are relative to WorkSpaceCenter1 in RAPID.
# The Python (X_py, Y_py) from image processing will map to RAPID (x_offset, z_offset).
# The Python Z_py (pen height) will map to RAPID y_offset.

A4_DRAWING_AREA_WIDTH_MM = 180  # Effective drawing width for scaling image contours
A4_DRAWING_AREA_HEIGHT_MM = 217 # Effective drawing height for scaling image contours

# Python Z-values for pen height, these will be sent as the 'Z' in the "X,Z,Y" string
# which corresponds to the 'y' offset in the RAPID MoveL Offs(WorkSpaceCenter1, x, y, z)
PEN_UP_Z_PY = -15.0  # Pen up position (e.g., -15mm from WorkSpaceCenter1's XY plane along its Y-axis)
PEN_DOWN_Z_PY = -7.0 # Pen down position (e.g., -7mm from WorkSpaceCenter1's XY plane along its Y-axis)

MIN_CONTOUR_LENGTH_PX = 50 # Minimum contour length in pixels to consider from image processing

DEFAULT_CANNY_THRESHOLD1 = 50
DEFAULT_CANNY_THRESHOLD2 = 150

# --- Signature Settings ---
# Path to the signature image, relative to the backend directory
ASSETS_FOLDER_NAME = 'assets'
SIGNATURE_IMAGE_FILENAME = "signature.jpg" # Ensure this file is in backend/assets/

# Canny thresholds for processing the signature image.
# These can be tuned for optimal results with your specific signature.jpg
SIGNATURE_CANNY_THRESHOLD1 = 50
SIGNATURE_CANNY_THRESHOLD2 = 150
# You might want to make these thresholds different from the default image processing
# if your signature image requires different settings for optimal edge detection.
# For example, if the signature is very clean, lower thresholds might be better.
# SIGNATURE_CANNY_THRESHOLD1 = 30
# SIGNATURE_CANNY_THRESHOLD2 = 100


# --- Temporary Audio File Settings ---
AUDIO_TEMP_FOLDER = 'audio_tmp' # Relative to the backend directory

# --- LLM Settings ---
# IMPORTANT: Replace with the actual filename of your downloaded GGUF model
# LLM_MODEL_FILENAME = "deepseek-llm-7b-chat.Q4_K_M.gguf"
LLM_MODEL_FILENAME = ""
LLM_MAX_TOKENS = 512 # Max tokens for LLM response
LLM_TEMPERATURE = 0.3 # Temperature for LLM response
LLM_N_CTX = 2048 # Context window size for the LLM
LLM_N_GPU_LAYERS = 0 # Number of layers to offload to GPU. 0 for CPU only. 
                     # If you have a compatible GPU and llama-cpp-python with GPU support, you can increase this.

--- END OF FILE: backend/config.py ---
--- START OF FILE: backend/image_processing_engine.py ---
# backend/image_processing_engine.py
import cv2
import numpy as np
import math
import os # For path joining if saving temp edge images
import config # Import our configuration
import logging # Added for consistency

# --- Helper Function (from original main.py) ---
def calculate_distance(p1, p2):
    """Calculates Euclidean distance between two points (x, y)."""
    if p1 is None or p2 is None: return float('inf')
    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)

# --- Core Image Processing Functions (adapted from original main.py) ---

def get_canny_edges_array(image_path_or_array, threshold1, threshold2):
    """
    Generates a Canny edge detected image array.
    :param image_path_or_array: Path to the input image or a pre-loaded cv2 image array (BGR or Grayscale).
    :param threshold1: Lower threshold for Canny edge detection.
    :param threshold2: Upper threshold for Canny edge detection.
    :return: NumPy array of the Canny edges, or None on failure.
    """
    if isinstance(image_path_or_array, str):
        if not os.path.exists(image_path_or_array):
            logging.error(f"Image path does not exist: {image_path_or_array}")
            return None
        image = cv2.imread(image_path_or_array, cv2.IMREAD_GRAYSCALE)
        if image is None:
            logging.error(f"Could not read image at {image_path_or_array}")
            return None
    elif isinstance(image_path_or_array, np.ndarray):
        if len(image_path_or_array.shape) == 3: # BGR
            image = cv2.cvtColor(image_path_or_array, cv2.COLOR_BGR2GRAY)
        elif len(image_path_or_array.shape) == 2: # Already Grayscale
            image = image_path_or_array
        else:
            logging.error("Invalid NumPy array format for image.")
            return None
    else:
        logging.error(f"Invalid input type for get_canny_edges_array: {type(image_path_or_array)}")
        return None

    image_height, image_width = image.shape[:2]
    if image_height == 0 or image_width == 0:
         logging.error("Invalid image dimensions for Canny edge detection.")
         return None

    blurred = cv2.GaussianBlur(image, (5, 5), 0)
    edges = cv2.Canny(blurred, threshold1, threshold2)
    
    return edges


def get_image_contours(image_path, threshold1, threshold2, save_edge_path_prefix=None):
    """
    Convert image to contours using specific thresholds.
    :param image_path: Path to the input image.
    :param threshold1: Lower threshold for Canny edge detection.
    :param threshold2: Upper threshold for Canny edge detection.
    :param save_edge_path_prefix: Optional prefix to save the edge image for preview (e.g., "temp_edges").
                                  If provided, the edge image from Canny will be saved.
    :return: List of contours (pixel coordinates), image_width, image_height, or (None, 0, 0) on failure.
    """
    edges = get_canny_edges_array(image_path, threshold1, threshold2)
    if edges is None:
        return None, 0, 0
        
    image_height, image_width = edges.shape[:2] # Get dimensions from the edges image

    if save_edge_path_prefix:
        try:
            # Ensure the directory for saved edges exists if it's part of the prefix
            edge_save_dir = os.path.dirname(save_edge_path_prefix)
            if edge_save_dir and not os.path.exists(edge_save_dir):
                os.makedirs(edge_save_dir, exist_ok=True)
            
            base, ext = os.path.splitext(os.path.basename(image_path))
            edge_filename = f"{save_edge_path_prefix}_{base}_t{threshold1}-{threshold2}.png"
            cv2.imwrite(edge_filename, edges)
            logging.info(f"Edge image saved to {edge_filename} (from get_image_contours)")
        except Exception as e:
            logging.error(f"Failed to save edge image in get_image_contours: {e}")

    contours_cv, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    
    contours_xy = []
    for contour in contours_cv:
        if cv2.arcLength(contour, closed=False) > config.MIN_CONTOUR_LENGTH_PX:
            points = contour.squeeze().tolist()
            if not isinstance(points, list) or not points: continue
            if isinstance(points[0], int): 
                points = [points]
            
            current_contour_points = []
            for p_arr in points:
                if isinstance(p_arr, (list, tuple)) and len(p_arr) == 2:
                    current_contour_points.append(tuple(p_arr))
                elif isinstance(p_arr, np.ndarray) and p_arr.shape == (2,): 
                    current_contour_points.append(tuple(p_arr.tolist()))

            if current_contour_points: 
                contours_xy.append(current_contour_points)
                
    return contours_xy, image_width, image_height

def scale_contour_point(point_xy, image_width, image_height, target_width_mm, target_height_mm):
    """ Scales and transforms a single (x, y) pixel coordinate to centered target (mm)."""
    x_pixel, y_pixel = point_xy
    
    scale_x_factor = target_width_mm / image_width
    scale_y_factor = target_height_mm / image_height
    scale_factor = min(scale_x_factor, scale_y_factor)

    x_centered_pixel = x_pixel - (image_width / 2)
    y_centered_pixel = (image_height / 2) - y_pixel 

    x_py_offset = x_centered_pixel * scale_factor
    y_py_offset = y_centered_pixel * scale_factor 
    return (x_py_offset, y_py_offset)


def generate_robot_drawing_commands(contours_xy, image_width, image_height, optimize_paths=True):
    """ 
    Takes list of contours (pixel coordinates), scales them, creates drawing paths (X_py, Z_depth_py, Y_py).
    Z_py is the pen height (config.PEN_UP_Z_PY or config.PEN_DOWN_Z_PY).
    X_py and Y_py are the planar coordinates for drawing.
    """
    if not contours_xy or image_width <= 0 or image_height <= 0:
        return []

    scaled_contours = []
    for contour in contours_xy:
        if not contour: continue
        scaled_contour_points = [
            scale_contour_point(p, image_width, image_height, 
                                config.A4_DRAWING_AREA_WIDTH_MM, config.A4_DRAWING_AREA_HEIGHT_MM)
            for p in contour
        ]
        if len(scaled_contour_points) >= 1: 
            scaled_contours.append(scaled_contour_points)

    if not scaled_contours:
        return []

    ordered_contours = []
    if optimize_paths and scaled_contours:
        remaining_contours = list(scaled_contours)
        current_point = (0,0) 

        while remaining_contours:
            best_contour_idx = -1
            min_dist = float('inf')
            reverse_needed = False

            for i, contour_to_check in enumerate(remaining_contours):
                start_pt = contour_to_check[0]
                end_pt = contour_to_check[-1]
                
                dist_to_start = calculate_distance(current_point, start_pt)
                dist_to_end = calculate_distance(current_point, end_pt)

                if dist_to_start < min_dist:
                    min_dist = dist_to_start
                    best_contour_idx = i
                    reverse_needed = False
                
                if dist_to_end < min_dist: 
                    min_dist = dist_to_end
                    best_contour_idx = i
                    reverse_needed = True
            
            if best_contour_idx != -1:
                next_contour = remaining_contours.pop(best_contour_idx)
                if reverse_needed:
                    next_contour.reverse()
                ordered_contours.append(next_contour)
                current_point = next_contour[-1] 
            else:
                break 
        processed_contours = ordered_contours
    else:
        processed_contours = scaled_contours

    robot_commands_xyz_py = [] 
    for contour_points in processed_contours:
        if not contour_points: continue
        
        start_x_py, start_y_py = contour_points[0]
        robot_commands_xyz_py.append((start_x_py, config.PEN_UP_Z_PY, start_y_py))
        robot_commands_xyz_py.append((start_x_py, config.PEN_DOWN_Z_PY, start_y_py))

        for i in range(len(contour_points)): 
            pt_x_py, pt_y_py = contour_points[i]
            if i > 0 or len(contour_points) == 1: 
                 robot_commands_xyz_py.append((pt_x_py, config.PEN_DOWN_Z_PY, pt_y_py))

        end_x_py, end_y_py = contour_points[-1]
        robot_commands_xyz_py.append((end_x_py, config.PEN_UP_Z_PY, end_y_py))
        
    return robot_commands_xyz_py


def process_image_to_robot_commands_pipeline(image_filepath, 
                                             canny_thresh1=config.DEFAULT_CANNY_THRESHOLD1, 
                                             canny_thresh2=config.DEFAULT_CANNY_THRESHOLD2,
                                             optimize=True):
    """
    Main pipeline function to take an image path and return a list of robot drawing commands.
    Each command is a tuple (X_py, Z_depth_py, Y_py).
    """
    logging.info(f"Processing image: {image_filepath} with Canny thresholds: {canny_thresh1}, {canny_thresh2}")
    
    # The get_image_contours function now internally calls get_canny_edges_array
    # and can save a preview if save_edge_path_prefix is set (though api_server handles preview separately now)
    contours, img_w, img_h = get_image_contours(image_filepath, canny_thresh1, canny_thresh2, save_edge_path_prefix=None) # No separate save here

    if contours is None or not contours:
        logging.warning("No contours found or error in contour extraction.")
        return []

    logging.info(f"Found {len(contours)} contours. Image dimensions: {img_w}x{img_h}")
    
    robot_drawing_cmds = generate_robot_drawing_commands(contours, img_w, img_h, optimize_paths=optimize)
    
    logging.info(f"Generated {len(robot_drawing_cmds)} robot drawing commands.")
    return robot_drawing_cmds

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO) # Ensure logging is configured for direct script run
    
    if not os.path.exists(config.QR_UPLOAD_FOLDER):
        os.makedirs(config.QR_UPLOAD_FOLDER)

    test_image_name = "test_square_preview.png"
    test_image_path = os.path.join(config.QR_UPLOAD_FOLDER, test_image_name)
    if not os.path.exists(test_image_path):
        img_arr = np.zeros((200, 200, 1), dtype="uint8")
        cv2.rectangle(img_arr, (50, 50), (150, 150), (255), thickness=3) 
        cv2.imwrite(test_image_path, img_arr)
        logging.info(f"Created dummy test image: {test_image_path}")

    if os.path.exists(test_image_path):
        logging.info(f"\n--- Testing Canny Edge Array Generation for {test_image_path} ---")
        test_t1, test_t2 = 50, 150
        edges = get_canny_edges_array(test_image_path, test_t1, test_t2)
        if edges is not None:
            logging.info(f"Canny edges array generated with shape: {edges.shape}")
            preview_save_path = os.path.join(config.QR_UPLOAD_FOLDER, f"test_canny_preview_t{test_t1}_{test_t2}.png")
            cv2.imwrite(preview_save_path, edges)
            logging.info(f"Saved Canny edge preview to: {preview_save_path}")
        else:
            logging.error("Failed to generate Canny edges array.")

        logging.info(f"\n--- Testing image processing pipeline with {test_image_path} ---")
        commands = process_image_to_robot_commands_pipeline(test_image_path, canny_thresh1=test_t1, canny_thresh2=test_t2)
        if commands:
            logging.info(f"\nFirst 5 generated commands (X_py, Z_depth_py, Y_py):")
            for cmd in commands[:5]:
                print(cmd) # Using print for cleaner tuple output
            if len(commands) > 5:
                logging.info("...")
                logging.info(f"Last 5 generated commands (X_py, Z_depth_py, Y_py):")
                for cmd in commands[-5:]:
                    print(cmd)
        else:
            logging.info("No commands generated by pipeline.")
    else:
        logging.warning(f"Test image not found: {test_image_path}. Skipping pipeline test.")

--- END OF FILE: backend/image_processing_engine.py ---
--- START OF FILE: backend/main.py ---
import tkinter as tk
from tkinter import messagebox, filedialog, ttk # Added ttk for progress bar
import os
import threading
import time
import logging
import socket
from concurrent.futures import ThreadPoolExecutor
from typing import List, Tuple, Optional
import cv2 # <-- Added
import numpy as np # <-- Added (likely already implicitly used by cv2)
import math
from PIL import Image, ImageTk # <-- Added
# Consider adding tkinterdnd2 for drag-and-drop later if needed
# import tkinterdnd2

# --- Drawing Logic Imports ---
# (image_to_contours_internal, scale_point_to_a4, create_drawing_paths, calculate_distance) defined below

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# --- Constants (Consolidated) ---
SCRIPT_DIR = os.getenv("SCRIPT_DIR", ".") # Default to current dir if not set
DATA_DIR = os.getenv("DATA_DIR", ".") # Default to current dir

# TMP_POSITION_FILE = os.path.join(DATA_DIR, "Tmp_position.txt") # Likely not needed for drawing
TMP_CAPTURE_PATH = os.path.join(DATA_DIR, "temp_capture.png") # For captured image
TMP_EDGE_OUTPUT_PATH = os.path.join(DATA_DIR, "temp_edges_{}.png") # For edge previews

REAL_ROBOT_HOST = '192.168.125.1'
REAL_ROBOT_PORT = 1025
SIMULATION_HOST = '127.0.0.1'
SIMULATION_PORT = 55000

# Drawing Specific Constants
FINAL_ROBOT_POSITION = (0, -350, 0) # Use X, Z, Y format (X, Depth, Y) - NOTE: Z is depth here
A4_WIDTH_MM = 180  # Drawing area width
A4_HEIGHT_MM = 217 # Drawing area height
PEN_UP_Z = -15     # Pen up position (depth)
PEN_DOWN_Z = -7   # Pen down position (depth)
MIN_CONTOUR_LENGTH_PX = 50 # Minimum contour length in pixels to consider

# Threshold options
THRESHOLD_OPTIONS = [
    ("Option {}".format(i), i*10, i*20) for i in range(1, 8)
]

# Time estimation factor
TIME_ESTIMATE_FACTOR = 0.018 # seconds per command estimated

SIGNATURE_POINTS = ((46.94, -15.0, -119.18), (46.94, PEN_DOWN_Z, -119.18), (47.06, PEN_DOWN_Z, -119.06), (47.41, PEN_DOWN_Z, -119.06), (47.53, PEN_DOWN_Z, -119.18), (47.29, PEN_DOWN_Z, -119.41), (47.29, PEN_DOWN_Z, -119.53), (47.18, PEN_DOWN_Z, -119.65), (47.18, PEN_DOWN_Z, -119.76), (47.06, PEN_DOWN_Z, -119.88), (47.06, PEN_DOWN_Z, -120.0), (46.94, PEN_DOWN_Z, -120.12), (46.94, PEN_DOWN_Z, -120.24), (46.82, PEN_DOWN_Z, -120.35), (46.59, PEN_DOWN_Z, -120.12), (46.71, PEN_DOWN_Z, -120.0), (46.71, PEN_DOWN_Z, -119.76), (46.82, PEN_DOWN_Z, -119.65), (46.82, PEN_DOWN_Z, -119.53), (46.94, PEN_DOWN_Z, -119.41), (46.94, -15.0, -119.41), (47.53, -15.0, -119.06), (47.53, PEN_DOWN_Z, -119.06), (47.53, PEN_DOWN_Z, -119.29), (47.29, PEN_DOWN_Z, -119.53), (47.29, PEN_DOWN_Z, -119.65), (47.18, PEN_DOWN_Z, -119.76), (47.18, PEN_DOWN_Z, -119.88), (47.06, PEN_DOWN_Z, -120.0), (47.06, PEN_DOWN_Z, -120.12), (46.94, PEN_DOWN_Z, -120.24), (46.94, PEN_DOWN_Z, -120.35), (46.71, PEN_DOWN_Z, -120.35), (46.71, PEN_DOWN_Z, -120.24), (46.59, PEN_DOWN_Z, -120.12), (46.71, PEN_DOWN_Z, -120.0), (46.71, PEN_DOWN_Z, -119.76), (46.82, PEN_DOWN_Z, -119.65), (46.82, PEN_DOWN_Z, -119.53), (46.94, PEN_DOWN_Z, -119.41), (46.94, PEN_DOWN_Z, -119.06), (47.53, PEN_DOWN_Z, -119.06), (47.65, PEN_DOWN_Z, -118.94), (47.65, -15.0, -118.94), (46.35, -15.0, -118.94), (46.35, PEN_DOWN_Z, -118.94), (46.47, PEN_DOWN_Z, -119.06), (46.59, PEN_DOWN_Z, -119.06), (46.59, PEN_DOWN_Z, -119.29), (46.47, PEN_DOWN_Z, -119.41), (46.47, PEN_DOWN_Z, -119.65), (46.24, PEN_DOWN_Z, -119.65), (46.24, PEN_DOWN_Z, -119.53), (46.12, PEN_DOWN_Z, -119.41), (46.12, PEN_DOWN_Z, -119.29), (46.0, PEN_DOWN_Z, -119.18), (46.0, PEN_DOWN_Z, -118.94), (46.0, -15.0, -118.94), (46.0, -15.0, -119.06), (46.0, PEN_DOWN_Z, -119.06), (46.12, PEN_DOWN_Z, -118.94), (46.35, PEN_DOWN_Z, -118.94), (46.59, PEN_DOWN_Z, -119.18), (46.59, PEN_DOWN_Z, -119.29), (46.47, PEN_DOWN_Z, -119.41), (46.47, PEN_DOWN_Z, -119.53), (46.35, PEN_DOWN_Z, -119.65), (46.24, PEN_DOWN_Z, -119.53), (46.24, PEN_DOWN_Z, -119.41), (46.0, PEN_DOWN_Z, -119.18), (46.0, -15.0, -119.18), (50.71, -15.0, -113.65), (50.71, PEN_DOWN_Z, -113.65), (50.59, PEN_DOWN_Z, -113.76), (50.47, PEN_DOWN_Z, -113.76), (50.35, PEN_DOWN_Z, -113.88), (50.24, PEN_DOWN_Z, -113.88), (50.12, PEN_DOWN_Z, -114.0), (50.0, PEN_DOWN_Z, -114.0), (49.65, PEN_DOWN_Z, -114.35), (49.53, PEN_DOWN_Z, -114.35), (48.71, PEN_DOWN_Z, -115.18), (48.71, PEN_DOWN_Z, -115.29), (48.35, PEN_DOWN_Z, -115.65), (48.35, PEN_DOWN_Z, -115.76), (48.24, PEN_DOWN_Z, -115.88), (48.24, PEN_DOWN_Z, -116.0), (48.12, PEN_DOWN_Z, -116.12), (48.12, PEN_DOWN_Z, -116.24), (48.0, PEN_DOWN_Z, -116.35), (48.0, PEN_DOWN_Z, -116.47), (47.88, PEN_DOWN_Z, -116.59), (47.88, PEN_DOWN_Z, -116.71), (47.76, PEN_DOWN_Z, -116.82), (47.76, PEN_DOWN_Z, -117.18), (47.53, PEN_DOWN_Z, -117.41), (47.53, PEN_DOWN_Z, -117.76), (47.41, PEN_DOWN_Z, -117.88), (47.41, PEN_DOWN_Z, -118.12), (47.29, PEN_DOWN_Z, -118.24), (47.29, PEN_DOWN_Z, -118.47), (47.18, PEN_DOWN_Z, -118.59), (47.18, PEN_DOWN_Z, -118.71), (47.88, PEN_DOWN_Z, -118.71), (47.88, PEN_DOWN_Z, -118.59), (48.12, PEN_DOWN_Z, -118.35), (48.12, PEN_DOWN_Z, -118.24), (48.24, PEN_DOWN_Z, -118.12), (48.24, PEN_DOWN_Z, -118.0), (48.47, PEN_DOWN_Z, -117.76), (48.47, PEN_DOWN_Z, -117.65), (48.59, PEN_DOWN_Z, -117.53), (48.59, PEN_DOWN_Z, -117.41), (48.82, PEN_DOWN_Z, -117.18), (48.82, PEN_DOWN_Z, -117.06), (48.94, PEN_DOWN_Z, -116.94), (48.94, PEN_DOWN_Z, -116.82), (49.18, PEN_DOWN_Z, -116.59), (49.18, PEN_DOWN_Z, -116.47), (49.41, PEN_DOWN_Z, -116.24), (49.41, PEN_DOWN_Z, -116.12), (49.53, PEN_DOWN_Z, -116.0), (49.53, PEN_DOWN_Z, -115.88), (49.76, PEN_DOWN_Z, -115.65), (49.76, PEN_DOWN_Z, -115.53), (49.88, PEN_DOWN_Z, -115.41), (49.88, PEN_DOWN_Z, -115.29), (50.12, PEN_DOWN_Z, -115.06), (50.12, PEN_DOWN_Z, -114.94), (50.35, PEN_DOWN_Z, -114.71), (50.35, PEN_DOWN_Z, -114.59), (50.47, PEN_DOWN_Z, -114.47), (50.47, PEN_DOWN_Z, -114.35), (50.71, PEN_DOWN_Z, -114.12), (50.71, PEN_DOWN_Z, -114.0), (50.82, PEN_DOWN_Z, -113.88), (50.47, PEN_DOWN_Z, -114.24), (50.47, PEN_DOWN_Z, -114.35), (50.35, PEN_DOWN_Z, -114.47), (50.35, PEN_DOWN_Z, -114.59), (50.12, PEN_DOWN_Z, -114.82), (50.12, PEN_DOWN_Z, -114.94), (49.88, PEN_DOWN_Z, -115.18), (49.88, PEN_DOWN_Z, -115.29), (49.76, PEN_DOWN_Z, -115.41), (49.76, PEN_DOWN_Z, -115.53), (49.53, PEN_DOWN_Z, -115.76), (49.53, PEN_DOWN_Z, -115.88), (49.41, PEN_DOWN_Z, -116.0), (49.41, PEN_DOWN_Z, -116.12), (49.18, PEN_DOWN_Z, -116.35), (49.18, PEN_DOWN_Z, -116.47), (48.94, PEN_DOWN_Z, -116.71), (48.94, PEN_DOWN_Z, -116.82), (48.82, PEN_DOWN_Z, -116.94), (48.82, PEN_DOWN_Z, -117.06), (48.59, PEN_DOWN_Z, -117.29), (48.59, PEN_DOWN_Z, -117.41), (48.47, PEN_DOWN_Z, -117.53), (48.47, PEN_DOWN_Z, -117.65), (48.24, PEN_DOWN_Z, -117.88), (48.24, PEN_DOWN_Z, -118.0), (48.12, PEN_DOWN_Z, -118.12), (48.12, PEN_DOWN_Z, -118.24), (47.88, PEN_DOWN_Z, -118.47), (47.88, PEN_DOWN_Z, -118.59), (47.76, PEN_DOWN_Z, -118.71), (47.29, PEN_DOWN_Z, -118.71), (47.18, PEN_DOWN_Z, -118.59), (47.29, PEN_DOWN_Z, -118.47), (47.29, PEN_DOWN_Z, -118.24), (47.41, PEN_DOWN_Z, -118.12), (47.41, PEN_DOWN_Z, -117.88), (47.53, PEN_DOWN_Z, -117.76), (47.53, PEN_DOWN_Z, -117.53), (47.65, PEN_DOWN_Z, -117.41), (47.65, PEN_DOWN_Z, -117.29), (47.76, PEN_DOWN_Z, -117.18), (47.76, PEN_DOWN_Z, -116.94), (47.88, PEN_DOWN_Z, -116.82), (47.88, PEN_DOWN_Z, -116.71), (48.0, PEN_DOWN_Z, -116.59), (48.0, PEN_DOWN_Z, -116.47), (48.12, PEN_DOWN_Z, -116.35), (48.12, PEN_DOWN_Z, -116.24), (48.24, PEN_DOWN_Z, -116.12), (48.24, PEN_DOWN_Z, -116.0), (48.35, PEN_DOWN_Z, -115.88), (48.35, PEN_DOWN_Z, -115.76), (48.71, PEN_DOWN_Z, -115.41), (48.71, PEN_DOWN_Z, -115.29), (49.65, PEN_DOWN_Z, -114.35), (49.76, PEN_DOWN_Z, -114.35), (50.12, PEN_DOWN_Z, -114.0), (50.24, PEN_DOWN_Z, -114.0), (50.47, PEN_DOWN_Z, -113.76), (50.59, PEN_DOWN_Z, -113.76), (50.71, PEN_DOWN_Z, -113.65), (50.94, PEN_DOWN_Z, -113.65), (50.94, -15.0, -113.65), (51.88, -15.0, -112.24), (51.88, PEN_DOWN_Z, -112.24), (51.65, PEN_DOWN_Z, -112.47), (51.65, PEN_DOWN_Z, -112.59), (51.53, PEN_DOWN_Z, -112.71), (51.53, PEN_DOWN_Z, -112.82), (51.29, PEN_DOWN_Z, -113.06), (51.29, PEN_DOWN_Z, -113.18), (51.06, PEN_DOWN_Z, -113.18), (50.94, PEN_DOWN_Z, -113.29), (50.71, PEN_DOWN_Z, -113.29), (50.59, PEN_DOWN_Z, -113.41), (50.47, PEN_DOWN_Z, -113.41), (50.35, PEN_DOWN_Z, -113.53), (50.24, PEN_DOWN_Z, -113.53), (50.0, PEN_DOWN_Z, -113.76), (49.88, PEN_DOWN_Z, -113.76), (49.65, PEN_DOWN_Z, -114.0), (49.53, PEN_DOWN_Z, -114.0), (48.24, PEN_DOWN_Z, -115.29), (48.24, PEN_DOWN_Z, -115.41), (48.12, PEN_DOWN_Z, -115.53), (48.12, PEN_DOWN_Z, -115.65), (47.88, PEN_DOWN_Z, -115.88), (47.88, PEN_DOWN_Z, -116.0), (47.76, PEN_DOWN_Z, -116.12), (47.76, PEN_DOWN_Z, -116.35), (47.65, PEN_DOWN_Z, -116.47), (47.65, PEN_DOWN_Z, -116.59), (47.41, PEN_DOWN_Z, -116.82), (47.41, PEN_DOWN_Z, -117.06), (47.29, PEN_DOWN_Z, -117.18), (47.29, PEN_DOWN_Z, -117.41), (47.18, PEN_DOWN_Z, -117.53), (47.18, PEN_DOWN_Z, -117.65), (47.06, PEN_DOWN_Z, -117.76), (47.06, PEN_DOWN_Z, -118.0), (46.94, PEN_DOWN_Z, -118.12), (46.94, PEN_DOWN_Z, -118.35), (46.82, PEN_DOWN_Z, -118.47), (46.82, PEN_DOWN_Z, -118.71), (46.47, PEN_DOWN_Z, -118.71), (46.35, PEN_DOWN_Z, -118.59), (46.0, PEN_DOWN_Z, -118.59), (45.88, PEN_DOWN_Z, -118.47), (45.76, PEN_DOWN_Z, -118.47), (45.76, PEN_DOWN_Z, -118.35), (45.65, PEN_DOWN_Z, -118.24), (45.65, PEN_DOWN_Z, -118.12), (45.53, PEN_DOWN_Z, -118.0), (45.41, PEN_DOWN_Z, -118.0), (45.29, PEN_DOWN_Z, -118.12), (45.29, PEN_DOWN_Z, -118.35), (45.41, PEN_DOWN_Z, -118.47), (45.41, PEN_DOWN_Z, -118.59), (45.53, PEN_DOWN_Z, -118.71), (45.53, PEN_DOWN_Z, -118.82), (45.65, PEN_DOWN_Z, -118.94), (45.65, PEN_DOWN_Z, -119.18), (45.76, PEN_DOWN_Z, -119.29), (45.76, PEN_DOWN_Z, -119.41), (45.88, PEN_DOWN_Z, -119.53), (45.88, PEN_DOWN_Z, -119.65), (46.12, PEN_DOWN_Z, -119.88), (46.12, PEN_DOWN_Z, -120.0), (46.24, PEN_DOWN_Z, -120.12), (46.24, PEN_DOWN_Z, -120.47), (46.12, PEN_DOWN_Z, -120.59), (46.12, PEN_DOWN_Z, -120.71), (46.0, PEN_DOWN_Z, -120.82), (46.0, PEN_DOWN_Z, -121.06), (45.88, PEN_DOWN_Z, -121.18), (45.88, PEN_DOWN_Z, -121.53), (45.76, PEN_DOWN_Z, -121.65), (45.76, PEN_DOWN_Z, -122.0), (45.65, PEN_DOWN_Z, -122.12), (45.65, PEN_DOWN_Z, -122.24), (45.53, PEN_DOWN_Z, -122.35), (45.53, PEN_DOWN_Z, -122.59), (45.41, PEN_DOWN_Z, -122.71), (45.41, PEN_DOWN_Z, -122.94), (45.29, PEN_DOWN_Z, -123.06), (45.29, PEN_DOWN_Z, -123.29), (45.18, PEN_DOWN_Z, -123.41), (45.18, PEN_DOWN_Z, -123.53), (45.06, PEN_DOWN_Z, -123.65), (45.06, PEN_DOWN_Z, -123.76), (44.94, PEN_DOWN_Z, -123.88), (44.94, PEN_DOWN_Z, -124.0), (44.82, PEN_DOWN_Z, -124.12), (44.82, PEN_DOWN_Z, -124.24), (44.71, PEN_DOWN_Z, -124.35), (44.71, PEN_DOWN_Z, -124.47), (44.59, PEN_DOWN_Z, -124.59), (44.59, PEN_DOWN_Z, -124.71), (44.71, PEN_DOWN_Z, -124.82), (44.82, PEN_DOWN_Z, -124.82), (44.94, PEN_DOWN_Z, -124.71), (44.94, PEN_DOWN_Z, -124.59), (45.06, PEN_DOWN_Z, -124.47), (45.06, PEN_DOWN_Z, -124.35), (45.18, PEN_DOWN_Z, -124.24), (45.18, PEN_DOWN_Z, -124.12), (45.29, PEN_DOWN_Z, -124.0), (45.29, PEN_DOWN_Z, -123.88), (45.41, PEN_DOWN_Z, -123.76), (45.41, PEN_DOWN_Z, -123.65), (45.53, PEN_DOWN_Z, -123.53), (45.53, PEN_DOWN_Z, -123.41), (45.65, PEN_DOWN_Z, -123.29), (45.65, PEN_DOWN_Z, -123.18), (45.76, PEN_DOWN_Z, -123.06), (45.76, PEN_DOWN_Z, -122.94), (45.88, PEN_DOWN_Z, -122.82), (45.88, PEN_DOWN_Z, -122.71), (46.0, PEN_DOWN_Z, -122.59), (46.0, PEN_DOWN_Z, -122.35), (46.12, PEN_DOWN_Z, -122.24), (46.12, PEN_DOWN_Z, -122.12), (46.35, PEN_DOWN_Z, -121.88), (46.35, PEN_DOWN_Z, -121.76), (46.59, PEN_DOWN_Z, -121.53), (46.59, PEN_DOWN_Z, -121.41), (46.71, PEN_DOWN_Z, -121.29), (46.71, PEN_DOWN_Z, -121.18), (47.06, PEN_DOWN_Z, -121.18), (47.06, PEN_DOWN_Z, -121.29), (47.41, PEN_DOWN_Z, -121.65), (47.53, PEN_DOWN_Z, -121.65), (47.88, PEN_DOWN_Z, -122.0), (48.0, PEN_DOWN_Z, -122.0), (48.12, PEN_DOWN_Z, -122.12), (48.24, PEN_DOWN_Z, -122.12), (48.35, PEN_DOWN_Z, -122.24), (48.47, PEN_DOWN_Z, -122.24), (48.59, PEN_DOWN_Z, -122.35), (48.71, PEN_DOWN_Z, -122.35), (48.94, PEN_DOWN_Z, -122.59), (49.41, PEN_DOWN_Z, -122.59), (49.53, PEN_DOWN_Z, -122.71), (50.82, PEN_DOWN_Z, -122.71), (50.94, PEN_DOWN_Z, -122.59), (51.29, PEN_DOWN_Z, -122.59), (51.41, PEN_DOWN_Z, -122.47), (51.65, PEN_DOWN_Z, -122.47), (51.76, PEN_DOWN_Z, -122.35), (51.88, PEN_DOWN_Z, -122.35), (52.0, PEN_DOWN_Z, -122.24), (52.12, PEN_DOWN_Z, -122.24), (52.24, PEN_DOWN_Z, -122.12), (52.35, PEN_DOWN_Z, -122.12), (52.47, PEN_DOWN_Z, -122.0), (52.59, PEN_DOWN_Z, -122.0), (52.71, PEN_DOWN_Z, -121.88), (52.82, PEN_DOWN_Z, -121.88), (53.06, PEN_DOWN_Z, -121.65), (53.18, PEN_DOWN_Z, -121.65), (53.41, PEN_DOWN_Z, -121.41), (53.53, PEN_DOWN_Z, -121.41), (53.88, PEN_DOWN_Z, -121.06), (54.0, PEN_DOWN_Z, -121.06), (55.18, PEN_DOWN_Z, -119.88), (55.41, PEN_DOWN_Z, -119.88), (55.76, PEN_DOWN_Z, -120.24), (55.88, PEN_DOWN_Z, -120.24), (56.0, PEN_DOWN_Z, -120.12), (56.12, PEN_DOWN_Z, -120.12), (56.71, PEN_DOWN_Z, -119.53), (56.71, PEN_DOWN_Z, -119.41), (56.94, PEN_DOWN_Z, -119.18), (56.94, PEN_DOWN_Z, -119.06), (57.06, PEN_DOWN_Z, -118.94), (57.29, PEN_DOWN_Z, -118.94), (57.41, PEN_DOWN_Z, -119.06), (57.88, PEN_DOWN_Z, -119.06), (58.0, PEN_DOWN_Z, -119.18), (59.18, PEN_DOWN_Z, -119.18), (59.18, PEN_DOWN_Z, -119.41), (59.06, PEN_DOWN_Z, -119.53), (59.06, PEN_DOWN_Z, -119.65), (58.82, PEN_DOWN_Z, -119.88), (58.82, PEN_DOWN_Z, -120.0), (58.71, PEN_DOWN_Z, -120.12), (58.71, PEN_DOWN_Z, -120.24), (58.82, PEN_DOWN_Z, -120.35), (58.94, PEN_DOWN_Z, -120.35), (59.06, PEN_DOWN_Z, -120.24), (59.06, PEN_DOWN_Z, -120.12), (59.18, PEN_DOWN_Z, -120.24), (59.29, PEN_DOWN_Z, -120.12), (59.41, PEN_DOWN_Z, -120.12), (59.53, PEN_DOWN_Z, -120.24), (59.76, PEN_DOWN_Z, -120.24), (59.88, PEN_DOWN_Z, -120.12), (60.24, PEN_DOWN_Z, -120.12), (60.35, PEN_DOWN_Z, -120.0), (60.82, PEN_DOWN_Z, -120.0), (60.94, PEN_DOWN_Z, -119.88), (61.18, PEN_DOWN_Z, -119.88), (61.29, PEN_DOWN_Z, -119.76), (61.41, PEN_DOWN_Z, -119.76), (61.53, PEN_DOWN_Z, -119.65), (61.76, PEN_DOWN_Z, -119.65), (61.88, PEN_DOWN_Z, -119.53), (62.0, PEN_DOWN_Z, -119.53), (62.12, PEN_DOWN_Z, -119.41), (62.35, PEN_DOWN_Z, -119.41), (62.59, PEN_DOWN_Z, -119.18), (62.94, PEN_DOWN_Z, -119.18), (62.94, PEN_DOWN_Z, -119.41), (62.82, PEN_DOWN_Z, -119.53), (62.82, PEN_DOWN_Z, -119.88), (63.18, PEN_DOWN_Z, -120.24), (63.41, PEN_DOWN_Z, -120.24), (64.24, PEN_DOWN_Z, -119.41), (64.24, PEN_DOWN_Z, -119.29), (64.35, PEN_DOWN_Z, -119.18), (64.35, PEN_DOWN_Z, -119.06), (64.47, PEN_DOWN_Z, -118.94), (64.71, PEN_DOWN_Z, -118.94), (64.82, PEN_DOWN_Z, -119.06), (65.29, PEN_DOWN_Z, -119.06), (65.41, PEN_DOWN_Z, -119.18), (66.59, PEN_DOWN_Z, -119.18), (66.59, PEN_DOWN_Z, -119.41), (66.35, PEN_DOWN_Z, -119.65), (66.35, PEN_DOWN_Z, -119.76), (66.24, PEN_DOWN_Z, -119.88), (66.24, PEN_DOWN_Z, -120.0), (66.0, PEN_DOWN_Z, -120.24), (66.0, PEN_DOWN_Z, -120.47), (65.88, PEN_DOWN_Z, -120.59), (65.88, PEN_DOWN_Z, -120.94), (66.24, PEN_DOWN_Z, -121.29), (66.71, PEN_DOWN_Z, -121.29), (66.82, PEN_DOWN_Z, -121.18), (67.06, PEN_DOWN_Z, -121.18), (67.18, PEN_DOWN_Z, -121.06), (67.41, PEN_DOWN_Z, -121.06), (67.65, PEN_DOWN_Z, -120.82), (67.76, PEN_DOWN_Z, -120.82), (67.88, PEN_DOWN_Z, -120.71), (68.0, PEN_DOWN_Z, -120.71), (68.12, PEN_DOWN_Z, -120.59), (68.24, PEN_DOWN_Z, -120.59), (68.35, PEN_DOWN_Z, -120.47), (68.47, PEN_DOWN_Z, -120.47), (68.71, PEN_DOWN_Z, -120.24), (68.82, PEN_DOWN_Z, -120.24), (68.94, PEN_DOWN_Z, -120.12), (69.06, PEN_DOWN_Z, -120.12), (69.18, PEN_DOWN_Z, -120.0), (69.29, PEN_DOWN_Z, -120.0), (69.53, PEN_DOWN_Z, -119.76), (69.65, PEN_DOWN_Z, -119.76), (70.0, PEN_DOWN_Z, -119.41), (70.12, PEN_DOWN_Z, -119.41), (70.35, PEN_DOWN_Z, -119.18), (70.47, PEN_DOWN_Z, -119.18), (70.59, PEN_DOWN_Z, -119.06), (70.71, PEN_DOWN_Z, -119.18), (70.71, PEN_DOWN_Z, -119.53), (70.82, PEN_DOWN_Z, -119.65), (70.82, PEN_DOWN_Z, -119.76), (70.94, PEN_DOWN_Z, -119.88), (71.06, PEN_DOWN_Z, -119.88), (71.18, PEN_DOWN_Z, -120.0), (71.76, PEN_DOWN_Z, -120.0), (71.88, PEN_DOWN_Z, -119.88), (72.24, PEN_DOWN_Z, -119.88), (72.35, PEN_DOWN_Z, -119.76), (72.59, PEN_DOWN_Z, -119.76), (72.71, PEN_DOWN_Z, -119.65), (72.82, PEN_DOWN_Z, -119.65), (72.94, PEN_DOWN_Z, -119.53), (73.06, PEN_DOWN_Z, -119.53), (73.18, PEN_DOWN_Z, -119.41), (73.29, PEN_DOWN_Z, -119.41), (73.41, PEN_DOWN_Z, -119.29), (73.65, PEN_DOWN_Z, -119.29), (73.76, PEN_DOWN_Z, -119.18), (73.76, PEN_DOWN_Z, -119.76), (73.65, PEN_DOWN_Z, -119.88), (73.65, PEN_DOWN_Z, -120.35), (73.53, PEN_DOWN_Z, -120.35), (73.29, PEN_DOWN_Z, -120.59), (73.18, PEN_DOWN_Z, -120.59), (73.06, PEN_DOWN_Z, -120.71), (73.06, PEN_DOWN_Z, -120.82), (73.29, PEN_DOWN_Z, -121.06), (73.41, PEN_DOWN_Z, -121.06), (73.88, PEN_DOWN_Z, -120.59), (73.88, PEN_DOWN_Z, -120.47), (74.0, PEN_DOWN_Z, -120.47), (74.12, PEN_DOWN_Z, -120.35), (74.24, PEN_DOWN_Z, -120.35), (74.35, PEN_DOWN_Z, -120.24), (74.47, PEN_DOWN_Z, -120.24), (74.59, PEN_DOWN_Z, -120.12), (74.71, PEN_DOWN_Z, -120.12), (74.82, PEN_DOWN_Z, -120.0), (75.06, PEN_DOWN_Z, -120.0), (75.18, PEN_DOWN_Z, -119.88), (75.29, PEN_DOWN_Z, -119.88), (75.41, PEN_DOWN_Z, -119.76), (75.53, PEN_DOWN_Z, -119.76), (75.65, PEN_DOWN_Z, -119.65), (75.76, PEN_DOWN_Z, -119.65), (75.88, PEN_DOWN_Z, -119.53), (76.12, PEN_DOWN_Z, -119.53), (76.24, PEN_DOWN_Z, -119.41), (76.35, PEN_DOWN_Z, -119.41), (76.47, PEN_DOWN_Z, -119.29), (76.59, PEN_DOWN_Z, -119.29), (76.71, PEN_DOWN_Z, -119.18), (76.94, PEN_DOWN_Z, -119.18), (76.94, PEN_DOWN_Z, -119.41), (76.71, PEN_DOWN_Z, -119.65), (76.71, PEN_DOWN_Z, -119.76), (76.59, PEN_DOWN_Z, -119.88), (76.59, PEN_DOWN_Z, -120.0), (76.35, PEN_DOWN_Z, -120.24), (76.35, PEN_DOWN_Z, -120.47), (76.24, PEN_DOWN_Z, -120.59), (76.24, PEN_DOWN_Z, -120.94), (76.59, PEN_DOWN_Z, -121.29), (77.06, PEN_DOWN_Z, -121.29), (77.18, PEN_DOWN_Z, -121.18), (77.41, PEN_DOWN_Z, -121.18), (77.53, PEN_DOWN_Z, -121.06), (77.76, PEN_DOWN_Z, -121.06), (78.0, PEN_DOWN_Z, -120.82), (78.12, PEN_DOWN_Z, -120.82), (78.24, PEN_DOWN_Z, -120.71), (78.35, PEN_DOWN_Z, -120.71), (78.47, PEN_DOWN_Z, -120.59), (78.59, PEN_DOWN_Z, -120.59), (78.71, PEN_DOWN_Z, -120.47), (78.82, PEN_DOWN_Z, -120.47), (79.06, PEN_DOWN_Z, -120.24), (79.18, PEN_DOWN_Z, -120.24), (79.29, PEN_DOWN_Z, -120.12), (79.41, PEN_DOWN_Z, -120.12), (79.53, PEN_DOWN_Z, -120.0), (79.65, PEN_DOWN_Z, -120.0), (79.88, PEN_DOWN_Z, -119.76), (80.0, PEN_DOWN_Z, -119.76), (80.35, PEN_DOWN_Z, -119.41), (80.47, PEN_DOWN_Z, -119.41), (80.71, PEN_DOWN_Z, -119.18), (80.82, PEN_DOWN_Z, -119.18), (81.06, PEN_DOWN_Z, -118.94), (81.18, PEN_DOWN_Z, -118.94), (81.41, PEN_DOWN_Z, -118.71), (81.41, PEN_DOWN_Z, -118.59), (81.29, PEN_DOWN_Z, -118.47), (81.18, PEN_DOWN_Z, -118.59), (81.06, PEN_DOWN_Z, -118.59), (80.82, PEN_DOWN_Z, -118.82), (80.71, PEN_DOWN_Z, -118.82), (80.47, PEN_DOWN_Z, -119.06), (80.35, PEN_DOWN_Z, -119.06), (80.12, PEN_DOWN_Z, -119.29), (80.0, PEN_DOWN_Z, -119.29), (79.76, PEN_DOWN_Z, -119.53), (79.65, PEN_DOWN_Z, -119.53), (79.41, PEN_DOWN_Z, -119.76), (79.29, PEN_DOWN_Z, -119.76), (79.18, PEN_DOWN_Z, -119.88), (79.06, PEN_DOWN_Z, -119.88), (78.82, PEN_DOWN_Z, -120.12), (78.71, PEN_DOWN_Z, -120.12), (78.59, PEN_DOWN_Z, -120.24), (78.47, PEN_DOWN_Z, -120.24), (78.24, PEN_DOWN_Z, -120.47), (78.12, PEN_DOWN_Z, -120.47), (78.0, PEN_DOWN_Z, -120.59), (77.88, PEN_DOWN_Z, -120.59), (77.76, PEN_DOWN_Z, -120.71), (77.41, PEN_DOWN_Z, -120.71), (77.29, PEN_DOWN_Z, -120.82), (77.06, PEN_DOWN_Z, -120.82), (76.94, PEN_DOWN_Z, -120.94), (76.59, PEN_DOWN_Z, -120.94), (76.59, PEN_DOWN_Z, -120.71), (76.71, PEN_DOWN_Z, -120.59), (76.71, PEN_DOWN_Z, -120.24), (76.82, PEN_DOWN_Z, -120.12), (76.82, PEN_DOWN_Z, -120.0), (77.06, PEN_DOWN_Z, -119.76), (77.06, PEN_DOWN_Z, -119.65), (77.18, PEN_DOWN_Z, -119.53), (77.18, PEN_DOWN_Z, -119.41), (77.29, PEN_DOWN_Z, -119.29), (77.29, PEN_DOWN_Z, -119.18), (77.53, PEN_DOWN_Z, -118.94), (77.53, PEN_DOWN_Z, -118.82), (77.65, PEN_DOWN_Z, -118.71), (77.41, PEN_DOWN_Z, -118.47), (77.29, PEN_DOWN_Z, -118.59), (77.18, PEN_DOWN_Z, -118.59), (77.06, PEN_DOWN_Z, -118.71), (76.94, PEN_DOWN_Z, -118.71), (76.82, PEN_DOWN_Z, -118.82), (76.71, PEN_DOWN_Z, -118.82), (76.59, PEN_DOWN_Z, -118.94), (76.47, PEN_DOWN_Z, -118.94), (76.35, PEN_DOWN_Z, -119.06), (76.24, PEN_DOWN_Z, -119.06), (76.12, PEN_DOWN_Z, -119.18), (76.0, PEN_DOWN_Z, -119.18), (75.88, PEN_DOWN_Z, -119.29), (75.65, PEN_DOWN_Z, -119.29), (75.53, PEN_DOWN_Z, -119.41), (75.41, PEN_DOWN_Z, -119.41), (75.29, PEN_DOWN_Z, -119.53), (75.18, PEN_DOWN_Z, -119.53), (75.06, PEN_DOWN_Z, -119.65), (74.94, PEN_DOWN_Z, -119.65), (74.82, PEN_DOWN_Z, -119.76), (74.71, PEN_DOWN_Z, -119.76), (74.59, PEN_DOWN_Z, -119.88), (74.35, PEN_DOWN_Z, -119.88), (74.24, PEN_DOWN_Z, -120.0), (74.12, PEN_DOWN_Z, -120.0), (74.12, PEN_DOWN_Z, -119.29), (74.24, PEN_DOWN_Z, -119.18), (74.24, PEN_DOWN_Z, -118.82), (74.35, PEN_DOWN_Z, -118.71), (74.35, PEN_DOWN_Z, -118.59), (74.47, PEN_DOWN_Z, -118.47), (74.47, PEN_DOWN_Z, -118.35), (74.71, PEN_DOWN_Z, -118.12), (74.94, PEN_DOWN_Z, -118.12), (74.94, PEN_DOWN_Z, -118.24), (75.18, PEN_DOWN_Z, -118.47), (75.41, PEN_DOWN_Z, -118.24), (75.41, PEN_DOWN_Z, -118.12), (75.06, PEN_DOWN_Z, -117.76), (74.71, PEN_DOWN_Z, -117.76), (74.47, PEN_DOWN_Z, -118.0), (74.35, PEN_DOWN_Z, -118.0), (74.24, PEN_DOWN_Z, -118.12), (74.24, PEN_DOWN_Z, -118.24), (74.12, PEN_DOWN_Z, -118.35), (74.12, PEN_DOWN_Z, -118.47), (74.0, PEN_DOWN_Z, -118.59), (74.0, PEN_DOWN_Z, -118.71), (73.88, PEN_DOWN_Z, -118.71), (73.65, PEN_DOWN_Z, -118.94), (73.53, PEN_DOWN_Z, -118.94), (73.41, PEN_DOWN_Z, -119.06), (73.29, PEN_DOWN_Z, -119.06), (73.18, PEN_DOWN_Z, -119.18), (72.94, PEN_DOWN_Z, -119.18), (72.82, PEN_DOWN_Z, -119.29), (72.71, PEN_DOWN_Z, -119.29), (72.59, PEN_DOWN_Z, -119.41), (72.24, PEN_DOWN_Z, -119.41), (72.12, PEN_DOWN_Z, -119.53), (71.88, PEN_DOWN_Z, -119.53), (71.76, PEN_DOWN_Z, -119.65), (71.18, PEN_DOWN_Z, -119.65), (71.06, PEN_DOWN_Z, -119.53), (71.06, PEN_DOWN_Z, -118.94), (71.18, PEN_DOWN_Z, -118.82), (71.18, PEN_DOWN_Z, -118.71), (71.29, PEN_DOWN_Z, -118.59), (71.29, PEN_DOWN_Z, -118.47), (71.41, PEN_DOWN_Z, -118.35), (71.41, PEN_DOWN_Z, -118.24), (71.29, PEN_DOWN_Z, -118.12), (70.71, PEN_DOWN_Z, -118.71), (70.59, PEN_DOWN_Z, -118.71), (70.47, PEN_DOWN_Z, -118.82), (70.35, PEN_DOWN_Z, -118.82), (70.12, PEN_DOWN_Z, -119.06), (70.0, PEN_DOWN_Z, -119.06), (69.76, PEN_DOWN_Z, -119.29), (69.65, PEN_DOWN_Z, -119.29), (69.41, PEN_DOWN_Z, -119.53), (69.29, PEN_DOWN_Z, -119.53), (69.06, PEN_DOWN_Z, -119.76), (68.94, PEN_DOWN_Z, -119.76), (68.82, PEN_DOWN_Z, -119.88), (68.71, PEN_DOWN_Z, -119.88), (68.47, PEN_DOWN_Z, -120.12), (68.35, PEN_DOWN_Z, -120.12), (68.24, PEN_DOWN_Z, -120.24), (68.12, PEN_DOWN_Z, -120.24), (67.88, PEN_DOWN_Z, -120.47), (67.76, PEN_DOWN_Z, -120.47), (67.65, PEN_DOWN_Z, -120.59), (67.53, PEN_DOWN_Z, -120.59), (67.41, PEN_DOWN_Z, -120.71), (67.06, PEN_DOWN_Z, -120.71), (66.94, PEN_DOWN_Z, -120.82), (66.71, PEN_DOWN_Z, -120.82), (66.59, PEN_DOWN_Z, -120.94), (66.24, PEN_DOWN_Z, -120.94), (66.24, PEN_DOWN_Z, -120.71), (66.35, PEN_DOWN_Z, -120.59), (66.35, PEN_DOWN_Z, -120.24), (66.47, PEN_DOWN_Z, -120.12), (66.47, PEN_DOWN_Z, -120.0), (66.71, PEN_DOWN_Z, -119.76), (66.71, PEN_DOWN_Z, -119.65), (66.82, PEN_DOWN_Z, -119.53), (66.82, PEN_DOWN_Z, -119.41), (66.94, PEN_DOWN_Z, -119.29), (66.94, PEN_DOWN_Z, -119.18), (67.18, PEN_DOWN_Z, -118.94), (67.18, PEN_DOWN_Z, -118.82), (67.41, PEN_DOWN_Z, -118.59), (67.41, PEN_DOWN_Z, -118.47), (67.76, PEN_DOWN_Z, -118.12), (67.76, PEN_DOWN_Z, -118.0), (67.88, PEN_DOWN_Z, -117.88), (67.88, PEN_DOWN_Z, -117.76), (68.24, PEN_DOWN_Z, -117.41), (68.24, PEN_DOWN_Z, -117.29), (68.47, PEN_DOWN_Z, -117.06), (68.47, PEN_DOWN_Z, -116.94), (68.59, PEN_DOWN_Z, -116.82), (70.24, PEN_DOWN_Z, -116.82), (70.35, PEN_DOWN_Z, -116.71), (70.35, PEN_DOWN_Z, -116.59), (70.24, PEN_DOWN_Z, -116.47), (69.06, PEN_DOWN_Z, -116.47), (69.06, PEN_DOWN_Z, -116.24), (69.29, PEN_DOWN_Z, -116.0), (69.29, PEN_DOWN_Z, -115.88), (69.53, PEN_DOWN_Z, -115.65), (69.41, PEN_DOWN_Z, -115.53), (69.29, PEN_DOWN_Z, -115.53), (68.94, PEN_DOWN_Z, -115.88), (68.94, PEN_DOWN_Z, -116.0), (68.71, PEN_DOWN_Z, -116.24), (68.71, PEN_DOWN_Z, -116.35), (68.59, PEN_DOWN_Z, -116.47), (67.29, PEN_DOWN_Z, -116.47), (67.18, PEN_DOWN_Z, -116.59), (67.18, PEN_DOWN_Z, -116.71), (67.29, PEN_DOWN_Z, -116.82), (68.12, PEN_DOWN_Z, -116.82), (68.12, PEN_DOWN_Z, -117.06), (67.88, PEN_DOWN_Z, -117.29), (67.88, PEN_DOWN_Z, -117.41), (67.65, PEN_DOWN_Z, -117.65), (67.65, PEN_DOWN_Z, -117.76), (67.41, PEN_DOWN_Z, -118.0), (67.41, PEN_DOWN_Z, -118.12), (67.06, PEN_DOWN_Z, -118.47), (67.06, PEN_DOWN_Z, -118.59), (66.94, PEN_DOWN_Z, -118.71), (66.71, PEN_DOWN_Z, -118.71), (66.59, PEN_DOWN_Z, -118.82), (65.41, PEN_DOWN_Z, -118.82), (65.29, PEN_DOWN_Z, -118.71), (64.71, PEN_DOWN_Z, -118.71), (64.59, PEN_DOWN_Z, -118.59), (64.59, PEN_DOWN_Z, -118.47), (64.35, PEN_DOWN_Z, -118.24), (63.88, PEN_DOWN_Z, -118.24), (63.76, PEN_DOWN_Z, -118.35), (63.53, PEN_DOWN_Z, -118.35), (63.29, PEN_DOWN_Z, -118.59), (63.18, PEN_DOWN_Z, -118.59), (63.06, PEN_DOWN_Z, -118.71), (62.94, PEN_DOWN_Z, -118.71), (62.82, PEN_DOWN_Z, -118.82), (62.71, PEN_DOWN_Z, -118.82), (62.59, PEN_DOWN_Z, -118.94), (62.47, PEN_DOWN_Z, -118.94), (62.35, PEN_DOWN_Z, -119.06), (62.24, PEN_DOWN_Z, -119.06), (62.12, PEN_DOWN_Z, -119.18), (62.0, PEN_DOWN_Z, -119.18), (61.88, PEN_DOWN_Z, -119.29), (61.53, PEN_DOWN_Z, -119.29), (61.41, PEN_DOWN_Z, -119.41), (61.29, PEN_DOWN_Z, -119.41), (61.18, PEN_DOWN_Z, -119.53), (60.94, PEN_DOWN_Z, -119.53), (60.82, PEN_DOWN_Z, -119.65), (60.35, PEN_DOWN_Z, -119.65), (60.24, PEN_DOWN_Z, -119.53), (60.12, PEN_DOWN_Z, -119.65), (60.0, PEN_DOWN_Z, -119.65), (59.88, PEN_DOWN_Z, -119.76), (59.76, PEN_DOWN_Z, -119.76), (59.65, PEN_DOWN_Z, -119.88), (59.41, PEN_DOWN_Z, -119.88), (59.29, PEN_DOWN_Z, -119.76), (59.18, PEN_DOWN_Z, -119.88), (59.29, PEN_DOWN_Z, -119.76), (59.29, PEN_DOWN_Z, -119.65), (59.88, PEN_DOWN_Z, -119.06), (60.0, PEN_DOWN_Z, -119.06), (60.47, PEN_DOWN_Z, -118.59), (60.59, PEN_DOWN_Z, -118.59), (60.71, PEN_DOWN_Z, -118.47), (60.82, PEN_DOWN_Z, -118.59), (60.82, PEN_DOWN_Z, -118.71), (60.71, PEN_DOWN_Z, -118.82), (60.71, PEN_DOWN_Z, -118.94), (60.59, PEN_DOWN_Z, -119.06), (60.59, PEN_DOWN_Z, -119.18), (60.24, PEN_DOWN_Z, -119.53), (60.35, PEN_DOWN_Z, -119.65), (60.47, PEN_DOWN_Z, -119.65), (60.82, PEN_DOWN_Z, -119.29), (60.82, PEN_DOWN_Z, -119.18), (61.06, PEN_DOWN_Z, -118.94), (61.06, PEN_DOWN_Z, -118.82), (61.18, PEN_DOWN_Z, -118.71), (61.18, PEN_DOWN_Z, -118.35), (60.94, PEN_DOWN_Z, -118.12), (60.71, PEN_DOWN_Z, -118.12), (60.47, PEN_DOWN_Z, -118.35), (60.35, PEN_DOWN_Z, -118.35), (60.12, PEN_DOWN_Z, -118.59), (60.0, PEN_DOWN_Z, -118.59), (60.0, PEN_DOWN_Z, -118.35), (60.12, PEN_DOWN_Z, -118.24), (60.12, PEN_DOWN_Z, -118.12), (60.24, PEN_DOWN_Z, -118.0), (60.24, PEN_DOWN_Z, -117.88), (60.35, PEN_DOWN_Z, -117.76), (60.35, PEN_DOWN_Z, -117.65), (60.59, PEN_DOWN_Z, -117.41), (60.59, PEN_DOWN_Z, -117.29), (60.71, PEN_DOWN_Z, -117.18), (60.71, PEN_DOWN_Z, -117.06), (60.82, PEN_DOWN_Z, -116.94), (60.82, PEN_DOWN_Z, -116.82), (60.94, PEN_DOWN_Z, -116.71), (60.94, PEN_DOWN_Z, -116.59), (61.18, PEN_DOWN_Z, -116.35), (61.18, PEN_DOWN_Z, -116.24), (61.29, PEN_DOWN_Z, -116.12), (61.29, PEN_DOWN_Z, -116.0), (61.53, PEN_DOWN_Z, -115.76), (61.53, PEN_DOWN_Z, -115.65), (61.76, PEN_DOWN_Z, -115.41), (61.76, PEN_DOWN_Z, -115.29), (62.0, PEN_DOWN_Z, -115.06), (61.76, PEN_DOWN_Z, -114.82), (61.65, PEN_DOWN_Z, -114.94), (61.65, PEN_DOWN_Z, -115.06), (61.41, PEN_DOWN_Z, -115.29), (61.41, PEN_DOWN_Z, -115.41), (61.18, PEN_DOWN_Z, -115.65), (61.18, PEN_DOWN_Z, -115.76), (60.94, PEN_DOWN_Z, -116.0), (60.94, PEN_DOWN_Z, -116.12), (60.82, PEN_DOWN_Z, -116.24), (60.82, PEN_DOWN_Z, -116.35), (60.71, PEN_DOWN_Z, -116.47), (60.71, PEN_DOWN_Z, -116.59), (60.59, PEN_DOWN_Z, -116.71), (60.59, PEN_DOWN_Z, -116.82), (60.35, PEN_DOWN_Z, -117.06), (60.35, PEN_DOWN_Z, -117.18), (60.24, PEN_DOWN_Z, -117.29), (60.24, PEN_DOWN_Z, -117.41), (60.12, PEN_DOWN_Z, -117.53), (60.12, PEN_DOWN_Z, -117.65), (59.88, PEN_DOWN_Z, -117.88), (59.88, PEN_DOWN_Z, -118.0), (59.76, PEN_DOWN_Z, -118.12), (59.76, PEN_DOWN_Z, -118.24), (59.65, PEN_DOWN_Z, -118.35), (59.65, PEN_DOWN_Z, -118.47), (59.53, PEN_DOWN_Z, -118.59), (59.53, PEN_DOWN_Z, -118.71), (59.29, PEN_DOWN_Z, -118.71), (59.18, PEN_DOWN_Z, -118.82), (58.0, PEN_DOWN_Z, -118.82), (57.88, PEN_DOWN_Z, -118.71), (57.29, PEN_DOWN_Z, -118.71), (57.18, PEN_DOWN_Z, -118.59), (57.18, PEN_DOWN_Z, -118.47), (56.94, PEN_DOWN_Z, -118.24), (56.47, PEN_DOWN_Z, -118.24), (56.35, PEN_DOWN_Z, -118.35), (56.24, PEN_DOWN_Z, -118.35), (55.65, PEN_DOWN_Z, -118.94), (55.65, PEN_DOWN_Z, -119.06), (54.47, PEN_DOWN_Z, -120.24), (54.35, PEN_DOWN_Z, -120.24), (53.65, PEN_DOWN_Z, -120.94), (53.53, PEN_DOWN_Z, -120.94), (53.18, PEN_DOWN_Z, -121.29), (53.06, PEN_DOWN_Z, -121.29), (52.82, PEN_DOWN_Z, -121.53), (52.71, PEN_DOWN_Z, -121.53), (52.47, PEN_DOWN_Z, -121.76), (52.35, PEN_DOWN_Z, -121.76), (52.24, PEN_DOWN_Z, -121.88), (52.12, PEN_DOWN_Z, -121.88), (52.0, PEN_DOWN_Z, -122.0), (51.76, PEN_DOWN_Z, -122.0), (51.65, PEN_DOWN_Z, -122.12), (51.41, PEN_DOWN_Z, -122.12), (51.29, PEN_DOWN_Z, -122.24), (50.82, PEN_DOWN_Z, -122.24), (50.71, PEN_DOWN_Z, -122.35), (49.53, PEN_DOWN_Z, -122.35), (49.41, PEN_DOWN_Z, -122.24), (48.94, PEN_DOWN_Z, -122.24), (48.82, PEN_DOWN_Z, -122.12), (48.71, PEN_DOWN_Z, -122.12), (48.59, PEN_DOWN_Z, -122.0), (48.47, PEN_DOWN_Z, -122.0), (48.35, PEN_DOWN_Z, -121.88), (48.24, PEN_DOWN_Z, -121.88), (48.0, PEN_DOWN_Z, -121.65), (47.88, PEN_DOWN_Z, -121.65), (47.18, PEN_DOWN_Z, -120.94), (47.18, PEN_DOWN_Z, -120.47), (47.29, PEN_DOWN_Z, -120.35), (47.29, PEN_DOWN_Z, -120.24), (47.41, PEN_DOWN_Z, -120.12), (47.41, PEN_DOWN_Z, -120.0), (47.65, PEN_DOWN_Z, -119.76), (47.65, PEN_DOWN_Z, -119.65), (47.76, PEN_DOWN_Z, -119.53), (47.76, PEN_DOWN_Z, -119.41), (47.88, PEN_DOWN_Z, -119.29), (47.88, PEN_DOWN_Z, -119.18), (48.0, PEN_DOWN_Z, -119.06), (48.12, PEN_DOWN_Z, -119.06), (48.24, PEN_DOWN_Z, -118.94), (48.24, PEN_DOWN_Z, -118.82), (48.35, PEN_DOWN_Z, -118.71), (48.35, PEN_DOWN_Z, -118.35), (48.59, PEN_DOWN_Z, -118.12), (48.59, PEN_DOWN_Z, -118.0), (48.82, PEN_DOWN_Z, -117.76), (48.82, PEN_DOWN_Z, -117.65), (48.94, PEN_DOWN_Z, -117.53), (48.94, PEN_DOWN_Z, -117.41), (49.18, PEN_DOWN_Z, -117.18), (49.18, PEN_DOWN_Z, -117.06), (49.29, PEN_DOWN_Z, -116.94), (49.29, PEN_DOWN_Z, -116.82), (49.53, PEN_DOWN_Z, -116.59), (49.53, PEN_DOWN_Z, -116.47), (49.76, PEN_DOWN_Z, -116.24), (49.76, PEN_DOWN_Z, -116.12), (49.88, PEN_DOWN_Z, -116.0), (49.88, PEN_DOWN_Z, -115.88), (50.0, PEN_DOWN_Z, -115.76), (50.0, PEN_DOWN_Z, -115.65), (50.24, PEN_DOWN_Z, -115.41), (50.24, PEN_DOWN_Z, -115.29), (50.47, PEN_DOWN_Z, -115.06), (50.47, PEN_DOWN_Z, -114.94), (50.59, PEN_DOWN_Z, -114.82), (50.59, PEN_DOWN_Z, -114.71), (50.82, PEN_DOWN_Z, -114.47), (50.82, PEN_DOWN_Z, -114.35), (50.94, PEN_DOWN_Z, -114.24), (50.94, PEN_DOWN_Z, -114.12), (51.18, PEN_DOWN_Z, -113.88), (51.18, PEN_DOWN_Z, -113.76), (51.29, PEN_DOWN_Z, -113.65), (51.29, PEN_DOWN_Z, -113.53), (51.41, PEN_DOWN_Z, -113.41), (51.53, PEN_DOWN_Z, -113.41), (51.65, PEN_DOWN_Z, -113.29), (52.82, PEN_DOWN_Z, -113.29), (52.94, PEN_DOWN_Z, -113.41), (53.06, PEN_DOWN_Z, -113.41), (53.18, PEN_DOWN_Z, -113.53), (53.29, PEN_DOWN_Z, -113.53), (53.29, PEN_DOWN_Z, -113.65), (53.53, PEN_DOWN_Z, -113.88), (53.53, PEN_DOWN_Z, -114.94), (53.41, PEN_DOWN_Z, -115.06), (53.41, PEN_DOWN_Z, -115.53), (53.29, PEN_DOWN_Z, -115.65), (53.29, PEN_DOWN_Z, -115.76), (53.18, PEN_DOWN_Z, -115.88), (53.18, PEN_DOWN_Z, -116.0), (52.94, PEN_DOWN_Z, -116.24), (52.94, PEN_DOWN_Z, -116.35), (52.12, PEN_DOWN_Z, -117.18), (52.0, PEN_DOWN_Z, -117.18), (51.65, PEN_DOWN_Z, -117.53), (51.53, PEN_DOWN_Z, -117.53), (51.41, PEN_DOWN_Z, -117.65), (51.29, PEN_DOWN_Z, -117.65), (51.06, PEN_DOWN_Z, -117.88), (50.94, PEN_DOWN_Z, -117.88), (50.82, PEN_DOWN_Z, -118.0), (50.59, PEN_DOWN_Z, -118.0), (50.47, PEN_DOWN_Z, -118.12), (50.24, PEN_DOWN_Z, -118.12), (50.12, PEN_DOWN_Z, -118.24), (50.0, PEN_DOWN_Z, -118.24), (49.88, PEN_DOWN_Z, -118.35), (49.65, PEN_DOWN_Z, -118.35), (49.53, PEN_DOWN_Z, -118.47), (49.18, PEN_DOWN_Z, -118.47), (49.06, PEN_DOWN_Z, -118.59), (48.71, PEN_DOWN_Z, -118.59), (48.59, PEN_DOWN_Z, -118.71), (48.71, PEN_DOWN_Z, -118.59), (49.06, PEN_DOWN_Z, -118.59), (49.18, PEN_DOWN_Z, -118.47), (49.53, PEN_DOWN_Z, -118.47), (49.65, PEN_DOWN_Z, -118.35), (49.76, PEN_DOWN_Z, -118.35), (49.88, PEN_DOWN_Z, -118.24), (50.12, PEN_DOWN_Z, -118.24), (50.24, PEN_DOWN_Z, -118.12), (50.47, PEN_DOWN_Z, -118.12), (50.59, PEN_DOWN_Z, -118.0), (50.71, PEN_DOWN_Z, -118.0), (50.82, PEN_DOWN_Z, -117.88), (50.94, PEN_DOWN_Z, -117.88), (51.18, PEN_DOWN_Z, -117.65), (51.29, PEN_DOWN_Z, -117.65), (51.41, PEN_DOWN_Z, -117.53), (51.53, PEN_DOWN_Z, -117.53), (51.88, PEN_DOWN_Z, -117.18), (52.0, PEN_DOWN_Z, -117.18), (52.94, PEN_DOWN_Z, -116.24), (52.94, PEN_DOWN_Z, -116.12), (53.18, PEN_DOWN_Z, -115.88), (53.18, PEN_DOWN_Z, -115.76), (53.29, PEN_DOWN_Z, -115.65), (53.29, PEN_DOWN_Z, -115.53), (53.41, PEN_DOWN_Z, -115.41), (53.41, PEN_DOWN_Z, -115.06), (53.53, PEN_DOWN_Z, -114.94), (53.53, PEN_DOWN_Z, -114.0), (53.29, PEN_DOWN_Z, -113.76), (53.29, PEN_DOWN_Z, -113.65), (53.18, PEN_DOWN_Z, -113.53), (53.06, PEN_DOWN_Z, -113.53), (52.82, PEN_DOWN_Z, -113.29), (51.76, PEN_DOWN_Z, -113.29), (51.65, PEN_DOWN_Z, -113.41), (51.53, PEN_DOWN_Z, -113.41), (51.29, PEN_DOWN_Z, -113.65), (51.29, PEN_DOWN_Z, -113.76), (51.18, PEN_DOWN_Z, -113.88), (51.18, PEN_DOWN_Z, -114.0), (50.94, PEN_DOWN_Z, -114.24), (50.94, PEN_DOWN_Z, -114.35), (50.82, PEN_DOWN_Z, -114.47), (50.82, PEN_DOWN_Z, -114.59), (50.59, PEN_DOWN_Z, -114.82), (50.59, PEN_DOWN_Z, -114.94), (50.47, PEN_DOWN_Z, -115.06), (50.47, PEN_DOWN_Z, -115.18), (50.24, PEN_DOWN_Z, -115.41), (50.24, PEN_DOWN_Z, -115.53), (50.0, PEN_DOWN_Z, -115.76), (50.0, PEN_DOWN_Z, -115.88), (49.88, PEN_DOWN_Z, -116.0), (49.88, PEN_DOWN_Z, -116.12), (49.76, PEN_DOWN_Z, -116.24), (49.76, PEN_DOWN_Z, -116.35), (49.53, PEN_DOWN_Z, -116.59), (49.53, PEN_DOWN_Z, -116.71), (49.29, PEN_DOWN_Z, -116.94), (49.29, PEN_DOWN_Z, -117.06), (49.18, PEN_DOWN_Z, -117.18), (49.18, PEN_DOWN_Z, -117.29), (48.94, PEN_DOWN_Z, -117.53), (48.94, PEN_DOWN_Z, -117.65), (48.82, PEN_DOWN_Z, -117.76), (48.82, PEN_DOWN_Z, -117.88), (48.59, PEN_DOWN_Z, -118.12), (48.59, PEN_DOWN_Z, -118.24), (48.35, PEN_DOWN_Z, -118.47), (48.35, PEN_DOWN_Z, -118.71), (48.24, PEN_DOWN_Z, -118.82), (48.35, PEN_DOWN_Z, -118.94), (49.06, PEN_DOWN_Z, -118.94), (49.18, PEN_DOWN_Z, -118.82), (49.41, PEN_DOWN_Z, -118.82), (49.53, PEN_DOWN_Z, -118.71), (49.88, PEN_DOWN_Z, -118.71), (50.0, PEN_DOWN_Z, -118.59), (50.24, PEN_DOWN_Z, -118.59), (50.47, PEN_DOWN_Z, -118.35), (50.71, PEN_DOWN_Z, -118.35), (50.82, PEN_DOWN_Z, -118.24), (51.06, PEN_DOWN_Z, -118.24), (51.29, PEN_DOWN_Z, -118.0), (51.41, PEN_DOWN_Z, -118.0), (51.65, PEN_DOWN_Z, -117.76), (51.76, PEN_DOWN_Z, -117.76), (51.88, PEN_DOWN_Z, -117.65), (52.0, PEN_DOWN_Z, -117.65), (52.35, PEN_DOWN_Z, -117.29), (52.47, PEN_DOWN_Z, -117.29), (53.06, PEN_DOWN_Z, -116.71), (53.06, PEN_DOWN_Z, -116.59), (53.29, PEN_DOWN_Z, -116.35), (53.29, PEN_DOWN_Z, -116.24), (53.41, PEN_DOWN_Z, -116.12), (53.41, PEN_DOWN_Z, -116.0), (53.53, PEN_DOWN_Z, -115.88), (53.53, PEN_DOWN_Z, -115.76), (53.76, PEN_DOWN_Z, -115.53), (53.76, PEN_DOWN_Z, -115.18), (53.88, PEN_DOWN_Z, -115.06), (53.88, PEN_DOWN_Z, -114.0), (53.76, PEN_DOWN_Z, -113.88), (53.76, PEN_DOWN_Z, -113.76), (53.65, PEN_DOWN_Z, -113.65), (53.65, PEN_DOWN_Z, -113.53), (53.29, PEN_DOWN_Z, -113.18), (53.18, PEN_DOWN_Z, -113.18), (53.06, PEN_DOWN_Z, -113.06), (52.94, PEN_DOWN_Z, -113.06), (52.82, PEN_DOWN_Z, -112.94), (51.76, PEN_DOWN_Z, -112.94), (51.88, PEN_DOWN_Z, -112.82), (51.88, PEN_DOWN_Z, -112.59), (52.12, PEN_DOWN_Z, -112.35), (52.12, PEN_DOWN_Z, -112.12), (52.0, PEN_DOWN_Z, -112.0), (51.88, PEN_DOWN_Z, -112.12), (51.88, -15.0, -112.12), (51.88, -15.0, -112.0), (51.88, PEN_DOWN_Z, -112.0), (51.88, PEN_DOWN_Z, -112.12), (51.65, PEN_DOWN_Z, -112.35), (51.65, PEN_DOWN_Z, -112.47), (51.53, PEN_DOWN_Z, -112.59), (51.53, PEN_DOWN_Z, -112.71), (51.29, PEN_DOWN_Z, -112.94), (51.29, PEN_DOWN_Z, -113.06), (51.18, PEN_DOWN_Z, -113.18), (51.06, PEN_DOWN_Z, -113.18), (50.94, PEN_DOWN_Z, -113.29), (50.71, PEN_DOWN_Z, -113.29), (50.59, PEN_DOWN_Z, -113.41), (50.35, PEN_DOWN_Z, -113.41), (50.24, PEN_DOWN_Z, -113.53), (50.12, PEN_DOWN_Z, -113.53), (49.88, PEN_DOWN_Z, -113.76), (49.76, PEN_DOWN_Z, -113.76), (49.53, PEN_DOWN_Z, -114.0), (49.41, PEN_DOWN_Z, -114.0), (48.24, PEN_DOWN_Z, -115.18), (48.24, PEN_DOWN_Z, -115.29), (48.12, PEN_DOWN_Z, -115.41), (48.12, PEN_DOWN_Z, -115.53), (47.88, PEN_DOWN_Z, -115.76), (47.88, PEN_DOWN_Z, -116.0), (47.76, PEN_DOWN_Z, -116.12), (47.76, PEN_DOWN_Z, -116.24), (47.65, PEN_DOWN_Z, -116.35), (47.65, PEN_DOWN_Z, -116.47), (47.53, PEN_DOWN_Z, -116.59), (47.53, PEN_DOWN_Z, -116.71), (47.41, PEN_DOWN_Z, -116.82), (47.41, PEN_DOWN_Z, -117.06), (47.29, PEN_DOWN_Z, -117.18), (47.29, PEN_DOWN_Z, -117.29), (47.18, PEN_DOWN_Z, -117.41), (47.18, PEN_DOWN_Z, -117.65), (47.06, PEN_DOWN_Z, -117.76), (47.06, PEN_DOWN_Z, -118.0), (46.94, PEN_DOWN_Z, -118.12), (46.94, PEN_DOWN_Z, -118.35), (46.82, PEN_DOWN_Z, -118.47), (46.82, PEN_DOWN_Z, -118.59), (46.71, PEN_DOWN_Z, -118.71), (46.47, PEN_DOWN_Z, -118.71), (46.35, PEN_DOWN_Z, -118.59), (46.12, PEN_DOWN_Z, -118.59), (46.0, PEN_DOWN_Z, -118.47), (45.88, PEN_DOWN_Z, -118.47), (45.76, PEN_DOWN_Z, -118.35), (45.76, PEN_DOWN_Z, -118.24), (45.65, PEN_DOWN_Z, -118.12), (45.65, PEN_DOWN_Z, -118.0), (45.29, PEN_DOWN_Z, -118.0), (45.29, PEN_DOWN_Z, -118.35), (45.41, PEN_DOWN_Z, -118.47), (45.41, PEN_DOWN_Z, -118.59), (45.53, PEN_DOWN_Z, -118.71), (45.53, PEN_DOWN_Z, -118.94), (45.65, PEN_DOWN_Z, -119.06), (45.65, PEN_DOWN_Z, -119.18), (45.76, PEN_DOWN_Z, -119.29), (45.76, PEN_DOWN_Z, -119.53), (45.88, PEN_DOWN_Z, -119.65), (45.88, PEN_DOWN_Z, -119.76), (46.12, PEN_DOWN_Z, -120.0), (46.12, PEN_DOWN_Z, -120.12), (46.24, PEN_DOWN_Z, -120.24), (46.24, PEN_DOWN_Z, -120.47), (46.12, PEN_DOWN_Z, -120.59), (46.12, PEN_DOWN_Z, -120.71), (46.0, PEN_DOWN_Z, -120.82), (46.0, PEN_DOWN_Z, -121.06), (45.88, PEN_DOWN_Z, -121.18), (45.88, PEN_DOWN_Z, -121.53), (45.76, PEN_DOWN_Z, -121.65), (45.76, PEN_DOWN_Z, -122.0), (45.65, PEN_DOWN_Z, -122.12), (45.65, PEN_DOWN_Z, -122.24), (45.53, PEN_DOWN_Z, -122.35), (45.53, PEN_DOWN_Z, -122.59), (45.41, PEN_DOWN_Z, -122.71), (45.41, PEN_DOWN_Z, -122.94), (45.29, PEN_DOWN_Z, -123.06), (45.29, PEN_DOWN_Z, -123.18), (45.18, PEN_DOWN_Z, -123.29), (45.18, PEN_DOWN_Z, -123.41), (45.06, PEN_DOWN_Z, -123.53), (45.06, PEN_DOWN_Z, -123.65), (44.94, PEN_DOWN_Z, -123.76), (44.94, PEN_DOWN_Z, -123.88), (44.82, PEN_DOWN_Z, -124.0), (44.82, PEN_DOWN_Z, -124.12), (44.71, PEN_DOWN_Z, -124.24), (44.71, PEN_DOWN_Z, -124.47), (44.59, PEN_DOWN_Z, -124.59), (44.59, PEN_DOWN_Z, -124.82), (44.94, PEN_DOWN_Z, -124.82), (44.94, PEN_DOWN_Z, -124.71), (45.06, PEN_DOWN_Z, -124.59), (45.06, PEN_DOWN_Z, -124.47), (45.18, PEN_DOWN_Z, -124.35), (45.18, PEN_DOWN_Z, -124.24), (45.29, PEN_DOWN_Z, -124.12), (45.29, PEN_DOWN_Z, -124.0), (45.41, PEN_DOWN_Z, -123.88), (45.41, PEN_DOWN_Z, -123.76), (45.53, PEN_DOWN_Z, -123.65), (45.53, PEN_DOWN_Z, -123.53), (45.65, PEN_DOWN_Z, -123.41), (45.65, PEN_DOWN_Z, -123.29), (45.76, PEN_DOWN_Z, -123.18), (45.76, PEN_DOWN_Z, -123.06), (45.88, PEN_DOWN_Z, -122.94), (45.88, PEN_DOWN_Z, -122.82), (46.0, PEN_DOWN_Z, -122.71), (46.0, PEN_DOWN_Z, -122.47), (46.12, PEN_DOWN_Z, -122.35), (46.12, PEN_DOWN_Z, -122.24), (46.35, PEN_DOWN_Z, -122.0), (46.35, PEN_DOWN_Z, -121.88), (46.59, PEN_DOWN_Z, -121.65), (46.59, PEN_DOWN_Z, -121.53), (46.71, PEN_DOWN_Z, -121.41), (46.71, PEN_DOWN_Z, -121.29), (46.82, PEN_DOWN_Z, -121.18), (46.94, PEN_DOWN_Z, -121.18), (47.06, PEN_DOWN_Z, -121.29), (47.06, PEN_DOWN_Z, -121.41), (47.29, PEN_DOWN_Z, -121.65), (47.41, PEN_DOWN_Z, -121.65), (47.76, PEN_DOWN_Z, -122.0), (47.88, PEN_DOWN_Z, -122.0), (48.0, PEN_DOWN_Z, -122.12), (48.12, PEN_DOWN_Z, -122.12), (48.24, PEN_DOWN_Z, -122.24), (48.35, PEN_DOWN_Z, -122.24), (48.47, PEN_DOWN_Z, -122.35), (48.59, PEN_DOWN_Z, -122.35), (48.71, PEN_DOWN_Z, -122.47), (48.82, PEN_DOWN_Z, -122.47), (48.94, PEN_DOWN_Z, -122.59), (49.41, PEN_DOWN_Z, -122.59), (49.53, PEN_DOWN_Z, -122.71), (50.82, PEN_DOWN_Z, -122.71), (50.94, PEN_DOWN_Z, -122.59), (51.29, PEN_DOWN_Z, -122.59), (51.41, PEN_DOWN_Z, -122.47), (51.65, PEN_DOWN_Z, -122.47), (51.76, PEN_DOWN_Z, -122.35), (52.0, PEN_DOWN_Z, -122.35), (52.12, PEN_DOWN_Z, -122.24), (52.24, PEN_DOWN_Z, -122.24), (52.35, PEN_DOWN_Z, -122.12), (52.47, PEN_DOWN_Z, -122.12), (52.59, PEN_DOWN_Z, -122.0), (52.71, PEN_DOWN_Z, -122.0), (52.82, PEN_DOWN_Z, -121.88), (52.94, PEN_DOWN_Z, -121.88), (53.18, PEN_DOWN_Z, -121.65), (53.29, PEN_DOWN_Z, -121.65), (53.53, PEN_DOWN_Z, -121.41), (53.65, PEN_DOWN_Z, -121.41), (54.0, PEN_DOWN_Z, -121.06), (54.12, PEN_DOWN_Z, -121.06), (55.29, PEN_DOWN_Z, -119.88), (55.53, PEN_DOWN_Z, -120.12), (55.65, PEN_DOWN_Z, -120.12), (55.76, PEN_DOWN_Z, -120.24), (55.88, PEN_DOWN_Z, -120.24), (56.0, PEN_DOWN_Z, -120.12), (56.24, PEN_DOWN_Z, -120.12), (56.71, PEN_DOWN_Z, -119.65), (56.71, PEN_DOWN_Z, -119.53), (56.94, PEN_DOWN_Z, -119.29), (56.94, PEN_DOWN_Z, -119.18), (57.18, PEN_DOWN_Z, -118.94), (57.29, PEN_DOWN_Z, -118.94), (57.41, PEN_DOWN_Z, -119.06), (57.88, PEN_DOWN_Z, -119.06), (58.0, PEN_DOWN_Z, -119.18), (59.06, PEN_DOWN_Z, -119.18), (59.18, PEN_DOWN_Z, -119.29), (59.18, PEN_DOWN_Z, -119.41), (58.82, PEN_DOWN_Z, -119.76), (58.82, PEN_DOWN_Z, -120.0), (58.71, PEN_DOWN_Z, -120.12), (58.71, PEN_DOWN_Z, -120.35), (59.06, PEN_DOWN_Z, -120.35), (59.29, PEN_DOWN_Z, -120.12), (59.41, PEN_DOWN_Z, -120.24), (59.76, PEN_DOWN_Z, -120.24), (59.88, PEN_DOWN_Z, -120.12), (60.24, PEN_DOWN_Z, -120.12), (60.35, PEN_DOWN_Z, -120.0), (60.82, PEN_DOWN_Z, -120.0), (60.94, PEN_DOWN_Z, -119.88), (61.18, PEN_DOWN_Z, -119.88), (61.29, PEN_DOWN_Z, -119.76), (61.53, PEN_DOWN_Z, -119.76), (61.65, PEN_DOWN_Z, -119.65), (61.76, PEN_DOWN_Z, -119.65), (61.88, PEN_DOWN_Z, -119.53), (62.12, PEN_DOWN_Z, -119.53), (62.24, PEN_DOWN_Z, -119.41), (62.35, PEN_DOWN_Z, -119.41), (62.47, PEN_DOWN_Z, -119.29), (62.59, PEN_DOWN_Z, -119.29), (62.71, PEN_DOWN_Z, -119.18), (62.82, PEN_DOWN_Z, -119.18), (62.94, PEN_DOWN_Z, -119.29), (62.94, PEN_DOWN_Z, -119.41), (62.82, PEN_DOWN_Z, -119.53), (62.82, PEN_DOWN_Z, -119.88), (62.94, PEN_DOWN_Z, -120.0), (62.94, PEN_DOWN_Z, -120.12), (63.06, PEN_DOWN_Z, -120.12), (63.18, PEN_DOWN_Z, -120.24), (63.41, PEN_DOWN_Z, -120.24), (63.53, PEN_DOWN_Z, -120.12), (63.65, PEN_DOWN_Z, -120.12), (64.24, PEN_DOWN_Z, -119.53), (64.24, PEN_DOWN_Z, -119.41), (64.35, PEN_DOWN_Z, -119.29), (64.35, PEN_DOWN_Z, -119.18), (64.59, PEN_DOWN_Z, -118.94), (64.71, PEN_DOWN_Z, -118.94), (64.82, PEN_DOWN_Z, -119.06), (65.29, PEN_DOWN_Z, -119.06), (65.41, PEN_DOWN_Z, -119.18), (66.47, PEN_DOWN_Z, -119.18), (66.59, PEN_DOWN_Z, -119.29), (66.35, PEN_DOWN_Z, -119.53), (66.35, PEN_DOWN_Z, -119.65), (66.24, PEN_DOWN_Z, -119.76), (66.24, PEN_DOWN_Z, -119.88), (66.12, PEN_DOWN_Z, -120.0), (66.12, PEN_DOWN_Z, -120.12), (66.0, PEN_DOWN_Z, -120.24), (66.0, PEN_DOWN_Z, -120.47), (65.88, PEN_DOWN_Z, -120.59), (65.88, PEN_DOWN_Z, -120.94), (66.0, PEN_DOWN_Z, -121.06), (66.0, PEN_DOWN_Z, -121.18), (66.12, PEN_DOWN_Z, -121.18), (66.24, PEN_DOWN_Z, -121.29), (66.71, PEN_DOWN_Z, -121.29), (66.82, PEN_DOWN_Z, -121.18), (67.06, PEN_DOWN_Z, -121.18), (67.18, PEN_DOWN_Z, -121.06), (67.41, PEN_DOWN_Z, -121.06), (67.53, PEN_DOWN_Z, -120.94), (67.65, PEN_DOWN_Z, -120.94), (67.76, PEN_DOWN_Z, -120.82), (67.88, PEN_DOWN_Z, -120.82), (68.0, PEN_DOWN_Z, -120.71), (68.12, PEN_DOWN_Z, -120.71), (68.24, PEN_DOWN_Z, -120.59), (68.35, PEN_DOWN_Z, -120.59), (68.47, PEN_DOWN_Z, -120.47), (68.59, PEN_DOWN_Z, -120.47), (68.82, PEN_DOWN_Z, -120.24), (68.94, PEN_DOWN_Z, -120.24), (69.06, PEN_DOWN_Z, -120.12), (69.18, PEN_DOWN_Z, -120.12), (69.29, PEN_DOWN_Z, -120.0), (69.41, PEN_DOWN_Z, -120.0), (69.65, PEN_DOWN_Z, -119.76), (69.76, PEN_DOWN_Z, -119.76), (70.12, PEN_DOWN_Z, -119.41), (70.24, PEN_DOWN_Z, -119.41), (70.59, PEN_DOWN_Z, -119.06), (70.71, PEN_DOWN_Z, -119.18), (70.71, PEN_DOWN_Z, -119.53), (70.82, PEN_DOWN_Z, -119.65), (70.82, PEN_DOWN_Z, -119.88), (71.06, PEN_DOWN_Z, -119.88), (71.18, PEN_DOWN_Z, -120.0), (71.76, PEN_DOWN_Z, -120.0), (71.88, PEN_DOWN_Z, -119.88), (72.24, PEN_DOWN_Z, -119.88), (72.35, PEN_DOWN_Z, -119.76), (72.59, PEN_DOWN_Z, -119.76), (72.71, PEN_DOWN_Z, -119.65), (72.82, PEN_DOWN_Z, -119.65), (72.94, PEN_DOWN_Z, -119.53), (73.18, PEN_DOWN_Z, -119.53), (73.29, PEN_DOWN_Z, -119.41), (73.41, PEN_DOWN_Z, -119.41), (73.53, PEN_DOWN_Z, -119.29), (73.65, PEN_DOWN_Z, -119.29), (73.76, PEN_DOWN_Z, -119.41), (73.76, PEN_DOWN_Z, -119.76), (73.65, PEN_DOWN_Z, -119.88), (73.65, PEN_DOWN_Z, -120.24), (73.53, PEN_DOWN_Z, -120.35), (73.41, PEN_DOWN_Z, -120.35), (73.18, PEN_DOWN_Z, -120.59), (73.06, PEN_DOWN_Z, -120.59), (73.06, PEN_DOWN_Z, -120.94), (73.18, PEN_DOWN_Z, -121.06), (73.53, PEN_DOWN_Z, -121.06), (73.88, PEN_DOWN_Z, -120.71), (73.88, PEN_DOWN_Z, -120.59), (74.0, PEN_DOWN_Z, -120.47), (74.12, PEN_DOWN_Z, -120.47), (74.24, PEN_DOWN_Z, -120.35), (74.35, PEN_DOWN_Z, -120.35), (74.47, PEN_DOWN_Z, -120.24), (74.59, PEN_DOWN_Z, -120.24), (74.71, PEN_DOWN_Z, -120.12), (74.82, PEN_DOWN_Z, -120.12), (74.94, PEN_DOWN_Z, -120.0), (75.06, PEN_DOWN_Z, -120.0), (75.18, PEN_DOWN_Z, -119.88), (75.41, PEN_DOWN_Z, -119.88), (75.53, PEN_DOWN_Z, -119.76), (75.65, PEN_DOWN_Z, -119.76), (75.76, PEN_DOWN_Z, -119.65), (75.88, PEN_DOWN_Z, -119.65), (76.0, PEN_DOWN_Z, -119.53), (76.12, PEN_DOWN_Z, -119.53), (76.24, PEN_DOWN_Z, -119.41), (76.35, PEN_DOWN_Z, -119.41), (76.47, PEN_DOWN_Z, -119.29), (76.59, PEN_DOWN_Z, -119.29), (76.71, PEN_DOWN_Z, -119.18), (76.82, PEN_DOWN_Z, -119.18), (76.94, PEN_DOWN_Z, -119.29), (76.71, PEN_DOWN_Z, -119.53), (76.71, PEN_DOWN_Z, -119.65), (76.59, PEN_DOWN_Z, -119.76), (76.59, PEN_DOWN_Z, -119.88), (76.47, PEN_DOWN_Z, -120.0), (76.47, PEN_DOWN_Z, -120.12), (76.35, PEN_DOWN_Z, -120.24), (76.35, PEN_DOWN_Z, -120.47), (76.24, PEN_DOWN_Z, -120.59), (76.24, PEN_DOWN_Z, -120.94), (76.35, PEN_DOWN_Z, -121.06), (76.35, PEN_DOWN_Z, -121.18), (76.47, PEN_DOWN_Z, -121.18), (76.59, PEN_DOWN_Z, -121.29), (77.06, PEN_DOWN_Z, -121.29), (77.18, PEN_DOWN_Z, -121.18), (77.41, PEN_DOWN_Z, -121.18), (77.53, PEN_DOWN_Z, -121.06), (77.76, PEN_DOWN_Z, -121.06), (77.88, PEN_DOWN_Z, -120.94), (78.0, PEN_DOWN_Z, -120.94), (78.12, PEN_DOWN_Z, -120.82), (78.24, PEN_DOWN_Z, -120.82), (78.35, PEN_DOWN_Z, -120.71), (78.47, PEN_DOWN_Z, -120.71), (78.59, PEN_DOWN_Z, -120.59), (78.71, PEN_DOWN_Z, -120.59), (78.82, PEN_DOWN_Z, -120.47), (78.94, PEN_DOWN_Z, -120.47), (79.18, PEN_DOWN_Z, -120.24), (79.29, PEN_DOWN_Z, -120.24), (79.41, PEN_DOWN_Z, -120.12), (79.53, PEN_DOWN_Z, -120.12), (79.65, PEN_DOWN_Z, -120.0), (79.76, PEN_DOWN_Z, -120.0), (80.0, PEN_DOWN_Z, -119.76), (80.12, PEN_DOWN_Z, -119.76), (80.47, PEN_DOWN_Z, -119.41), (80.59, PEN_DOWN_Z, -119.41), (80.82, PEN_DOWN_Z, -119.18), (80.94, PEN_DOWN_Z, -119.18), (81.18, PEN_DOWN_Z, -118.94), (81.29, PEN_DOWN_Z, -118.94), (81.41, PEN_DOWN_Z, -118.82), (81.53, PEN_DOWN_Z, -118.94), (81.53, PEN_DOWN_Z, -120.35), (81.65, PEN_DOWN_Z, -120.47), (81.65, PEN_DOWN_Z, -120.82), (81.76, PEN_DOWN_Z, -120.94), (81.76, PEN_DOWN_Z, -121.06), (81.88, PEN_DOWN_Z, -121.18), (81.88, PEN_DOWN_Z, -121.29), (82.0, PEN_DOWN_Z, -121.41), (82.0, PEN_DOWN_Z, -121.53), (82.24, PEN_DOWN_Z, -121.76), (82.24, PEN_DOWN_Z, -121.88), (82.35, PEN_DOWN_Z, -121.88), (82.47, PEN_DOWN_Z, -122.0), (82.82, PEN_DOWN_Z, -122.0), (82.82, PEN_DOWN_Z, -121.76), (82.35, PEN_DOWN_Z, -121.29), (82.35, PEN_DOWN_Z, -121.18), (82.12, PEN_DOWN_Z, -120.94), (82.12, PEN_DOWN_Z, -120.82), (82.0, PEN_DOWN_Z, -120.71), (82.0, PEN_DOWN_Z, -120.35), (81.88, PEN_DOWN_Z, -120.24), (81.88, PEN_DOWN_Z, -118.94), (82.0, PEN_DOWN_Z, -118.82), (82.0, PEN_DOWN_Z, -118.35), (82.12, PEN_DOWN_Z, -118.24), (82.12, PEN_DOWN_Z, -117.88), (82.24, PEN_DOWN_Z, -117.76), (82.24, PEN_DOWN_Z, -117.65), (82.35, PEN_DOWN_Z, -117.53), (82.35, PEN_DOWN_Z, -117.41), (82.47, PEN_DOWN_Z, -117.29), (82.47, PEN_DOWN_Z, -117.18), (82.59, PEN_DOWN_Z, -117.06), (82.59, PEN_DOWN_Z, -116.94), (82.71, PEN_DOWN_Z, -116.82), (82.71, PEN_DOWN_Z, -116.71), (82.94, PEN_DOWN_Z, -116.47), (82.94, PEN_DOWN_Z, -116.35), (84.0, PEN_DOWN_Z, -115.29), (84.12, PEN_DOWN_Z, -115.29), (84.24, PEN_DOWN_Z, -115.18), (84.24, PEN_DOWN_Z, -114.82), (84.12, PEN_DOWN_Z, -114.94), (83.76, PEN_DOWN_Z, -114.94), (83.41, PEN_DOWN_Z, -115.29), (83.29, PEN_DOWN_Z, -115.29), (82.94, PEN_DOWN_Z, -115.65), (82.94, PEN_DOWN_Z, -115.76), (82.59, PEN_DOWN_Z, -116.12), (82.59, PEN_DOWN_Z, -116.24), (82.35, PEN_DOWN_Z, -116.47), (82.35, PEN_DOWN_Z, -116.59), (82.24, PEN_DOWN_Z, -116.71), (82.24, PEN_DOWN_Z, -116.82), (82.12, PEN_DOWN_Z, -116.94), (82.12, PEN_DOWN_Z, -117.18), (82.0, PEN_DOWN_Z, -117.29), (82.0, PEN_DOWN_Z, -117.41), (81.88, PEN_DOWN_Z, -117.53), (81.88, PEN_DOWN_Z, -117.76), (81.76, PEN_DOWN_Z, -117.88), (81.76, PEN_DOWN_Z, -118.12), (81.65, PEN_DOWN_Z, -118.24), (81.65, PEN_DOWN_Z, -118.82), (81.53, PEN_DOWN_Z, -118.94), (81.41, PEN_DOWN_Z, -118.82), (81.41, PEN_DOWN_Z, -118.59), (81.29, PEN_DOWN_Z, -118.47), (81.18, PEN_DOWN_Z, -118.47), (80.94, PEN_DOWN_Z, -118.71), (80.82, PEN_DOWN_Z, -118.71), (80.71, PEN_DOWN_Z, -118.82), (80.59, PEN_DOWN_Z, -118.82), (80.35, PEN_DOWN_Z, -119.06), (80.24, PEN_DOWN_Z, -119.06), (80.0, PEN_DOWN_Z, -119.29), (79.88, PEN_DOWN_Z, -119.29), (79.65, PEN_DOWN_Z, -119.53), (79.53, PEN_DOWN_Z, -119.53), (79.29, PEN_DOWN_Z, -119.76), (79.18, PEN_DOWN_Z, -119.76), (79.06, PEN_DOWN_Z, -119.88), (78.94, PEN_DOWN_Z, -119.88), (78.71, PEN_DOWN_Z, -120.12), (78.59, PEN_DOWN_Z, -120.12), (78.47, PEN_DOWN_Z, -120.24), (78.35, PEN_DOWN_Z, -120.24), (78.12, PEN_DOWN_Z, -120.47), (78.0, PEN_DOWN_Z, -120.47), (77.88, PEN_DOWN_Z, -120.59), (77.76, PEN_DOWN_Z, -120.59), (77.65, PEN_DOWN_Z, -120.71), (77.41, PEN_DOWN_Z, -120.71), (77.29, PEN_DOWN_Z, -120.82), (77.06, PEN_DOWN_Z, -120.82), (76.94, PEN_DOWN_Z, -120.94), (76.71, PEN_DOWN_Z, -120.94), (76.59, PEN_DOWN_Z, -120.82), (76.59, PEN_DOWN_Z, -120.71), (76.71, PEN_DOWN_Z, -120.59), (76.71, PEN_DOWN_Z, -120.35), (76.82, PEN_DOWN_Z, -120.24), (76.82, PEN_DOWN_Z, -120.12), (77.06, PEN_DOWN_Z, -119.88), (77.06, PEN_DOWN_Z, -119.76), (77.18, PEN_DOWN_Z, -119.65), (77.18, PEN_DOWN_Z, -119.53), (77.29, PEN_DOWN_Z, -119.41), (77.29, PEN_DOWN_Z, -119.29), (77.53, PEN_DOWN_Z, -119.06), (77.53, PEN_DOWN_Z, -118.94), (77.76, PEN_DOWN_Z, -118.71), (77.76, PEN_DOWN_Z, -118.59), (78.12, PEN_DOWN_Z, -118.24), (78.12, PEN_DOWN_Z, -118.12), (78.24, PEN_DOWN_Z, -118.0), (78.24, PEN_DOWN_Z, -117.88), (78.59, PEN_DOWN_Z, -117.53), (78.59, PEN_DOWN_Z, -117.41), (78.82, PEN_DOWN_Z, -117.18), (78.82, PEN_DOWN_Z, -117.06), (79.06, PEN_DOWN_Z, -116.82), (80.71, PEN_DOWN_Z, -116.82), (80.71, PEN_DOWN_Z, -116.47), (79.53, PEN_DOWN_Z, -116.47), (79.41, PEN_DOWN_Z, -116.35), (79.65, PEN_DOWN_Z, -116.12), (79.65, PEN_DOWN_Z, -116.0), (79.88, PEN_DOWN_Z, -115.76), (79.88, PEN_DOWN_Z, -115.53), (79.53, PEN_DOWN_Z, -115.53), (79.29, PEN_DOWN_Z, -115.76), (79.29, PEN_DOWN_Z, -115.88), (79.06, PEN_DOWN_Z, -116.12), (79.06, PEN_DOWN_Z, -116.24), (78.82, PEN_DOWN_Z, -116.47), (77.53, PEN_DOWN_Z, -116.47), (77.53, PEN_DOWN_Z, -116.82), (78.35, PEN_DOWN_Z, -116.82), (78.47, PEN_DOWN_Z, -116.94), (78.24, PEN_DOWN_Z, -117.18), (78.24, PEN_DOWN_Z, -117.29), (78.0, PEN_DOWN_Z, -117.53), (78.0, PEN_DOWN_Z, -117.65), (77.76, PEN_DOWN_Z, -117.88), (77.76, PEN_DOWN_Z, -118.0), (77.18, PEN_DOWN_Z, -118.59), (77.06, PEN_DOWN_Z, -118.59), (76.94, PEN_DOWN_Z, -118.71), (76.82, PEN_DOWN_Z, -118.71), (76.71, PEN_DOWN_Z, -118.82), (76.59, PEN_DOWN_Z, -118.82), (76.47, PEN_DOWN_Z, -118.94), (76.35, PEN_DOWN_Z, -118.94), (76.24, PEN_DOWN_Z, -119.06), (76.12, PEN_DOWN_Z, -119.06), (76.0, PEN_DOWN_Z, -119.18), (75.88, PEN_DOWN_Z, -119.18), (75.76, PEN_DOWN_Z, -119.29), (75.65, PEN_DOWN_Z, -119.29), (75.53, PEN_DOWN_Z, -119.41), (75.29, PEN_DOWN_Z, -119.41), (75.18, PEN_DOWN_Z, -119.53), (75.06, PEN_DOWN_Z, -119.53), (74.94, PEN_DOWN_Z, -119.65), (74.82, PEN_DOWN_Z, -119.65), (74.71, PEN_DOWN_Z, -119.76), (74.59, PEN_DOWN_Z, -119.76), (74.47, PEN_DOWN_Z, -119.88), (74.35, PEN_DOWN_Z, -119.88), (74.24, PEN_DOWN_Z, -120.0), (74.12, PEN_DOWN_Z, -119.88), (74.12, PEN_DOWN_Z, -119.29), (74.24, PEN_DOWN_Z, -119.18), (74.24, PEN_DOWN_Z, -118.94), (74.35, PEN_DOWN_Z, -118.82), (74.35, PEN_DOWN_Z, -118.59), (74.82, PEN_DOWN_Z, -118.12), (75.06, PEN_DOWN_Z, -118.35), (75.06, PEN_DOWN_Z, -118.47), (75.29, PEN_DOWN_Z, -118.47), (75.29, PEN_DOWN_Z, -118.35), (75.41, PEN_DOWN_Z, -118.24), (75.41, PEN_DOWN_Z, -118.0), (75.29, PEN_DOWN_Z, -117.88), (75.18, PEN_DOWN_Z, -117.88), (75.06, PEN_DOWN_Z, -117.76), (74.71, PEN_DOWN_Z, -117.76), (74.59, PEN_DOWN_Z, -117.88), (74.47, PEN_DOWN_Z, -117.88), (74.35, PEN_DOWN_Z, -118.0), (74.24, PEN_DOWN_Z, -118.0), (74.24, PEN_DOWN_Z, -118.12), (74.12, PEN_DOWN_Z, -118.24), (74.12, PEN_DOWN_Z, -118.35), (74.0, PEN_DOWN_Z, -118.47), (74.0, PEN_DOWN_Z, -118.59), (73.88, PEN_DOWN_Z, -118.71), (73.76, PEN_DOWN_Z, -118.71), (73.53, PEN_DOWN_Z, -118.94), (73.41, PEN_DOWN_Z, -118.94), (73.29, PEN_DOWN_Z, -119.06), (73.18, PEN_DOWN_Z, -119.06), (73.06, PEN_DOWN_Z, -119.18), (72.94, PEN_DOWN_Z, -119.18), (72.82, PEN_DOWN_Z, -119.29), (72.59, PEN_DOWN_Z, -119.29), (72.47, PEN_DOWN_Z, -119.41), (72.24, PEN_DOWN_Z, -119.41), (72.12, PEN_DOWN_Z, -119.53), (71.88, PEN_DOWN_Z, -119.53), (71.76, PEN_DOWN_Z, -119.65), (71.29, PEN_DOWN_Z, -119.65), (71.06, PEN_DOWN_Z, -119.41), (71.06, PEN_DOWN_Z, -119.06), (71.18, PEN_DOWN_Z, -118.94), (71.18, PEN_DOWN_Z, -118.82), (71.29, PEN_DOWN_Z, -118.71), (71.29, PEN_DOWN_Z, -118.59), (71.41, PEN_DOWN_Z, -118.47), (71.41, PEN_DOWN_Z, -118.24), (71.53, PEN_DOWN_Z, -118.12), (71.18, PEN_DOWN_Z, -118.12), (70.59, PEN_DOWN_Z, -118.71), (70.47, PEN_DOWN_Z, -118.71), (70.35, PEN_DOWN_Z, -118.82), (70.24, PEN_DOWN_Z, -118.82), (70.0, PEN_DOWN_Z, -119.06), (69.88, PEN_DOWN_Z, -119.06), (69.65, PEN_DOWN_Z, -119.29), (69.53, PEN_DOWN_Z, -119.29), (69.29, PEN_DOWN_Z, -119.53), (69.18, PEN_DOWN_Z, -119.53), (68.94, PEN_DOWN_Z, -119.76), (68.82, PEN_DOWN_Z, -119.76), (68.71, PEN_DOWN_Z, -119.88), (68.59, PEN_DOWN_Z, -119.88), (68.35, PEN_DOWN_Z, -120.12), (68.24, PEN_DOWN_Z, -120.12), (68.12, PEN_DOWN_Z, -120.24), (68.0, PEN_DOWN_Z, -120.24), (67.76, PEN_DOWN_Z, -120.47), (67.65, PEN_DOWN_Z, -120.47), (67.53, PEN_DOWN_Z, -120.59), (67.41, PEN_DOWN_Z, -120.59), (67.29, PEN_DOWN_Z, -120.71), (67.06, PEN_DOWN_Z, -120.71), (66.94, PEN_DOWN_Z, -120.82), (66.71, PEN_DOWN_Z, -120.82), (66.59, PEN_DOWN_Z, -120.94), (66.35, PEN_DOWN_Z, -120.94), (66.24, PEN_DOWN_Z, -120.82), (66.24, PEN_DOWN_Z, -120.71), (66.35, PEN_DOWN_Z, -120.59), (66.35, PEN_DOWN_Z, -120.35), (66.47, PEN_DOWN_Z, -120.24), (66.47, PEN_DOWN_Z, -120.12), (66.71, PEN_DOWN_Z, -119.88), (66.71, PEN_DOWN_Z, -119.76), (66.82, PEN_DOWN_Z, -119.65), (66.82, PEN_DOWN_Z, -119.53), (66.94, PEN_DOWN_Z, -119.41), (66.94, PEN_DOWN_Z, -119.29), (67.18, PEN_DOWN_Z, -119.06), (67.18, PEN_DOWN_Z, -118.94), (67.41, PEN_DOWN_Z, -118.71), (67.41, PEN_DOWN_Z, -118.59), (67.65, PEN_DOWN_Z, -118.35), (67.65, PEN_DOWN_Z, -118.24), (67.88, PEN_DOWN_Z, -118.0), (67.88, PEN_DOWN_Z, -117.88), (68.24, PEN_DOWN_Z, -117.53), (68.24, PEN_DOWN_Z, -117.41), (68.47, PEN_DOWN_Z, -117.18), (68.47, PEN_DOWN_Z, -117.06), (68.71, PEN_DOWN_Z, -116.82), (70.35, PEN_DOWN_Z, -116.82), (70.35, PEN_DOWN_Z, -116.47), (69.18, PEN_DOWN_Z, -116.47), (69.06, PEN_DOWN_Z, -116.35), (69.29, PEN_DOWN_Z, -116.12), (69.29, PEN_DOWN_Z, -116.0), (69.53, PEN_DOWN_Z, -115.76), (69.53, PEN_DOWN_Z, -115.53), (69.18, PEN_DOWN_Z, -115.53), (68.94, PEN_DOWN_Z, -115.76), (68.94, PEN_DOWN_Z, -115.88), (68.71, PEN_DOWN_Z, -116.12), (68.71, PEN_DOWN_Z, -116.24), (68.47, PEN_DOWN_Z, -116.47), (67.18, PEN_DOWN_Z, -116.47), (67.18, PEN_DOWN_Z, -116.82), (68.0, PEN_DOWN_Z, -116.82), (68.12, PEN_DOWN_Z, -116.94), (67.88, PEN_DOWN_Z, -117.18), (67.88, PEN_DOWN_Z, -117.29), (67.65, PEN_DOWN_Z, -117.53), (67.65, PEN_DOWN_Z, -117.65), (67.41, PEN_DOWN_Z, -117.88), (67.41, PEN_DOWN_Z, -118.0), (67.18, PEN_DOWN_Z, -118.24), (67.18, PEN_DOWN_Z, -118.35), (66.82, PEN_DOWN_Z, -118.71), (66.71, PEN_DOWN_Z, -118.71), (66.59, PEN_DOWN_Z, -118.82), (65.41, PEN_DOWN_Z, -118.82), (65.29, PEN_DOWN_Z, -118.71), (64.82, PEN_DOWN_Z, -118.71), (64.47, PEN_DOWN_Z, -118.35), (64.47, PEN_DOWN_Z, -118.24), (63.88, PEN_DOWN_Z, -118.24), (63.76, PEN_DOWN_Z, -118.35), (63.53, PEN_DOWN_Z, -118.35), (63.41, PEN_DOWN_Z, -118.47), (63.29, PEN_DOWN_Z, -118.47), (63.18, PEN_DOWN_Z, -118.59), (63.06, PEN_DOWN_Z, -118.59), (62.94, PEN_DOWN_Z, -118.71), (62.82, PEN_DOWN_Z, -118.71), (62.71, PEN_DOWN_Z, -118.82), (62.59, PEN_DOWN_Z, -118.82), (62.47, PEN_DOWN_Z, -118.94), (62.35, PEN_DOWN_Z, -118.94), (62.24, PEN_DOWN_Z, -119.06), (62.12, PEN_DOWN_Z, -119.06), (62.0, PEN_DOWN_Z, -119.18), (61.88, PEN_DOWN_Z, -119.18), (61.76, PEN_DOWN_Z, -119.29), (61.53, PEN_DOWN_Z, -119.29), (61.41, PEN_DOWN_Z, -119.41), (61.29, PEN_DOWN_Z, -119.41), (61.18, PEN_DOWN_Z, -119.53), (60.94, PEN_DOWN_Z, -119.53), (60.82, PEN_DOWN_Z, -119.65), (60.71, PEN_DOWN_Z, -119.65), (60.59, PEN_DOWN_Z, -119.53), (61.06, PEN_DOWN_Z, -119.06), (61.06, PEN_DOWN_Z, -118.82), (61.18, PEN_DOWN_Z, -118.71), (61.18, PEN_DOWN_Z, -118.35), (61.06, PEN_DOWN_Z, -118.24), (61.06, PEN_DOWN_Z, -118.12), (60.59, PEN_DOWN_Z, -118.12), (60.35, PEN_DOWN_Z, -118.35), (60.12, PEN_DOWN_Z, -118.12), (60.35, PEN_DOWN_Z, -117.88), (60.35, PEN_DOWN_Z, -117.76), (60.59, PEN_DOWN_Z, -117.53), (60.59, PEN_DOWN_Z, -117.41), (60.71, PEN_DOWN_Z, -117.29), (60.71, PEN_DOWN_Z, -117.18), (60.82, PEN_DOWN_Z, -117.06), (60.82, PEN_DOWN_Z, -116.94), (60.94, PEN_DOWN_Z, -116.82), (60.94, PEN_DOWN_Z, -116.71), (61.18, PEN_DOWN_Z, -116.47), (61.18, PEN_DOWN_Z, -116.35), (61.29, PEN_DOWN_Z, -116.24), (61.29, PEN_DOWN_Z, -116.12), (61.53, PEN_DOWN_Z, -115.88), (61.53, PEN_DOWN_Z, -115.76), (61.76, PEN_DOWN_Z, -115.53), (61.76, PEN_DOWN_Z, -115.41), (62.0, PEN_DOWN_Z, -115.18), (62.0, PEN_DOWN_Z, -115.06), (61.76, PEN_DOWN_Z, -114.82), (61.65, PEN_DOWN_Z, -114.82), (61.65, PEN_DOWN_Z, -114.94), (61.41, PEN_DOWN_Z, -115.18), (61.41, PEN_DOWN_Z, -115.29), (61.18, PEN_DOWN_Z, -115.53), (61.18, PEN_DOWN_Z, -115.65), (60.94, PEN_DOWN_Z, -115.88), (60.94, PEN_DOWN_Z, -116.0), (60.82, PEN_DOWN_Z, -116.12), (60.82, PEN_DOWN_Z, -116.24), (60.71, PEN_DOWN_Z, -116.35), (60.71, PEN_DOWN_Z, -116.47), (60.59, PEN_DOWN_Z, -116.59), (60.59, PEN_DOWN_Z, -116.71), (60.35, PEN_DOWN_Z, -116.94), (60.35, PEN_DOWN_Z, -117.06), (60.24, PEN_DOWN_Z, -117.18), (60.24, PEN_DOWN_Z, -117.29), (60.12, PEN_DOWN_Z, -117.41), (60.12, PEN_DOWN_Z, -117.53), (59.88, PEN_DOWN_Z, -117.76), (59.88, PEN_DOWN_Z, -117.88), (59.76, PEN_DOWN_Z, -118.0), (59.76, PEN_DOWN_Z, -118.12), (59.65, PEN_DOWN_Z, -118.24), (59.65, PEN_DOWN_Z, -118.35), (59.53, PEN_DOWN_Z, -118.47), (59.53, PEN_DOWN_Z, -118.59), (59.41, PEN_DOWN_Z, -118.71), (59.29, PEN_DOWN_Z, -118.71), (59.18, PEN_DOWN_Z, -118.82), (58.0, PEN_DOWN_Z, -118.82), (57.88, PEN_DOWN_Z, -118.71), (57.41, PEN_DOWN_Z, -118.71), (57.06, PEN_DOWN_Z, -118.35), (57.06, PEN_DOWN_Z, -118.24), (56.47, PEN_DOWN_Z, -118.24), (56.35, PEN_DOWN_Z, -118.35), (56.12, PEN_DOWN_Z, -118.35), (55.65, PEN_DOWN_Z, -118.82), (55.65, PEN_DOWN_Z, -118.94), (54.35, PEN_DOWN_Z, -120.24), (54.24, PEN_DOWN_Z, -120.24), (53.53, PEN_DOWN_Z, -120.94), (53.41, PEN_DOWN_Z, -120.94), (53.06, PEN_DOWN_Z, -121.29), (52.94, PEN_DOWN_Z, -121.29), (52.71, PEN_DOWN_Z, -121.53), (52.59, PEN_DOWN_Z, -121.53), (52.35, PEN_DOWN_Z, -121.76), (52.24, PEN_DOWN_Z, -121.76), (52.12, PEN_DOWN_Z, -121.88), (52.0, PEN_DOWN_Z, -121.88), (51.88, PEN_DOWN_Z, -122.0), (51.76, PEN_DOWN_Z, -122.0), (51.65, PEN_DOWN_Z, -122.12), (51.41, PEN_DOWN_Z, -122.12), (51.29, PEN_DOWN_Z, -122.24), (50.82, PEN_DOWN_Z, -122.24), (50.71, PEN_DOWN_Z, -122.35), (49.53, PEN_DOWN_Z, -122.35), (49.41, PEN_DOWN_Z, -122.24), (49.06, PEN_DOWN_Z, -122.24), (48.94, PEN_DOWN_Z, -122.12), (48.82, PEN_DOWN_Z, -122.12), (48.71, PEN_DOWN_Z, -122.0), (48.59, PEN_DOWN_Z, -122.0), (48.47, PEN_DOWN_Z, -121.88), (48.35, PEN_DOWN_Z, -121.88), (48.12, PEN_DOWN_Z, -121.65), (48.0, PEN_DOWN_Z, -121.65), (47.18, PEN_DOWN_Z, -120.82), (47.18, PEN_DOWN_Z, -120.59), (47.29, PEN_DOWN_Z, -120.47), (47.29, PEN_DOWN_Z, -120.35), (47.41, PEN_DOWN_Z, -120.24), (47.41, PEN_DOWN_Z, -120.12), (47.65, PEN_DOWN_Z, -119.88), (47.65, PEN_DOWN_Z, -119.76), (47.76, PEN_DOWN_Z, -119.65), (47.76, PEN_DOWN_Z, -119.53), (47.88, PEN_DOWN_Z, -119.41), (47.88, PEN_DOWN_Z, -119.29), (48.12, PEN_DOWN_Z, -119.06), (48.35, PEN_DOWN_Z, -119.06), (48.47, PEN_DOWN_Z, -118.94), (49.06, PEN_DOWN_Z, -118.94), (49.18, PEN_DOWN_Z, -118.82), (49.41, PEN_DOWN_Z, -118.82), (49.53, PEN_DOWN_Z, -118.71), (49.88, PEN_DOWN_Z, -118.71), (50.0, PEN_DOWN_Z, -118.59), (50.24, PEN_DOWN_Z, -118.59), (50.35, PEN_DOWN_Z, -118.47), (50.47, PEN_DOWN_Z, -118.47), (50.59, PEN_DOWN_Z, -118.35), (50.71, PEN_DOWN_Z, -118.35), (50.82, PEN_DOWN_Z, -118.24), (51.06, PEN_DOWN_Z, -118.24), (51.18, PEN_DOWN_Z, -118.12), (51.29, PEN_DOWN_Z, -118.12), (51.41, PEN_DOWN_Z, -118.0), (51.53, PEN_DOWN_Z, -118.0), (51.76, PEN_DOWN_Z, -117.76), (51.88, PEN_DOWN_Z, -117.76), (52.0, PEN_DOWN_Z, -117.65), (52.12, PEN_DOWN_Z, -117.65), (52.47, PEN_DOWN_Z, -117.29), (52.59, PEN_DOWN_Z, -117.29), (53.06, PEN_DOWN_Z, -116.82), (53.06, PEN_DOWN_Z, -116.71), (53.29, PEN_DOWN_Z, -116.47), (53.29, PEN_DOWN_Z, -116.35), (53.41, PEN_DOWN_Z, -116.24), (53.41, PEN_DOWN_Z, -116.12), (53.53, PEN_DOWN_Z, -116.0), (53.53, PEN_DOWN_Z, -115.88), (53.65, PEN_DOWN_Z, -115.76), (53.65, PEN_DOWN_Z, -115.65), (53.76, PEN_DOWN_Z, -115.53), (53.76, PEN_DOWN_Z, -115.18), (53.88, PEN_DOWN_Z, -115.06), (53.88, PEN_DOWN_Z, -114.0), (53.76, PEN_DOWN_Z, -113.88), (53.76, PEN_DOWN_Z, -113.65), (53.65, PEN_DOWN_Z, -113.53), (53.65, PEN_DOWN_Z, -113.41), (53.41, PEN_DOWN_Z, -113.18), (53.18, PEN_DOWN_Z, -113.18), (53.06, PEN_DOWN_Z, -113.06), (52.94, PEN_DOWN_Z, -113.06), (52.82, PEN_DOWN_Z, -112.94), (52.0, PEN_DOWN_Z, -112.94), (51.88, PEN_DOWN_Z, -112.82), (51.88, PEN_DOWN_Z, -112.71), (52.12, PEN_DOWN_Z, -112.47), (52.12, PEN_DOWN_Z, -112.0), (52.12, -15.0, -112.0), (56.59, -15.0, -118.47), (56.59, PEN_DOWN_Z, -118.47), (56.59, PEN_DOWN_Z, -118.59), (56.47, PEN_DOWN_Z, -118.71), (56.24, PEN_DOWN_Z, -118.71), (56.12, PEN_DOWN_Z, -118.82), (56.12, PEN_DOWN_Z, -118.94), (55.88, PEN_DOWN_Z, -119.18), (55.88, PEN_DOWN_Z, -119.29), (55.76, PEN_DOWN_Z, -119.41), (55.76, PEN_DOWN_Z, -119.53), (55.65, PEN_DOWN_Z, -119.65), (55.76, PEN_DOWN_Z, -119.76), (55.76, PEN_DOWN_Z, -119.88), (56.0, PEN_DOWN_Z, -119.88), (56.35, PEN_DOWN_Z, -119.53), (56.35, PEN_DOWN_Z, -119.41), (56.59, PEN_DOWN_Z, -119.18), (56.59, PEN_DOWN_Z, -118.94), (56.71, PEN_DOWN_Z, -118.82), (56.71, PEN_DOWN_Z, -118.71), (56.59, PEN_DOWN_Z, -118.59), (56.59, -15.0, -118.59), (56.35, -15.0, -118.71), (56.35, PEN_DOWN_Z, -118.71), (56.59, PEN_DOWN_Z, -118.71), (56.71, PEN_DOWN_Z, -118.82), (56.59, PEN_DOWN_Z, -118.94), (56.59, PEN_DOWN_Z, -119.06), (56.35, PEN_DOWN_Z, -119.29), (56.35, PEN_DOWN_Z, -119.41), (55.88, PEN_DOWN_Z, -119.88), (55.65, PEN_DOWN_Z, -119.65), (55.88, PEN_DOWN_Z, -119.41), (55.88, PEN_DOWN_Z, -119.29), (56.0, PEN_DOWN_Z, -119.18), (56.0, PEN_DOWN_Z, -119.06), (56.0, -15.0, -119.06), (60.12, -15.0, -119.06), (60.12, PEN_DOWN_Z, -119.06), (60.0, PEN_DOWN_Z, -119.06), (59.29, PEN_DOWN_Z, -119.76), (59.41, PEN_DOWN_Z, -119.88), (59.65, PEN_DOWN_Z, -119.88), (59.88, PEN_DOWN_Z, -119.65), (60.0, PEN_DOWN_Z, -119.65), (60.71, PEN_DOWN_Z, -118.94), (60.71, PEN_DOWN_Z, -118.82), (60.82, PEN_DOWN_Z, -118.71), (60.82, PEN_DOWN_Z, -118.59), (60.71, PEN_DOWN_Z, -118.47), (60.71, -15.0, -118.47), (63.41, -15.0, -119.06), (63.41, PEN_DOWN_Z, -119.06), (63.41, PEN_DOWN_Z, -119.18), (63.29, PEN_DOWN_Z, -119.29), (63.29, PEN_DOWN_Z, -119.41), (63.18, PEN_DOWN_Z, -119.53), (63.18, PEN_DOWN_Z, -119.76), (63.29, PEN_DOWN_Z, -119.88), (63.76, PEN_DOWN_Z, -119.41), (63.76, PEN_DOWN_Z, -119.29), (64.0, PEN_DOWN_Z, -119.06), (64.0, PEN_DOWN_Z, -118.94), (64.12, PEN_DOWN_Z, -118.82), (63.88, PEN_DOWN_Z, -118.59), (63.88, -15.0, -118.59), (64.0, -15.0, -118.59), (64.0, PEN_DOWN_Z, -118.59), (64.12, PEN_DOWN_Z, -118.71), (64.12, PEN_DOWN_Z, -118.82), (64.0, PEN_DOWN_Z, -118.94), (64.0, PEN_DOWN_Z, -119.18), (63.76, PEN_DOWN_Z, -119.41), (63.76, PEN_DOWN_Z, -119.53), (63.41, PEN_DOWN_Z, -119.88), (63.18, PEN_DOWN_Z, -119.88), (63.18, PEN_DOWN_Z, -119.41), (63.29, PEN_DOWN_Z, -119.29), (63.29, PEN_DOWN_Z, -119.18), (63.41, PEN_DOWN_Z, -119.06), (63.41, PEN_DOWN_Z, -118.94), (63.65, PEN_DOWN_Z, -118.71), (63.76, PEN_DOWN_Z, -118.71), (64.0, PEN_DOWN_Z, -118.47), (64.0, -15.0, -118.47), (79.29, -15.0, -115.88), (79.29, PEN_DOWN_Z, -115.88), (79.29, PEN_DOWN_Z, -116.0), (79.06, PEN_DOWN_Z, -116.24), (79.06, PEN_DOWN_Z, -116.35), (78.94, PEN_DOWN_Z, -116.47), (77.65, PEN_DOWN_Z, -116.47), (77.53, PEN_DOWN_Z, -116.59), (77.53, PEN_DOWN_Z, -116.71), (77.65, PEN_DOWN_Z, -116.82), (78.47, PEN_DOWN_Z, -116.82), (78.47, PEN_DOWN_Z, -117.06), (78.24, PEN_DOWN_Z, -117.29), (78.24, PEN_DOWN_Z, -117.41), (78.0, PEN_DOWN_Z, -117.65), (78.0, PEN_DOWN_Z, -117.76), (77.76, PEN_DOWN_Z, -118.0), (77.76, PEN_DOWN_Z, -118.12), (77.41, PEN_DOWN_Z, -118.47), (77.65, PEN_DOWN_Z, -118.71), (77.76, PEN_DOWN_Z, -118.59), (77.76, PEN_DOWN_Z, -118.47), (78.12, PEN_DOWN_Z, -118.12), (78.12, PEN_DOWN_Z, -118.0), (78.24, PEN_DOWN_Z, -117.88), (78.24, PEN_DOWN_Z, -117.76), (78.59, PEN_DOWN_Z, -117.41), (78.59, PEN_DOWN_Z, -117.29), (78.82, PEN_DOWN_Z, -117.06), (78.82, PEN_DOWN_Z, -116.94), (78.94, PEN_DOWN_Z, -116.82), (80.59, PEN_DOWN_Z, -116.82), (80.71, PEN_DOWN_Z, -116.71), (80.71, PEN_DOWN_Z, -116.59), (80.59, PEN_DOWN_Z, -116.47), (79.41, PEN_DOWN_Z, -116.47), (79.41, PEN_DOWN_Z, -116.24), (79.65, PEN_DOWN_Z, -116.0), (79.65, PEN_DOWN_Z, -115.88), (79.88, PEN_DOWN_Z, -115.65), (79.76, PEN_DOWN_Z, -115.53), (79.65, PEN_DOWN_Z, -115.53), (79.65, -15.0, -115.53), (83.53, -15.0, -115.29), (83.53, PEN_DOWN_Z, -115.29), (83.41, PEN_DOWN_Z, -115.29), (82.94, PEN_DOWN_Z, -115.76), (82.94, PEN_DOWN_Z, -115.88), (82.59, PEN_DOWN_Z, -116.24), (82.59, PEN_DOWN_Z, -116.35), (82.35, PEN_DOWN_Z, -116.59), (82.35, PEN_DOWN_Z, -116.71), (82.24, PEN_DOWN_Z, -116.82), (82.24, PEN_DOWN_Z, -116.94), (82.12, PEN_DOWN_Z, -117.06), (82.12, PEN_DOWN_Z, -117.18), (82.0, PEN_DOWN_Z, -117.29), (82.0, PEN_DOWN_Z, -117.53), (81.88, PEN_DOWN_Z, -117.65), (81.88, PEN_DOWN_Z, -117.76), (81.76, PEN_DOWN_Z, -117.88), (81.76, PEN_DOWN_Z, -118.12), (81.65, PEN_DOWN_Z, -118.24), (81.65, PEN_DOWN_Z, -118.82), (81.53, PEN_DOWN_Z, -118.94), (81.53, PEN_DOWN_Z, -120.35), (81.65, PEN_DOWN_Z, -120.47), (81.65, PEN_DOWN_Z, -120.82), (81.76, PEN_DOWN_Z, -120.94), (81.76, PEN_DOWN_Z, -121.06), (82.0, PEN_DOWN_Z, -121.29), (82.0, PEN_DOWN_Z, -121.41), (82.24, PEN_DOWN_Z, -121.65), (82.24, PEN_DOWN_Z, -121.76), (82.35, PEN_DOWN_Z, -121.88), (82.47, PEN_DOWN_Z, -121.88), (82.59, PEN_DOWN_Z, -122.0), (82.71, PEN_DOWN_Z, -122.0), (82.82, PEN_DOWN_Z, -121.88), (82.35, PEN_DOWN_Z, -121.41), (82.35, PEN_DOWN_Z, -121.29), (82.12, PEN_DOWN_Z, -121.06), (82.12, PEN_DOWN_Z, -120.94), (82.0, PEN_DOWN_Z, -120.82), (82.0, PEN_DOWN_Z, -120.35), (81.88, PEN_DOWN_Z, -120.24), (81.88, PEN_DOWN_Z, -118.94), (82.0, PEN_DOWN_Z, -118.82), (82.0, PEN_DOWN_Z, -118.35), (82.12, PEN_DOWN_Z, -118.24), (82.12, PEN_DOWN_Z, -117.88), (82.24, PEN_DOWN_Z, -117.76), (82.24, PEN_DOWN_Z, -117.53), (82.35, PEN_DOWN_Z, -117.41), (82.35, PEN_DOWN_Z, -117.29), (82.47, PEN_DOWN_Z, -117.18), (82.47, PEN_DOWN_Z, -117.06), (82.59, PEN_DOWN_Z, -116.94), (82.59, PEN_DOWN_Z, -116.82), (82.71, PEN_DOWN_Z, -116.71), (82.71, PEN_DOWN_Z, -116.59), (82.94, PEN_DOWN_Z, -116.35), (82.94, PEN_DOWN_Z, -116.24), (83.88, PEN_DOWN_Z, -115.29), (84.0, PEN_DOWN_Z, -115.29), (84.24, PEN_DOWN_Z, -115.06), (84.12, PEN_DOWN_Z, -114.94), (83.88, PEN_DOWN_Z, -114.94), (83.88, -15.0, -114.94), (85.18, -15.0, -116.0), (85.18, PEN_DOWN_Z, -116.0), (85.06, PEN_DOWN_Z, -116.0), (84.94, PEN_DOWN_Z, -116.12), (84.94, PEN_DOWN_Z, -116.24), (85.18, PEN_DOWN_Z, -116.47), (85.18, PEN_DOWN_Z, -116.59), (85.29, PEN_DOWN_Z, -116.71), (85.29, PEN_DOWN_Z, -116.82), (85.41, PEN_DOWN_Z, -116.94), (85.41, PEN_DOWN_Z, -117.18), (85.53, PEN_DOWN_Z, -117.29), (85.53, PEN_DOWN_Z, -117.53), (85.76, PEN_DOWN_Z, -117.76), (86.0, PEN_DOWN_Z, -117.76), (86.35, PEN_DOWN_Z, -117.41), (86.35, PEN_DOWN_Z, -117.29), (86.24, PEN_DOWN_Z, -117.18), (86.24, PEN_DOWN_Z, -116.94), (86.12, PEN_DOWN_Z, -116.82), (86.12, PEN_DOWN_Z, -116.71), (85.88, PEN_DOWN_Z, -116.47), (85.88, PEN_DOWN_Z, -116.35), (85.76, PEN_DOWN_Z, -116.24), (85.76, PEN_DOWN_Z, -116.12), (85.41, PEN_DOWN_Z, -115.76), (85.41, -15.0, -115.76), (85.41, -15.0, -115.76), (85.41, PEN_DOWN_Z, -115.76), (85.29, PEN_DOWN_Z, -115.88), (85.18, PEN_DOWN_Z, -115.88), (85.06, PEN_DOWN_Z, -116.0), (84.94, PEN_DOWN_Z, -116.0), (84.94, PEN_DOWN_Z, -116.35), (85.18, PEN_DOWN_Z, -116.59), (85.18, PEN_DOWN_Z, -116.71), (85.29, PEN_DOWN_Z, -116.82), (85.29, PEN_DOWN_Z, -116.94), (85.41, PEN_DOWN_Z, -117.06), (85.41, PEN_DOWN_Z, -117.18), (85.53, PEN_DOWN_Z, -117.29), (85.53, PEN_DOWN_Z, -117.53), (85.65, PEN_DOWN_Z, -117.65), (85.65, PEN_DOWN_Z, -117.76), (86.12, PEN_DOWN_Z, -117.76), (86.35, PEN_DOWN_Z, -117.53), (86.35, PEN_DOWN_Z, -117.29), (86.24, PEN_DOWN_Z, -117.18), (86.24, PEN_DOWN_Z, -116.82), (86.12, PEN_DOWN_Z, -116.71), (86.12, PEN_DOWN_Z, -116.59), (85.88, PEN_DOWN_Z, -116.35), (85.88, PEN_DOWN_Z, -116.24), (85.65, PEN_DOWN_Z, -116.0), (85.65, PEN_DOWN_Z, -115.88), (85.53, PEN_DOWN_Z, -115.88), (85.53, -15.0, -115.88), (87.06, -15.0, -115.53), (87.06, PEN_DOWN_Z, -115.53), (86.82, PEN_DOWN_Z, -115.76), (87.06, PEN_DOWN_Z, -116.0), (87.06, PEN_DOWN_Z, -116.12), (87.18, PEN_DOWN_Z, -116.24), (87.18, PEN_DOWN_Z, -116.35), (87.41, PEN_DOWN_Z, -116.59), (87.41, PEN_DOWN_Z, -116.82), (87.76, PEN_DOWN_Z, -117.18), (87.88, PEN_DOWN_Z, -117.18), (88.24, PEN_DOWN_Z, -116.82), (88.24, PEN_DOWN_Z, -116.59), (88.12, PEN_DOWN_Z, -116.47), (88.12, PEN_DOWN_Z, -116.35), (88.0, PEN_DOWN_Z, -116.24), (88.0, PEN_DOWN_Z, -116.12), (87.88, PEN_DOWN_Z, -116.0), (87.88, PEN_DOWN_Z, -115.88), (87.41, PEN_DOWN_Z, -115.41), (87.29, PEN_DOWN_Z, -115.41), (87.18, PEN_DOWN_Z, -115.53), (87.18, -15.0, -115.53), (87.18, -15.0, -115.41), (87.18, PEN_DOWN_Z, -115.41), (87.06, PEN_DOWN_Z, -115.53), (86.94, PEN_DOWN_Z, -115.53), (86.94, PEN_DOWN_Z, -115.65), (86.82, PEN_DOWN_Z, -115.76), (86.82, PEN_DOWN_Z, -115.88), (87.06, PEN_DOWN_Z, -116.12), (87.06, PEN_DOWN_Z, -116.24), (87.18, PEN_DOWN_Z, -116.35), (87.18, PEN_DOWN_Z, -116.47), (87.41, PEN_DOWN_Z, -116.71), (87.41, PEN_DOWN_Z, -116.94), (87.65, PEN_DOWN_Z, -117.18), (88.0, PEN_DOWN_Z, -117.18), (88.24, PEN_DOWN_Z, -116.94), (88.24, PEN_DOWN_Z, -116.47), (88.0, PEN_DOWN_Z, -116.24), (88.0, PEN_DOWN_Z, -116.0), (87.88, PEN_DOWN_Z, -115.88), (87.88, PEN_DOWN_Z, -115.76), (87.53, PEN_DOWN_Z, -115.41), (87.53, -15.0, -115.41), (90.0, -15.0, -115.76), (90.0, PEN_DOWN_Z, -115.76), (90.0, PEN_DOWN_Z, -116.12), (89.88, PEN_DOWN_Z, -116.24), (89.88, PEN_DOWN_Z, -116.71), (89.76, PEN_DOWN_Z, -116.82), (89.76, PEN_DOWN_Z, -117.06), (89.65, PEN_DOWN_Z, -117.18), (89.65, PEN_DOWN_Z, -117.41), (89.53, PEN_DOWN_Z, -117.53), (89.53, PEN_DOWN_Z, -117.76), (89.41, PEN_DOWN_Z, -117.88), (89.41, PEN_DOWN_Z, -118.12), (89.29, PEN_DOWN_Z, -118.24), (89.29, PEN_DOWN_Z, -118.35), (89.18, PEN_DOWN_Z, -118.47), (89.18, PEN_DOWN_Z, -118.59), (89.06, PEN_DOWN_Z, -118.71), (89.06, PEN_DOWN_Z, -118.82), (88.35, PEN_DOWN_Z, -119.53), (88.24, PEN_DOWN_Z, -119.53), (88.12, PEN_DOWN_Z, -119.65), (88.0, PEN_DOWN_Z, -119.65), (87.88, PEN_DOWN_Z, -119.76), (87.76, PEN_DOWN_Z, -119.76), (87.65, PEN_DOWN_Z, -119.88), (87.53, PEN_DOWN_Z, -119.88), (87.41, PEN_DOWN_Z, -120.0), (87.29, PEN_DOWN_Z, -120.0), (87.18, PEN_DOWN_Z, -120.12), (87.06, PEN_DOWN_Z, -120.12), (86.94, PEN_DOWN_Z, -120.24), (86.82, PEN_DOWN_Z, -120.24), (86.71, PEN_DOWN_Z, -120.35), (86.47, PEN_DOWN_Z, -120.35), (86.24, PEN_DOWN_Z, -120.59), (86.35, PEN_DOWN_Z, -120.71), (86.35, PEN_DOWN_Z, -120.82), (86.59, PEN_DOWN_Z, -121.06), (86.94, PEN_DOWN_Z, -121.06), (87.06, PEN_DOWN_Z, -120.94), (87.18, PEN_DOWN_Z, -120.94), (87.29, PEN_DOWN_Z, -120.82), (87.53, PEN_DOWN_Z, -120.82), (87.76, PEN_DOWN_Z, -120.59), (88.0, PEN_DOWN_Z, -120.59), (88.24, PEN_DOWN_Z, -120.35), (88.35, PEN_DOWN_Z, -120.35), (88.71, PEN_DOWN_Z, -120.0), (88.82, PEN_DOWN_Z, -120.0), (89.65, PEN_DOWN_Z, -119.18), (89.65, PEN_DOWN_Z, -119.06), (89.88, PEN_DOWN_Z, -118.82), (89.88, PEN_DOWN_Z, -118.71), (90.0, PEN_DOWN_Z, -118.59), (90.0, PEN_DOWN_Z, -118.35), (90.24, PEN_DOWN_Z, -118.12), (90.24, PEN_DOWN_Z, -117.88), (90.35, PEN_DOWN_Z, -117.76), (90.35, PEN_DOWN_Z, -117.53), (90.47, PEN_DOWN_Z, -117.41), (90.47, PEN_DOWN_Z, -117.18), (90.59, PEN_DOWN_Z, -117.06), (90.59, PEN_DOWN_Z, -116.82), (90.71, PEN_DOWN_Z, -116.71), (90.71, PEN_DOWN_Z, -116.24), (90.82, PEN_DOWN_Z, -116.12), (90.82, PEN_DOWN_Z, -115.76), (90.71, PEN_DOWN_Z, -115.65), (90.59, PEN_DOWN_Z, -115.65), (90.47, PEN_DOWN_Z, -115.53), (90.24, PEN_DOWN_Z, -115.53), (90.24, -15.0, -115.53), (90.12, -15.0, -115.53), (90.12, PEN_DOWN_Z, -115.53), (90.12, PEN_DOWN_Z, -115.65), (90.0, PEN_DOWN_Z, -115.76), (90.0, PEN_DOWN_Z, -116.12), (89.88, PEN_DOWN_Z, -116.24), (89.88, PEN_DOWN_Z, -116.71), (89.76, PEN_DOWN_Z, -116.82), (89.76, PEN_DOWN_Z, -117.06), (89.65, PEN_DOWN_Z, -117.18), (89.65, PEN_DOWN_Z, -117.41), (89.53, PEN_DOWN_Z, -117.53), (89.53, PEN_DOWN_Z, -117.76), (89.41, PEN_DOWN_Z, -117.88), (89.41, PEN_DOWN_Z, -118.0), (89.29, PEN_DOWN_Z, -118.12), (89.29, PEN_DOWN_Z, -118.24), (89.18, PEN_DOWN_Z, -118.35), (89.18, PEN_DOWN_Z, -118.47), (89.06, PEN_DOWN_Z, -118.59), (89.06, PEN_DOWN_Z, -118.71), (88.24, PEN_DOWN_Z, -119.53), (88.12, PEN_DOWN_Z, -119.53), (88.0, PEN_DOWN_Z, -119.65), (87.88, PEN_DOWN_Z, -119.65), (87.65, PEN_DOWN_Z, -119.88), (87.41, PEN_DOWN_Z, -119.88), (87.29, PEN_DOWN_Z, -120.0), (87.18, PEN_DOWN_Z, -120.0), (87.06, PEN_DOWN_Z, -120.12), (86.94, PEN_DOWN_Z, -120.12), (86.71, PEN_DOWN_Z, -120.35), (86.35, PEN_DOWN_Z, -120.35), (86.24, PEN_DOWN_Z, -120.47), (86.24, PEN_DOWN_Z, -120.71), (86.35, PEN_DOWN_Z, -120.82), (86.35, PEN_DOWN_Z, -120.94), (86.47, PEN_DOWN_Z, -121.06), (87.06, PEN_DOWN_Z, -121.06), (87.29, PEN_DOWN_Z, -120.82), (87.65, PEN_DOWN_Z, -120.82), (87.88, PEN_DOWN_Z, -120.59), (88.0, PEN_DOWN_Z, -120.59), (88.12, PEN_DOWN_Z, -120.47), (88.24, PEN_DOWN_Z, -120.47), (88.35, PEN_DOWN_Z, -120.35), (88.47, PEN_DOWN_Z, -120.35), (88.82, PEN_DOWN_Z, -120.0), (88.94, PEN_DOWN_Z, -120.0), (89.65, PEN_DOWN_Z, -119.29), (89.65, PEN_DOWN_Z, -119.18), (89.88, PEN_DOWN_Z, -118.94), (89.88, PEN_DOWN_Z, -118.82), (90.0, PEN_DOWN_Z, -118.71), (90.0, PEN_DOWN_Z, -118.47), (90.24, PEN_DOWN_Z, -118.24), (90.24, PEN_DOWN_Z, -117.88), (90.35, PEN_DOWN_Z, -117.76), (90.35, PEN_DOWN_Z, -117.53), (90.47, PEN_DOWN_Z, -117.41), (90.47, PEN_DOWN_Z, -117.18), (90.59, PEN_DOWN_Z, -117.06), (90.59, PEN_DOWN_Z, -116.82), (90.71, PEN_DOWN_Z, -116.71), (90.71, PEN_DOWN_Z, -116.24), (90.82, PEN_DOWN_Z, -116.12), (90.82, PEN_DOWN_Z, -115.65), (90.59, PEN_DOWN_Z, -115.65), (90.47, PEN_DOWN_Z, -115.53), (90.47, -15.0, -115.53), (93.53, -15.0, -115.06), (93.53, PEN_DOWN_Z, -115.06), (93.65, PEN_DOWN_Z, -115.18), (93.76, PEN_DOWN_Z, -115.18), (94.12, PEN_DOWN_Z, -115.53), (94.12, PEN_DOWN_Z, -115.65), (94.35, PEN_DOWN_Z, -115.88), (94.35, PEN_DOWN_Z, -116.12), (94.47, PEN_DOWN_Z, -116.24), (94.47, PEN_DOWN_Z, -116.59), (94.59, PEN_DOWN_Z, -116.71), (94.59, PEN_DOWN_Z, -118.12), (94.47, PEN_DOWN_Z, -118.24), (94.47, PEN_DOWN_Z, -118.71), (94.35, PEN_DOWN_Z, -118.82), (94.35, PEN_DOWN_Z, -119.18), (94.24, PEN_DOWN_Z, -119.29), (94.24, PEN_DOWN_Z, -119.53), (94.12, PEN_DOWN_Z, -119.65), (94.12, PEN_DOWN_Z, -119.76), (94.0, PEN_DOWN_Z, -119.88), (94.0, PEN_DOWN_Z, -120.0), (93.88, PEN_DOWN_Z, -120.12), (93.88, PEN_DOWN_Z, -120.24), (93.76, PEN_DOWN_Z, -120.35), (93.76, PEN_DOWN_Z, -120.47), (92.71, PEN_DOWN_Z, -121.53), (92.59, PEN_DOWN_Z, -121.53), (92.47, PEN_DOWN_Z, -121.65), (92.35, PEN_DOWN_Z, -121.65), (92.12, PEN_DOWN_Z, -121.88), (92.24, PEN_DOWN_Z, -122.0), (92.47, PEN_DOWN_Z, -122.0), (92.59, PEN_DOWN_Z, -121.88), (92.71, PEN_DOWN_Z, -121.88), (92.94, PEN_DOWN_Z, -121.65), (93.06, PEN_DOWN_Z, -121.65), (93.76, PEN_DOWN_Z, -120.94), (93.76, PEN_DOWN_Z, -120.82), (94.0, PEN_DOWN_Z, -120.59), (94.0, PEN_DOWN_Z, -120.47), (94.12, PEN_DOWN_Z, -120.35), (94.12, PEN_DOWN_Z, -120.24), (94.35, PEN_DOWN_Z, -120.0), (94.35, PEN_DOWN_Z, -119.88), (94.47, PEN_DOWN_Z, -119.76), (94.47, PEN_DOWN_Z, -119.53), (94.59, PEN_DOWN_Z, -119.41), (94.59, PEN_DOWN_Z, -119.29), (94.71, PEN_DOWN_Z, -119.18), (94.71, PEN_DOWN_Z, -118.82), (94.82, PEN_DOWN_Z, -118.71), (94.82, PEN_DOWN_Z, -118.24), (94.94, PEN_DOWN_Z, -118.12), (94.94, PEN_DOWN_Z, -116.71), (94.82, PEN_DOWN_Z, -116.59), (94.82, PEN_DOWN_Z, -116.24), (94.71, PEN_DOWN_Z, -116.12), (94.71, PEN_DOWN_Z, -116.0), (94.59, PEN_DOWN_Z, -115.88), (94.59, PEN_DOWN_Z, -115.76), (94.47, PEN_DOWN_Z, -115.65), (94.47, PEN_DOWN_Z, -115.53), (93.76, PEN_DOWN_Z, -114.82), (93.76, -15.0, -114.82), (93.76, -15.0, -114.82), (93.76, PEN_DOWN_Z, -114.82), (93.53, PEN_DOWN_Z, -115.06), (93.53, PEN_DOWN_Z, -115.18), (93.65, PEN_DOWN_Z, -115.18), (94.12, PEN_DOWN_Z, -115.65), (94.12, PEN_DOWN_Z, -115.76), (94.35, PEN_DOWN_Z, -116.0), (94.35, PEN_DOWN_Z, -116.12), (94.47, PEN_DOWN_Z, -116.24), (94.47, PEN_DOWN_Z, -116.59), (94.59, PEN_DOWN_Z, -116.71), (94.59, PEN_DOWN_Z, -118.12), (94.47, PEN_DOWN_Z, -118.24), (94.47, PEN_DOWN_Z, -118.71), (94.35, PEN_DOWN_Z, -118.82), (94.35, PEN_DOWN_Z, -119.18), (94.24, PEN_DOWN_Z, -119.29), (94.24, PEN_DOWN_Z, -119.41), (94.12, PEN_DOWN_Z, -119.53), (94.12, PEN_DOWN_Z, -119.65), (94.0, PEN_DOWN_Z, -119.76), (94.0, PEN_DOWN_Z, -119.88), (93.88, PEN_DOWN_Z, -120.0), (93.88, PEN_DOWN_Z, -120.12), (93.76, PEN_DOWN_Z, -120.24), (93.76, PEN_DOWN_Z, -120.35), (92.59, PEN_DOWN_Z, -121.53), (92.47, PEN_DOWN_Z, -121.53), (92.35, PEN_DOWN_Z, -121.65), (92.24, PEN_DOWN_Z, -121.65), (92.12, PEN_DOWN_Z, -121.76), (92.12, PEN_DOWN_Z, -122.0), (92.59, PEN_DOWN_Z, -122.0), (92.71, PEN_DOWN_Z, -121.88), (92.82, PEN_DOWN_Z, -121.88), (93.06, PEN_DOWN_Z, -121.65), (93.18, PEN_DOWN_Z, -121.65), (93.76, PEN_DOWN_Z, -121.06), (93.76, PEN_DOWN_Z, -120.94), (94.0, PEN_DOWN_Z, -120.71), (94.0, PEN_DOWN_Z, -120.59), (94.12, PEN_DOWN_Z, -120.47), (94.12, PEN_DOWN_Z, -120.35), (94.35, PEN_DOWN_Z, -120.12), (94.35, PEN_DOWN_Z, -119.88), (94.47, PEN_DOWN_Z, -119.76), (94.47, PEN_DOWN_Z, -119.65), (94.59, PEN_DOWN_Z, -119.53), (94.59, PEN_DOWN_Z, -119.29), (94.71, PEN_DOWN_Z, -119.18), (94.71, PEN_DOWN_Z, -118.82), (94.82, PEN_DOWN_Z, -118.71), (94.82, PEN_DOWN_Z, -118.24), (94.94, PEN_DOWN_Z, -118.12), (94.94, PEN_DOWN_Z, -116.71), (94.82, PEN_DOWN_Z, -116.59), (94.82, PEN_DOWN_Z, -116.24), (94.71, PEN_DOWN_Z, -116.12), (94.71, PEN_DOWN_Z, -115.88), (94.59, PEN_DOWN_Z, -115.76), (94.59, PEN_DOWN_Z, -115.65), (94.47, PEN_DOWN_Z, -115.53), (94.47, PEN_DOWN_Z, -115.41), (93.88, PEN_DOWN_Z, -114.82), (93.88, -15.0, -114.82))


def create_signature_commands(points):
    """Converts raw signature points (X, Z, Y) into robot commands."""
    commands = []
    if not points:
        return commands

    # 1. Move to the start of the signature with Pen Up
    start_x, _, start_y = points[0] # Use X, Y from the first point
    commands.append((start_x, PEN_UP_Z, start_y)) # Ensure pen is up

    # 2. Add all signature points as commands (using their specified Z)
    for point in points:
        commands.append(point) # Add the point (x, z, y) directly

    # 3. Lift pen after the last point
    if commands:
        last_x, _, last_y = points[-1]
        commands.append((last_x, PEN_UP_Z, last_y)) # Lift pen at the end

    return commands


# --- Drawing Helper Function ---
def calculate_distance(p1, p2):
    """Calculates Euclidean distance between two points (x, y)."""
    if p1 is None or p2 is None: return float('inf')
    return math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)

# --- Drawing Image Processing Functions ---
def image_to_contours_internal(image_path_or_array, threshold1, threshold2, save_edge_path=None):
    """
    Internal version: Convert image to contours using specific thresholds.
    Can accept a file path OR a pre-loaded cv2 image array.
    Does NOT print status messages.
    :param image_path_or_array: Path to the input image or numpy array (BGR or Grayscale).
    :param threshold1: Lower threshold for Canny edge detection.
    :param threshold2: Upper threshold for Canny edge detection.
    :param save_edge_path: Optional path to save the edge image for preview.
    :return: List of contours (pixel coordinates), image_width, image_height, or (None, 0, 0) on failure.
    """
    if isinstance(image_path_or_array, str):
        image = cv2.imread(image_path_or_array, cv2.IMREAD_GRAYSCALE)
    elif isinstance(image_path_or_array, np.ndarray):
        if len(image_path_or_array.shape) == 3: # BGR
            image = cv2.cvtColor(image_path_or_array, cv2.COLOR_BGR2GRAY)
        else: # Assuming already grayscale
            image = image_path_or_array
    else:
        logging.error("Invalid input type for image_to_contours_internal")
        return None, 0, 0

    if image is None:
        logging.error(f"Could not read or process image input.")
        return None, 0, 0

    image_height, image_width = image.shape[:2]
    if image_height == 0 or image_width == 0:
         logging.error("Invalid image dimensions.")
         return None, 0, 0

    blurred = cv2.GaussianBlur(image, (5, 5), 0)
    edges = cv2.Canny(blurred, threshold1, threshold2)

    if save_edge_path:
        try:
            cv2.imwrite(save_edge_path, edges)
        except Exception as e:
            logging.error(f"Failed to save edge image to {save_edge_path}: {e}")

    contours, hierarchy = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    filtered_contours = [c for c in contours if cv2.arcLength(c, closed=False) > MIN_CONTOUR_LENGTH_PX]

    contours_xy = []
    for contour in filtered_contours:
        points = contour.squeeze().tolist()
        if not isinstance(points, list) or not points: continue # Skip empty squeezes
        if isinstance(points[0], int): # Handle single point contour
            points = [points]
        contours_xy.append([(p[0], p[1]) for p in points if isinstance(p, (list, tuple)) and len(p) == 2]) # Ensure points are valid pairs

    # Filter out empty contours that might result from the above processing
    contours_xy = [c for c in contours_xy if c]

    return contours_xy, image_width, image_height


def scale_point_to_a4(point_xy, image_width, image_height, scale_factor):
    """ Scales and transforms a single (x, y) pixel coordinate to centered A4 (mm)."""
    x_pixel, y_pixel = point_xy
    center_x_pixel = image_width / 2
    center_y_pixel = image_height / 2
    x_centered_pixel = x_pixel - center_x_pixel
    y_centered_pixel = center_y_pixel - y_pixel # Invert y-axis
    x_mm = x_centered_pixel * scale_factor
    y_mm = y_centered_pixel * scale_factor
    return (x_mm, y_mm)

def create_drawing_paths(contours_xy, image_width, image_height, optimize_paths=True):
    """ Takes list of contours (pixel coordinates), scales them, creates drawing paths."""
    if not contours_xy or image_width <= 0 or image_height <= 0:
        return []

    scale_x = A4_WIDTH_MM / image_width
    scale_y = A4_HEIGHT_MM / image_height
    scale_factor = min(scale_x, scale_y)

    scaled_contours = []
    for contour in contours_xy:
        # Ensure contour is not empty before scaling
        if not contour: continue
        scaled_contour = [scale_point_to_a4(p, image_width, image_height, scale_factor) for p in contour]
        if len(scaled_contour) >= 2:
            scaled_contours.append(scaled_contour)
        elif len(scaled_contour) == 1 :
             # Handle single points - represent as a tiny segment back to itself?
             # This ensures it gets processed for pen down/up at least.
            scaled_contours.append([scaled_contour[0], scaled_contour[0]])


    if not scaled_contours:
        return []

    ordered_contours = []
    last_point = None # Keep track of the last point of the previously added contour
    if optimize_paths:
        remaining_contours = list(scaled_contours)
        # Find a starting contour (e.g., closest to origin, or just the first)
        # For simplicity, start with the first one if available.
        if remaining_contours:
             current_contour = remaining_contours.pop(0)
             ordered_contours.append(current_contour)
             last_point = current_contour[-1]

             while remaining_contours:
                 best_dist = float('inf')
                 best_idx = -1
                 best_reversed = False

                 for i, contour in enumerate(remaining_contours):
                     start_point = contour[0]
                     end_point = contour[-1]
                     dist_start = calculate_distance(last_point, start_point)
                     dist_end = calculate_distance(last_point, end_point)

                     if dist_start < best_dist:
                         best_dist = dist_start
                         best_idx = i
                         best_reversed = False
                     if dist_end < best_dist: # Check second condition independently
                         best_dist = dist_end
                         best_idx = i
                         best_reversed = True

                 if best_idx != -1:
                      next_contour = remaining_contours.pop(best_idx)
                      if best_reversed:
                          next_contour.reverse()
                      ordered_contours.append(next_contour)
                      last_point = next_contour[-1]
                 else:
                    # Should not happen if remaining_contours is not empty, but break just in case
                   logging.warning("Path optimization loop finished unexpectedly.")
                   break # Avoid infinite loop if something goes wrong
        scaled_contours = ordered_contours # Use the optimized order
        # logging.info(f"Optimized contour drawing order.") # Reduce noise
    else:
         # If not optimizing, just use the original order
         scaled_contours = [c for c in scaled_contours] # Ensure it's a list copy if needed


    robot_commands = []
    for contour in scaled_contours:
        if not contour: continue # Should not happen, but safe check
        start_point = contour[0]
        robot_commands.append((start_point[0], PEN_UP_Z, start_point[1])) # Move pen up to start X, Y
        robot_commands.append((start_point[0], PEN_DOWN_Z, start_point[1])) # Move pen down at start X, Y

        for i in range(len(contour) - 1):
            end_point = contour[i+1]
            # Avoid duplicate commands for single-point contours handled earlier
            if end_point != contour[i]:
                robot_commands.append((end_point[0], PEN_DOWN_Z, end_point[1])) # Draw to next point

        final_point = contour[-1]
        robot_commands.append((final_point[0], PEN_UP_Z, final_point[1])) # Lift pen at the end of contour

    return robot_commands


class RUNME_GUI:
    """Main GUI application for the Robotics System."""

    def __init__(self):
        self.window = tk.Tk()
        self.window.title("Robotics Drawing GUI")
        self.main_frame = tk.Frame(self.window)
        self.main_frame.pack(pady=20, padx=20, fill="both", expand=True)

        # Connection related variables
        self.connection_var = tk.StringVar(value="simulation")
        self.socket = None
        self.connected = False
        self.connection_established = False
        # self.positions = [] # Removed, not used for drawing 

        # Camera related variables
        self.cap = None
        self.camera_running = False
        self.camera_frame_label = None # Label to display camera feed 
        self.capture_button = None
        self.camera_back_button = None

        # Drawing process related
        self.current_image_path = None # Path to the image being processed
        self.threshold_options_data = {} # Store commands for each threshold choice
        self.selected_commands = None
        self.drawing_in_progress = False
        self.cancel_requested = False # *** NEW: Flag for cancellation ***
        self.progress_bar = None
        self.status_label = None
        self.cancel_button = None # *** NEW: Reference to cancel button ***
        self.reconnect_button = None # *** NEW: Reference to reconnect button ***

        self.last_drawing_status = {
            "total_commands": 0,
            "completed_commands": 0,
            "status": "None",  # e.g., "Completed", "Cancelled", "Connection Lost", "Protocol Error", "Failed to Resume"
            "error_message": ""
        }
        
        # Resume related variables
        self.resume_needed = False # *** NEW: Flag indicating connection was lost during drawing ***
        self.resume_commands = None # *** NEW: Store remaining commands ***
        self.resume_total_original_commands = 0 # *** NEW: Store original total for progress bar ***
        self.resume_start_index_global = 0 # *** NEW: Store the global index to resume from ***

        self.main_page()

    # --- Page Navigation ---
    def main_page(self):
        """Main application page."""
        self.clear_frame()
        tk.Label(self.main_frame, text="Robotics Drawing System", font=("Arial", 16)).pack(pady=10)
        tk.Button(self.main_frame, text="Setup Connection & Draw",
                  command=self.connection_setup_page, width=30).pack(pady=5)
        # tk.Button(self.main_frame, text="Camera Calibration", # Keep if needed 
        #           command=self.calibration_page, width=30).pack(pady=5) 
        tk.Button(self.main_frame, text="Exit",
                  command=self.on_window_close, width=30).pack(pady=5) # Call proper close handler

    def connection_setup_page(self):
        """Page for setting up robot connection."""
        # Simplified - remove radio buttons if only one target is needed often
        # Or keep as is 
        self.clear_frame()
        tk.Label(self.main_frame, text="Robot Connection Setup", font=("Arial", 16)).pack(pady=10)

        connection_frame = tk.Frame(self.main_frame)
        connection_frame.pack(pady=10)
        tk.Radiobutton(connection_frame, text=f"Simulation: {SIMULATION_HOST}:{SIMULATION_PORT}",
                       variable=self.connection_var, value="simulation").pack(anchor='w')
        tk.Radiobutton(connection_frame, text=f"Real Robot: {REAL_ROBOT_HOST}:{REAL_ROBOT_PORT}",
                       variable=self.connection_var, value="real").pack(anchor='w')

        # *** NEW: Conditionally show Connect or Reconnect & Resume button ***
        self.connect_button = tk.Button(self.main_frame, text="Connect", command=self.establish_connection, width=20)
        self.reconnect_button = tk.Button(self.main_frame, text="Reconnect & Resume", command=self.establish_connection, width=20) # Same command

        if self.resume_needed:
            self.reconnect_button.pack(pady=5)
            tk.Label(self.main_frame, text="Connection lost during last drawing. Reconnect to resume.", fg="orange").pack()
        else:
            self.connect_button.pack(pady=5)

        tk.Button(self.main_frame, text="Back", command=self.main_page, width=20).pack(pady=5) # Go back to main page

    def drawing_options_page(self):
        """Page shown after successful connection."""
        if not self.connection_established:
            messagebox.showerror("Connection Required", "Please establish connection first.")
            self.connection_setup_page()
            return

        self.clear_frame()
        tk.Label(self.main_frame, text="Robot Drawing Options", font=("Arial", 16)).pack(pady=10)
        conn_type = "Simulation" if self.connection_var.get() == "simulation" else "Real Robot"
        tk.Label(self.main_frame, text=f"Connected to: {conn_type}", fg="green").pack(pady=5)
        last_status = self.last_drawing_status["status"]
        if last_status not in ["None", "Completed"]:
            status_frame = tk.Frame(self.main_frame, relief=tk.RIDGE, borderwidth=2)
            status_frame.pack(pady=10, padx=10, fill='x')
            tk.Label(status_frame, text="Previous Drawing Status:", font=("Arial", 10, "bold")).pack(anchor='w')
            status_text = f"Status: {last_status}"
            if self.last_drawing_status["total_commands"] > 0:
                status_text += f" (Stopped at command {self.last_drawing_status['completed_commands'] + 1}" \
                                f" of {self.last_drawing_status['total_commands']})"
            tk.Label(status_frame, text=status_text).pack(anchor='w', padx=5)
            if self.last_drawing_status["error_message"]:
                tk.Label(status_frame, text=f"Details: {self.last_drawing_status['error_message']}", wraplength=400).pack(anchor='w', padx=5)


        tk.Button(self.main_frame, text="Capture Image to Draw",
                  command=self.capture_image_page, width=30).pack(pady=5) # Changed command
        tk.Button(self.main_frame, text="Input Image to Draw",
                  command=self.input_image_page, width=30).pack(pady=5) # Changed command
        tk.Button(self.main_frame, text="Disconnect",
                  command=self.close_and_return_main, width=30).pack(pady=5)

    # --- Capture Image Workflow ---
    def capture_image_page(self):
        """Opens camera view for capturing."""
        self.clear_frame()
        tk.Label(self.main_frame, text="Camera View", font=("Arial", 16)).pack(pady=5)

        self.camera_frame_label = tk.Label(self.main_frame)
        self.camera_frame_label.pack(pady=10)

        button_frame = tk.Frame(self.main_frame)
        button_frame.pack(pady=5)

        self.capture_button = tk.Button(button_frame, text="Capture (S)", command=self.capture_action)
        self.capture_button.pack(side=tk.LEFT, padx=5)
        self.camera_back_button = tk.Button(button_frame, text="Back", command=self.stop_camera_and_go_back)
        self.camera_back_button.pack(side=tk.LEFT, padx=5)

        # Bind 's' key
        self.window.bind('s', self.capture_action_event)
        self.window.bind('S', self.capture_action_event) # Also capital S

        self.start_camera_feed()

    def start_camera_feed(self):
        """Starts displaying the camera feed."""
        if self.camera_running: return # Already running

        try:
            self.cap = cv2.VideoCapture(0) # Use default camera 
            if not self.cap.isOpened():
                messagebox.showerror("Camera Error", "Could not open camera.")
                self.stop_camera_and_go_back()
                return
            self.camera_running = True
            self._update_camera_frame() # Start the update loop
        except Exception as e:
             messagebox.showerror("Camera Error", f"Error initializing camera: {e}")
             self.stop_camera_and_go_back()


    def _update_camera_frame(self):
        """Internal method to continuously update the camera feed label."""
        if not self.camera_running or not self.cap:
             return

        ret, frame = self.cap.read()
        if ret:
            # Convert frame for Tkinter
            cv_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(cv_image)
            # Resize image to fit nicely (optional)
            # aspect_ratio = pil_image.width / pil_image.height 
            # new_height = 300
            # new_width = int(aspect_ratio * new_height) 
            # pil_image = pil_image.resize((new_width, new_height), Image.Resampling.LANCZOS) 

            imgtk = ImageTk.PhotoImage(image=pil_image)

            if self.camera_frame_label: # Check if label still exists
                self.camera_frame_label.imgtk = imgtk
                self.camera_frame_label.configure(image=imgtk)
        else:
            logging.warning("Failed to grab frame from camera.")
            # Optionally try to reopen or show error after multiple failures

        # Schedule the next update
        if self.camera_running:
            self.window.after(30, self._update_camera_frame) # Update ~30fps

    def stop_camera_feed(self):
         """Stops the camera feed and releases resources."""
         self.camera_running = False # Signal the loop to stop
         time.sleep(0.1) # Give the loop a moment to exit
         if self.cap:
              self.cap.release()
              self.cap = None
         # cv2.destroyAllWindows() # Don't destroy all, might affect other CV windows if used 

    def stop_camera_and_go_back(self):
        """Stops camera and returns to drawing options page."""
        self.stop_camera_feed()
        self.window.unbind('s') # Unbind keys
        self.window.unbind('S')
        self.drawing_options_page() # Go back

    def capture_action_event(self, event=None):
         """Wrapper for key press event."""
         self.capture_action()

    def capture_action(self):
        """Captures the current frame and processes it."""
        if not self.camera_running or not self.cap:
            messagebox.showwarning("Capture Error", "Camera not running.")
            return

        ret, frame = self.cap.read()
        self.stop_camera_feed() # Stop feed after capture
        self.window.unbind('s') # Unbind keys
        self.window.unbind('S')


        if ret:
            try:
                # Ensure DATA_DIR exists
                os.makedirs(DATA_DIR, exist_ok=True)
                cv2.imwrite(TMP_CAPTURE_PATH, frame)
                logging.info(f"Image captured and saved to {TMP_CAPTURE_PATH}")
                self.current_image_path = TMP_CAPTURE_PATH
                # Proceed to threshold selection
                self.show_threshold_options(self.current_image_path)
            except Exception as e:
                messagebox.showerror("Save Error", f"Could not save captured image: {e}")
                self.drawing_options_page() # Go back on error
        else:
            messagebox.showerror("Capture Error", "Failed to capture frame from camera.")
            self.drawing_options_page() # Go back on error


    # --- Input Image Workflow ---
    def input_image_page(self):
        """Page for selecting an image file."""
        self.clear_frame()
        tk.Label(self.main_frame, text="Input Image to Draw", font=("Arial", 16)).pack(pady=10)

        entry_frame = tk.Frame(self.main_frame)
        entry_frame.pack(pady=5, fill='x', padx=10)
        tk.Label(entry_frame, text="Image Path:").pack(side=tk.LEFT)
        self.image_path_var = tk.StringVar()
        path_entry = tk.Entry(entry_frame, textvariable=self.image_path_var, width=50)
        path_entry.pack(side=tk.LEFT, fill='x', expand=True, padx=5)
        tk.Button(entry_frame, text="Browse...", command=self.browse_image_file).pack(side=tk.LEFT)

        # Placeholder for drag-and-drop - requires tkinterdnd2
        # drop_target = tk.Label(self.main_frame, text="Or Drag and Drop Image Here", relief="ridge", height=5, width=60) 
        # drop_target.pack(pady=10)
        # drop_target.drop_target_register(DND_FILES) 
        # drop_target.dnd_bind('<<Drop>>', self.handle_drop) 

        tk.Button(self.main_frame, text="Process Image", command=self.process_input_image, width=20).pack(pady=10)
        tk.Button(self.main_frame, text="Back", command=self.drawing_options_page, width=20).pack(pady=10)

    def browse_image_file(self):
        """Opens file dialog to select an image."""
        filepath = filedialog.askopenfilename(
            title="Select Image to Draw", 
            filetypes=[("Image Files", "*.png *.jpg *.jpeg *.bmp *.gif"), ("All Files", "*.*")]
        )
        if filepath:
            self.image_path_var.set(filepath)

    # def handle_drop(self, event): # Requires tkinterdnd2 
    #     """Handles file drop event.""" 
    #     filepath = event.data.strip('{}') # Clean up path if needed 
    #     if os.path.isfile(filepath):
    #          self.image_path_var.set(filepath) 
    #     else: 
    #          messagebox.showwarning("Drop Error", f"Invalid file dropped: {filepath}") 


    def process_input_image(self):
        """Validates path and proceeds to threshold selection."""
        filepath = self.image_path_var.get()
        if not filepath or not os.path.isfile(filepath):
            messagebox.showerror("Error", f"Invalid or non-existent file path:\n{filepath}")
            return
        self.current_image_path = filepath
        self.show_threshold_options(self.current_image_path)


    # --- Threshold Selection Workflow ---
    def show_threshold_options(self, image_path):
        """Processes image with different thresholds and shows options."""
        self.clear_frame()
        tk.Label(self.main_frame, text="Select Drawing Style (Thresholds)", font=("Arial", 16)).pack(pady=10)

        self.threshold_options_data = {} # Clear previous results
        self.selected_threshold_option = tk.StringVar(value=None) # Variable for Radiobuttons
        self.preview_label = tk.Label(self.main_frame) # For showing edge previews
        self.preview_label.pack(pady=5)

        options_frame = tk.Frame(self.main_frame)
        options_frame.pack(pady=5)

        # Process each option in background to avoid freezing GUI
        loading_label = tk.Label(options_frame, text="Processing options...")
        loading_label.pack()
        self.window.update() # Show loading message 

        threading.Thread(target=self._process_threshold_options_thread, args=(image_path, options_frame, loading_label), daemon=True).start()


    def _process_threshold_options_thread(self, image_path, options_frame, loading_label):
        """Background thread to generate commands for each threshold option."""
        results = {}
        preview_paths = {} # Store paths to preview images

        for i, (label, t1, t2) in enumerate(THRESHOLD_OPTIONS):
            logging.info(f"Processing option: {label} (t1={t1}, t2={t2})")
            preview_path = TMP_EDGE_OUTPUT_PATH.format(i) # Unique path for preview
            contours_xy, w, h = image_to_contours_internal(image_path, t1, t2, save_edge_path=preview_path)

            if contours_xy is None or w == 0 or h == 0:
                 logging.warning(f"Failed to process contours for option {label}")
                 results[label] = None # Indicate failure 
                 preview_paths[label] = None
                 continue

            commands = create_drawing_paths(contours_xy, w, h, optimize_paths=True)
            if commands:
                num_commands = len(commands)
                est_time_sec = num_commands * TIME_ESTIMATE_FACTOR
                est_time_min = est_time_sec / 60
                results[label] = {
                    "commands": commands, 
                    "count": num_commands,
                    "time_str": f"{est_time_min:.1f} min",
                    "t1": t1,
                    "t2": t2
                }
                preview_paths[label] = preview_path if os.path.exists(preview_path) else None
            else:
                 results[label] = None # No commands generated
                 preview_paths[label] = None
                 logging.warning(f"No commands generated for option {label}")

        # Update GUI from the main thread
        self.window.after(0, lambda: self._display_threshold_options(options_frame, loading_label, results, preview_paths))


    def _display_threshold_options(self, options_frame, loading_label, results, preview_paths):
         """Updates the GUI with the processed threshold options."""
         loading_label.destroy() # Remove loading message

         self.threshold_options_data = results # Store results
         self.edge_preview_paths = preview_paths # Store preview paths

         default_selected = False
         for i, (label, t1, t2) in enumerate(THRESHOLD_OPTIONS):
             option_data = results.get(label)
             if option_data:
                 count = option_data["count"]
                 time_str = option_data["time_str"]
                 radio_text = f"{label} (t1={t1}, t2={t2}) - Cmds: {count}, Est: {time_str}"
                 rb = tk.Radiobutton(
                    options_frame, 
                 text=radio_text,
                 variable=self.selected_threshold_option,
                 value=label,
                 command=lambda l=label: self.show_edge_preview(l) # Show preview on select
                 )
                 rb.pack(anchor='w')
                 # Select the first valid option by default
                 if not default_selected:
                      self.selected_threshold_option.set(label)
                      self.show_edge_preview(label) # Show its preview
                      default_selected = True
             else:
                 # Option failed or produced no commands
                 tk.Label(options_frame, text=f"{label} (t1={t1}, t2={t2}) - No drawing generated", fg="gray").pack(anchor='w')

         # Add Confirm and Back buttons below the options
         button_frame = tk.Frame(self.main_frame)
         button_frame.pack(pady=10)
         tk.Button(button_frame, text="Confirm and Draw", command=self.confirm_and_start_drawing, width=20).pack(side=tk.LEFT, padx=5)
         # Back button should go back to the drawing options page (Capture/Input)
         tk.Button(button_frame, text="Back", command=self.drawing_options_page, width=20).pack(side=tk.LEFT, padx=5)

    def show_edge_preview(self, option_label):
         """Displays the edge preview image for the selected option."""
         preview_path = self.edge_preview_paths.get(option_label)
         if preview_path and os.path.exists(preview_path):
              try:
                   img = Image.open(preview_path)
                   # Resize for display
                   img.thumbnail((300, 300)) # Max width/height 300px
                   imgtk = ImageTk.PhotoImage(image=img)
                   self.preview_label.imgtk = imgtk
                   self.preview_label.configure(image=imgtk)
              except Exception as e:
                   logging.error(f"Error loading preview image {preview_path}: {e}")
                   self.preview_label.configure(image=None, text="Preview error") # Clear preview
         else:
              self.preview_label.configure(image=None, text="No Preview") # Clear preview


    def confirm_and_start_drawing(self):
        """Gets selected commands and starts the drawing process."""
        selected_label = self.selected_threshold_option.get()
        if not selected_label:
            messagebox.showwarning("Selection Needed", "Please select a drawing style option.")
            return

        option_data = self.threshold_options_data.get(selected_label)
        if not option_data or not option_data.get("commands"):
             messagebox.showerror("Error", "Selected option has no drawing commands.")
             return

        self.selected_commands = option_data["commands"]

        # Start drawing in a background thread
        if not self.drawing_in_progress:
             self.drawing_in_progress = True
             self.cancel_requested = False # Ensure cancel flag is reset
             self.resume_needed = False # Reset resume flag
             # *** Pass the full command list including signature ***
             full_command_list = self.selected_commands + create_signature_commands(SIGNATURE_POINTS)
             threading.Thread(target=self.run_drawing_loop, args=(full_command_list,), daemon=True).start()
             self.show_drawing_progress_page(len(full_command_list)) # Show progress UI with total commands
        else:
            messagebox.showwarning("Busy", "Drawing already in progress.")


    # --- Drawing Execution Workflow ---
    def show_drawing_progress_page(self, total_commands, current_progress=0, status_message="Starting..."):
         """Displays the progress bar and status during drawing."""
         self.clear_frame()
         tk.Label(self.main_frame, text="Drawing in Progress...", font=("Arial", 16)).pack(pady=10)

         self.status_label = tk.Label(self.main_frame, text=status_message)
         self.status_label.pack(pady=5)

         self.progress_bar = ttk.Progressbar(self.main_frame, orient="horizontal", length=300, mode="determinate", maximum=total_commands, value=current_progress)
         self.progress_bar.pack(pady=10)

         # *** NEW: Add Cancel Button ***
         self.cancel_button = tk.Button(self.main_frame, text="Cancel Drawing", command=self.request_cancel_drawing)
         self.cancel_button.pack(pady=5)


    def update_drawing_status(self, current_command_index, total_commands, message=""):
        """Callback to update progress bar and status label from drawing thread."""
        if self.progress_bar and self.progress_bar.winfo_exists():
            self.progress_bar['value'] = current_command_index
        if self.status_label and self.status_label.winfo_exists():
            status_text = f"Sent {current_command_index} / {total_commands} commands"
            if message:
                 status_text += f" ({message})"
            self.status_label.config(text=status_text)
            # self.window.update_idletasks() # Force update if needed, but 'after' usually handles it 

    def request_cancel_drawing(self):
        """Sets the cancellation flag when the Cancel button is pressed."""
        if self.drawing_in_progress:
            logging.info("Cancel requested by user.")
            self.cancel_requested = True
            if self.cancel_button and self.cancel_button.winfo_exists():
                self.cancel_button.config(text="Cancelling...", state=tk.DISABLED)
            if self.status_label and self.status_label.winfo_exists():
                self.status_label.config(text="Cancellation requested...")

    def _send_final_position_and_cleanup(self, success_message, failure_message):
        """Sends the robot to the final position and cleans up state. Runs in drawing thread."""
        logging.info("Attempting to move robot to final position.")
        final_x, final_z, final_y = FINAL_ROBOT_POSITION
        command_str_final = f"{final_x:.3f},{final_z:.3f},{final_y:.3f}" # Format final command 

        move_ok = False
        if self.connected and self.socket:
            if self.send_message_internal(command_str_final):
                response_r_final = self.receive_message_internal(timeout=20.0)
                if response_r_final == "R":
                    response_d_final = self.receive_message_internal(timeout=30.0) # Longer timeout for final move
                    if response_d_final == "D":
                        logging.info("Robot reached final position.") #
                        move_ok = True
                    else:
                        logging.error(f"Robot didn't confirm final move completion (D), got '{response_d_final}'") #
                else:
                    logging.error(f"Robot didn't confirm final move receipt (R), got '{response_r_final}'") #
            else:
                logging.error("Failed to send final position command.") #

        # Update GUI status based on move success/failure and original reason
        final_status = ""
        if move_ok:
            final_status = f"{success_message} Robot at final position."
        else:
            final_status = f"{failure_message} Failed to reach final position."

        self.last_drawing_status["status"] = success_message # Use the original reason (Completed, Cancelled, etc.)
        self.last_drawing_status["error_message"] = "" if move_ok else "Failed to reach final position."

        self.window.after(0, lambda fs=final_status: self.update_final_status(fs))

        # --- Final Cleanup ---
        self.drawing_in_progress = False
        self.selected_commands = None
        self.cancel_requested = False
        # Reset resume state ONLY if the process finished (successfully or cancelled), not on disconnect
        if not self.resume_needed: # Don't clear resume state if we dropped connection
            self.resume_commands = None
            self.resume_total_original_commands = 0
            self.resume_start_index_global = 0

        # Go back to the drawing options page after a short delay
        self.window.after(2000, self.drawing_options_page) # Wait 2s before going back 

    def update_final_status(self, message):
        """Updates the status label safely from the main thread."""
        if self.status_label and self.status_label.winfo_exists():
            self.status_label.config(text=message)
        if self.cancel_button and self.cancel_button.winfo_exists():
            self.cancel_button.pack_forget() # Remove cancel button

    def run_drawing_loop(self, commands_to_send: List[Tuple], start_index=0):
        """Sends drawing commands sequentially (RUNS IN THREAD). Handles cancel and resume."""
        total_commands = len(commands_to_send) + start_index # Total original commands for progress bar max
        current_command_global_index = start_index # Start from the correct global index
        commands_processed_in_this_run = 0

        # If resuming, ensure progress page reflects original total and current progress
        if start_index > 0:
            self.window.after(0, lambda: self.show_drawing_progress_page(total_commands, current_command_global_index, "Resuming drawing..."))
            self.window.after(0, lambda: self.update_drawing_status(current_command_global_index, total_commands, "Resuming..."))
        else:
            self.window.after(0, lambda: self.update_drawing_status(0, total_commands, "Starting..."))

        try:
            # Iterate through the commands *starting from the correct index*
            for i, (x, z, y) in enumerate(commands_to_send[start_index:], start=start_index):
                current_command_global_index = i + 1 # Overall progress index (1-based)

                # *** NEW: Check for cancellation before sending ***
                if self.cancel_requested:
                    logging.info(f"Cancellation detected at command {current_command_global_index}.")
                    self.window.after(0, lambda idx=i: self.update_drawing_status(idx, total_commands, "Cancelling..."))
                    self._send_final_position_and_cleanup("Drawing Cancelled.", "Drawing Cancelled.")
                    return # Exit the thread

                # Format command
                command_str = f"{x:.2f},{z},{y:.2f}" # Format for robot 
                logging.debug(f"Sending command {current_command_global_index}/{total_commands}: {command_str}")

                # --- Robot Communication Protocol ---
                # 1. Send Command
                if not self.send_message_internal(command_str): # If send fails...
                    # *** NEW: Handle connection loss ***
                    logging.error(f"Connection lost while sending command {current_command_global_index}. Preparing to resume.")
                    self.resume_needed = True
                    # Save state relative to the *original full list*
                    self.resume_commands = commands_to_send # Keep the full list
                    self.resume_start_index_global = i # Save the index of the command that failed (0-based)
                    self.resume_total_original_commands = total_commands
                    
                    self.last_drawing_status["total_commands"] = total_commands
                    self.last_drawing_status["completed_commands"] = i # Command i failed
                    self.last_drawing_status["status"] = "Connection Lost"
                    self.last_drawing_status["error_message"] = f"Lost connection before sending command {i+1}"
                    
                    self.window.after(0, lambda idx=i: self.update_drawing_status(idx, total_commands, "Connection Lost!"))
                    self.window.after(1000, self.connection_setup_page) # Go to connection page to allow reconnect
                    self.drawing_in_progress = False # Allow reconnect button to work
                    return # Exit thread

                # 2. Wait for Receipt 'R'
                response_r = self.receive_message_internal(timeout=20.0) # If receive fails...
                if response_r is None: # Check for None indicating socket error/timeout
                    # *** NEW: Handle connection loss ***
                    logging.error(f"Connection lost while waiting for 'R' after command {current_command_global_index}. Preparing to resume.")
                    self.resume_needed = True
                    self.resume_commands = commands_to_send
                    self.resume_start_index_global = i # Resume from the command that wasn't fully confirmed
                    self.resume_total_original_commands = total_commands
                    self.window.after(0, lambda idx=i: self.update_drawing_status(idx, total_commands, "Connection Lost! (No 'R')"))
                    self.window.after(1000, self.connection_setup_page)
                    self.drawing_in_progress = False
                    return # Exit thread
                elif response_r != "R":
                    error_msg = f"Robot did not confirm receipt (R) for command {current_command_global_index}, got '{response_r}'."
                    logging.error(error_msg + " Preparing to resume.") # Changed log message
                    # *** NEW: Prepare for resume on 'R' error ***
                    self.resume_needed = True
                    self.resume_commands = commands_to_send
                    self.resume_start_index_global = i # Resume from the command that failed confirmation
                    self.resume_total_original_commands = total_commands
                    # Update last status
                    self.last_drawing_status["total_commands"] = total_commands
                    self.last_drawing_status["completed_commands"] = i
                    self.last_drawing_status["status"] = "Protocol Error (R)"
                    self.last_drawing_status["error_message"] = error_msg
                    # *** End NEW ***
                    self.window.after(0, lambda idx=i, r=response_r: self.update_drawing_status(idx, total_commands, f"Error: No 'R' (Got {r}). Reconnect to resume."))
                    # *** NEW: Go to connection page instead of cleanup ***
                    self.window.after(1000, self.connection_setup_page)
                    self.drawing_in_progress = False
                    return # Exit thread

                # 3. Wait for Done 'D'
                response_d = self.receive_message_internal(timeout=30.0) # Longer timeout for move completion 
                if response_d is None: # Check for None indicating socket error/timeout
                    # *** NEW: Handle connection loss ***
                    logging.error(f"Connection lost while waiting for 'D' after command {current_command_global_index}. Preparing to resume.")
                    self.resume_needed = True
                    self.resume_commands = commands_to_send
                    # Resume from the *next* command since this one completed movement but confirmation failed
                    self.resume_start_index_global = i + 1
                    self.resume_total_original_commands = total_commands
                    self.window.after(0, lambda idx=i: self.update_drawing_status(idx + 1, total_commands, "Connection Lost! (No 'D')")) # Show progress for completed command
                    self.window.after(1000, self.connection_setup_page)
                    self.drawing_in_progress = False
                    return # Exit thread
                elif response_d != "D":
                    error_msg = f"Robot did not confirm completion (D) for command {current_command_global_index}, got '{response_d}'."
                    logging.error(error_msg + " Preparing to resume.") # Changed log message
                    # *** NEW: Prepare for resume on 'D' error ***
                    self.resume_needed = True
                    self.resume_commands = commands_to_send
                    # Resume from the *next* command since 'R' was received, but 'D' failed
                    self.resume_start_index_global = i + 1
                    self.resume_total_original_commands = total_commands
                    # Update last status
                    self.last_drawing_status["total_commands"] = total_commands
                    self.last_drawing_status["completed_commands"] = i + 1 # Command i movement likely completed
                    self.last_drawing_status["status"] = "Protocol Error (D)"
                    self.last_drawing_status["error_message"] = error_msg
                    # *** End NEW ***
                    self.window.after(0, lambda idx=i, d=response_d: self.update_drawing_status(idx + 1, total_commands, f"Error: No 'D' (Got {d}). Reconnect to resume."))
                    # *** NEW: Go to connection page instead of cleanup ***
                    self.window.after(1000, self.connection_setup_page)
                    self.drawing_in_progress = False
                    return # Exit thread

                commands_processed_in_this_run += 1
                # Update GUI progress
                self.window.after(0, lambda idx=current_command_global_index: self.update_drawing_status(idx, total_commands)) # 

            # If the loop completes without cancellation or error
            logging.info("All drawing commands sent successfully.")
            self.window.after(0, lambda: self.update_drawing_status(total_commands, total_commands, "Drawing Complete."))
            self._send_final_position_and_cleanup("Drawing Complete.", "Drawing Complete.")

        except Exception as e:
            logging.error(f"Unexpected error during drawing process: {e}", exc_info=True) # 
            # Attempt to update status, but might fail if GUI is gone
            try:
                self.window.after(0, lambda idx=current_command_global_index: self.update_drawing_status(idx, total_commands, f"Runtime Error: {e}")) # 
            except tk.TclError:
                logging.error("GUI already closed during error handling.")
            # Don't try to move robot here, connection state unknown
            self.drawing_in_progress = False
            self.cancel_requested = False
            # Keep resume state in case it was a connection error leading to this exception
            # self.window.after(2000, self.drawing_options_page) # Don't automatically go back on unexpected error


    # --- Internal Socket Methods (without GUI popups) ---
    def send_message_internal(self, message: str) -> bool:
        """ Sends message without triggering GUI popups on error. Returns success status. """
        if not self.connected or not self.socket: return False
        try:
            self.socket.sendall(message.encode('utf-8'))
            logging.debug(f"Sent (internal): {message}")
            return True
        except (socket.error, ConnectionResetError, BrokenPipeError, socket.timeout) as e: # Added BrokenPipeError
            logging.error(f"Send error (internal): {e}")
            self.handle_connection_loss() # Use centralized handler
            return False

    def receive_message_internal(self, timeout=20.0) -> Optional[str]:
         """ Receives message without triggering GUI popups on error. Returns message or None. """
         if not self.connected or not self.socket: return None
         try:
             self.socket.settimeout(timeout)
             data = self.socket.recv(1024)
             self.socket.settimeout(None) # Reset timeout
             if not data: # Socket closed gracefully by peer
                 logging.warning("Receive error (internal): Connection closed by peer.")
                 self.handle_connection_loss()
                 return None
             decoded_data = data.decode('utf-8').strip()
             logging.debug(f"Received (internal): {decoded_data}")
             return decoded_data
         except socket.timeout:
             logging.error(f"Timeout receiving message (internal)")
             # Don't necessarily close socket on timeout, maybe robot is just slow
             # Consider if timeout should also trigger resume logic if it happens during drawing
             # For now, returning None might lead to connection loss handling higher up if expected msg isn't received.
             return None # Indicate timeout specifically? For now, None leads to resume check.
         except (socket.error, ConnectionResetError, BrokenPipeError) as e: # Added BrokenPipeError
             logging.error(f"Receive error (internal): {e}")
             self.handle_connection_loss() # Use centralized handler
             return None

    def handle_connection_loss(self):
        """Centralized handling of connection loss detection."""
        logging.warning("Connection lost detected.")
        was_connected = self.connected
        self.close_socket() # Close the broken socket and update flags
        # *** If connection lost DURING drawing, set resume flag ***
        # The resume flag is set higher up in the run_drawing_loop when errors occur
        # Here, we just ensure the socket is closed.
        # If we weren't drawing, we don't need to set resume_needed.
        # We might need to inform the user if they were connected but not drawing.
        if was_connected and not self.drawing_in_progress and not self.resume_needed:
             # Use 'after' to schedule GUI updates from the main thread
            self.window.after(0, lambda: messagebox.showinfo("Connection Lost", "Robot connection lost."))
            # Potentially navigate back to connection page if not already there
            # Check current page? For simplicity, assume user might need to reconnect manually.


    # --- Connection Handling ---
    def establish_connection(self):
        """Attempt connection (modified to use internal methods and handle resume)."""
        if hasattr(self, 'connect_button') and self.connect_button.winfo_exists(): self.connect_button.config(state=tk.DISABLED)
        if hasattr(self, 'reconnect_button') and self.reconnect_button.winfo_exists(): self.reconnect_button.config(state=tk.DISABLED)

        host, port = (SIMULATION_HOST, SIMULATION_PORT) if self.connection_var.get() == "simulation" else (REAL_ROBOT_HOST, REAL_ROBOT_PORT)

        def connection_attempt():
            try:
                self.close_socket() # Ensure clean start
                self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
                self.socket.settimeout(5)
                self.socket.connect((host, port))
                self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
                self.socket.settimeout(None) # Default to blocking for operations
                logging.info(f"Connected to {host}:{port}")
                self.connected = True
                # *** Call handle_connection_result via 'after' ***
                self.window.after(0, lambda: self.handle_connection_result(True))
            except (socket.error, socket.timeout, ConnectionRefusedError) as e:
                logging.error(f"Connection error: {e}")
                self.connected = False # Ensure flag is false before calling handler
                self.close_socket() # Clean up socket if connection failed
                # *** Call handle_connection_result via 'after' ***
                self.window.after(0, lambda: self.handle_connection_result(False))
        threading.Thread(target=connection_attempt, daemon=True).start()

    def handle_connection_result(self, connected):
        """Handle connection result and trigger resume if needed."""
        # Re-enable buttons safely
        if hasattr(self, 'connect_button') and self.connect_button.winfo_exists():
            self.connect_button.config(state=tk.NORMAL)
        if hasattr(self, 'reconnect_button') and self.reconnect_button.winfo_exists():
            self.reconnect_button.config(state=tk.NORMAL)

        if connected:
            self.connection_established = True
            # *** NEW: Check if resume is needed ***
            if self.resume_needed and self.resume_commands is not None:
                logging.info("Reconnection successful. Preparing to resume drawing.")
                # Move to final position BEFORE resuming
                self.move_to_final_before_resume() # This will start resume loop after move
            else:
                # Normal connection, go to drawing options
                self.drawing_options_page() # Go to drawing options
        else:
            if self.resume_needed:
                messagebox.showerror("Reconnection Failed", "Failed to reconnect. Cannot resume the previous drawing.")
                # Reset resume state as we can't continue
                self.resume_needed = False
                self.resume_commands = None
                self.resume_total_original_commands = 0
                self.resume_start_index_global = 0
                # Update last status to reflect the failed resume attempt
                self.last_drawing_status["status"] = "Resume Failed"
                self.last_drawing_status["error_message"] = "Could not reconnect to robot."
                # Go back to drawing options page after acknowledging the error
                self.drawing_options_page()
            else:
                messagebox.showerror("Connection Failed", "Failed to establish connection.")
            # Stay on connection page if it was a normal connection attempt that failed
    def move_to_final_before_resume(self):
        """Sends robot to FINAL_ROBOT_POSITION and then starts resume. Runs in thread."""
        def move_and_resume_thread():
            logging.info("Moving robot to FINAL_ROBOT_POSITION before resuming...")
            self.show_drawing_progress_page(self.resume_total_original_commands, self.resume_start_index_global, "Moving to resume position...")

            final_x, final_z, final_y = FINAL_ROBOT_POSITION
            command_str_final = f"{final_x:.3f},{final_z:.3f},{final_y:.3f}"
            move_ok = False
            if self.connected and self.socket:
                if self.send_message_internal(command_str_final):
                    response_r = self.receive_message_internal(timeout=5.0)
                    if response_r == "R":
                        response_d = self.receive_message_internal(timeout=5.0)
                        if response_d == "D":
                            logging.info("Robot reached FINAL_ROBOT_POSITION.")
                            move_ok = True
                        else: logging.error("Failed to get 'D' confirmation for pre-resume move.")
                    else: logging.error("Failed to get 'R' confirmation for pre-resume move.")
                else: logging.error("Failed to send pre-resume move command.")

            if move_ok:
                 # *** Start the drawing loop from the resume point ***
                 logging.info(f"Starting resume from command index {self.resume_start_index_global}")
                 self.drawing_in_progress = True # Set flag before starting thread
                 self.cancel_requested = False # Ensure cancel flag is reset
                 # We don't reset resume_needed here, it's reset on completion/cancel
                 # Use the stored remaining commands and start index
                 # NOTE: run_drawing_loop expects the FULL command list and the start_index
                 self.run_drawing_loop(self.resume_commands, self.resume_start_index_global)
                 # The run_drawing_loop itself now handles progress updates etc.
            else: # if move_ok is False
                error_msg = "Failed to move robot to safe resume position."
                logging.error(error_msg + " Cannot resume automatically, but allowing retry.")
                # *** NEW: Update status but keep resume state ***
                self.last_drawing_status["status"] = "Resume Failed (Pre-move)"
                self.last_drawing_status["error_message"] = error_msg
                # Keep previous command counts if available
                # Ensure resume_needed remains True, DO NOT reset resume variables here
                # *** End NEW ***
                self.window.after(0, lambda: messagebox.showwarning("Resume Warning", error_msg + "\nConnection might be unstable. You can try 'Reconnect & Resume' again."))
                # Reset drawing flag
                self.drawing_in_progress = False
                # *** NEW: Go back to connection page to allow retry ***
                self.window.after(1000, self.connection_setup_page)

        # Start the move and potential resume in a new thread
        threading.Thread(target=move_and_resume_thread, daemon=True).start()


    def close_socket(self):
        """Close socket cleanly and update flags."""
        if self.socket:
            try:
                self.socket.shutdown(socket.SHUT_RDWR)
            except (socket.error, OSError): pass # Ignore errors if already closed
            finally:
                try: self.socket.close()
                except (socket.error, OSError): pass
                self.socket = None
                logging.info("Socket closed")
        # Always update flags when this is called
        self.connected = False
        self.connection_established = False
        # Do NOT reset drawing_in_progress or resume flags here,
        # they are managed by the drawing loop and connection loss handler

    def close_and_return_main(self):
         """Close connection and go to main page."""
         # If drawing was in progress, should we cancel it first?
         # For simplicity now, just close the socket. Active drawing will fail.
         self.close_socket()
         # Reset any pending resume state if user explicitly disconnects
         self.resume_needed = False
         self.resume_commands = None
         self.resume_total_original_commands = 0
         self.resume_start_index_global = 0
         self.main_page()

    # --- Utility Methods ---
    def clear_frame(self):
        """Clear all widgets from the main frame."""
        # Stop camera if running when clearing frame
        if self.camera_running:
            self.stop_camera_feed()
        # Destroy widgets
        for widget in self.main_frame.winfo_children():
            widget.destroy()
        # Reset references to GUI elements that are destroyed
        self.camera_frame_label = None
        self.capture_button = None
        self.camera_back_button = None
        self.progress_bar = None
        self.status_label = None
        self.cancel_button = None
        self.connect_button = None
        self.reconnect_button = None
        self.preview_label = None


    @staticmethod
    def run_script(script_path: str) -> bool:
        """Run a Python script (kept for calibration)."""
        # (Implementation remains the same) 
        if not os.path.exists(script_path):
             logging.error(f"Script not found: {script_path}")
             return False
        try:
            logging.info(f"Running script: {script_path}")
            result = os.system(f'python "{script_path}"')
            if result != 0: logging.error(f"Script {script_path} failed with exit code {result}")
            return result == 0
        except Exception as e:
            logging.error(f"Error running script {script_path}: {e}")
            return False

    def on_window_close(self):
        """Handle window close event."""
        logging.info("Window close requested.")
        self.cancel_requested = True # Signal drawing thread to stop if running
        self.stop_camera_feed() # Ensure camera stops
        self.close_socket()     # Ensure socket closes
        # Give threads a moment to potentially react to cancel_requested or socket closure
        time.sleep(0.2)
        self.window.destroy()


# --- Main Execution ---
if __name__ == "__main__":
    # Create DATA_DIR if it doesn't exist 
    os.makedirs(DATA_DIR, exist_ok=True)

    app = RUNME_GUI()
    app.window.protocol("WM_DELETE_WINDOW", app.on_window_close)
    app.window.mainloop()
--- END OF FILE: backend/main.py ---
--- START OF FILE: backend/main_orchestrator.py ---
# backend/main_orchestrator.py
from api_server import app, socketio # app is the Flask app instance

if __name__ == '__main__':
    server_port = 5555 # Define the port
    # It's good practice to ensure app config is set before running.
    # This is already done in api_server.py when it's imported, 
    # but explicitly setting it here or ensuring it's set in app object is fine.
    if 'SERVER_PORT' not in app.config:
        app.config['SERVER_PORT'] = server_port

    print(f"Starting Python backend server (SocketIO with Flask) on port {server_port}...")
    print(f"Frontend should connect to ws://localhost:{server_port} (or your machine's IP on the network)")
    
    # Construct the QR code upload page URL for the print message
    # This logic is similar to what's in api_server.py for determining host_ip
    # For simplicity in this print, we'll just remind the user it's their local IP.
    print(f"QR code upload page will be accessible via http://<YOUR_LOCAL_IP>:{server_port}/qr_upload_page/<session_id>")

    # The async_mode='eventlet' should be set during SocketIO instantiation in api_server.py
    # The use_reloader=False is important when debug=True with eventlet.
    socketio.run(app, 
                 host='0.0.0.0', 
                 port=server_port, 
                 debug=True, 
                 use_reloader=False) # Removed async_mode='eventlet' from here

--- END OF FILE: backend/main_orchestrator.py ---
--- START OF FILE: backend/rapid_code_for_controlling_the_robot_movement.txt ---
MODULE InputDrawing
    VAR num x;
    VAR num y;
    VAR num z;
    VAR robtarget Object_Target;
    VAR pos p1;
    VAR num target;
    VAR string data;
    VAR socketdev client_socket;
    VAR socketdev temp_socket;
    VAR robtarget targetRobTarget;
    VAR string tempX;
    VAR string tempY;
    VAR string tempZ;
    VAR num idx0;
    VAR num idx1;
    VAR num idx2;
    VAR bool success;
    CONST robtarget home1:=[[409.328464947,30.699294352,-350.922061873],[0.999898286,-0.005230998,0.00469865,0.012408784],[0,-1,1,0],[9E+09,9E+09,9E+09,9E+09,9E+09,9E+09]];
    CONST robtarget WorkSpaceCenter1:=[[75.78,312.76,9.799641871],[0.988089954,-0.00592235,0.00373461,-0.153717993],[0,0,0,0],[9E+09,9E+09,9E+09,9E+09,9E+09,9E+09]];
    TASK PERS wobjdata Wobj_1:=[FALSE,TRUE,"",[[87.974520519,-126.434467699,0],[0,0.707106781,0.707106781,0]],[[0,0,0],[1,0,0,0]]];

    PROC main()
        MoveJ home1,v1000,z100,tool2\WObj:=Wobj_1;
        SocketConnect;

        WHILE TRUE DO
            ! socket sent in "x,z,y"
            IF SocketGetStatus(client_socket)=SOCKET_CONNECTED THEN
                SocketReceive client_socket\Str:=data,\Time:=WAIT_MAX;
                SocketSend client_socket\Str:="R";
                ConvertSocketStrToPose(data);
                ! Wait until ConvertSocketStrToPose completes
                IF success THEN
                    MoveL Offs(WorkSpaceCenter1,x,y,z),v1000,z100,tool2\WObj:=Wobj_1;                
                    SocketSend client_socket\Str:="D";
                ENDIF
            ENDIF
        ENDWHILE
    ENDPROC

    ! for real life robot station
!    PROC SocketConnect()
!        SocketCreate temp_socket;
!        SocketBind temp_socket,"192.168.125.1",1025;
!        SocketListen temp_socket;
!        SocketAccept temp_socket,client_socket,\Time:=WAIT_MAX;
!        TPWrite "Socket connection established.";
!    ENDPROC

    ! for simulation station
    
    PROC SocketConnect()
        ! Create, bind, listen, and accept the socket connection
        SocketCreate temp_socket;
        SocketBind temp_socket,"127.0.0.1",55000;
        SocketListen temp_socket;
        SocketAccept temp_socket,client_socket,\Time:=WAIT_MAX;
        TPWrite "Socket connection established.";
    ENDPROC    
    PROC ConvertSocketStrToPose(string data)
        ! Find indices of the commas
        idx1:=StrFind(data,1,",");
        idx2:=StrFind(data,idx1+1,",");

        ! Ensure all indices are valid
        IF idx1>0 AND idx2>0 THEN
            ! Extract substrings for x, y, and z
            tempX:=StrPart(data,1,idx1-1);
            tempZ:=StrPart(data,idx1+1,idx2-idx1-1);
            tempY:=StrPart(data,idx2+1,StrLen(data)-idx2);
            ! Convert strings to numeric values
            success := FALSE;
            IF StrToVal(tempX,x) AND
                           StrToVal(tempZ,z) AND
                           StrToVal(tempY,y) THEN
                success := TRUE;
            ENDIF
        ELSE
            success := FALSE;
        ENDIF
    ENDPROC

ENDMODULE
--- END OF FILE: backend/rapid_code_for_controlling_the_robot_movement.txt ---
--- START OF FILE: backend/README.md ---
# Python backend 

--- END OF FILE: backend/README.md ---
--- START OF FILE: backend/requirements.txt ---
Flask
python-socketio
Flask-SocketIO
eventlet
# or instead of Flask-SocketIO and eventlet, use:
# websockets
# if using FastAPI:
# fastapi
# uvicorn[standard]

opencv-python
Pillow
qrcode[pil]
numpy
openai-whisper
llama-cpp-python

# Add other AI/ML libraries later, e.g.:
# transformers
# torch
# accelerate
# bitsandbytes
--- END OF FILE: backend/requirements.txt ---
--- START OF FILE: backend/robot_interface.py ---
# backend/robot_interface.py
import socket
import time # Make sure time is imported (it likely already is)
import config

class RobotInterface:
    def __init__(self):
        self.robot_socket = None
        self.is_connected = False
        self.target_host = config.REAL_ROBOT_HOST if config.USE_REAL_ROBOT else config.SIMULATION_HOST
        self.target_port = config.REAL_ROBOT_PORT if config.USE_REAL_ROBOT else config.SIMULATION_PORT

    def _format_command(self, x, z, y):
        return f"{x:.2f},{z:.2f},{y:.2f}"

    def connect_robot(self):
        if self.is_connected:
            print("Robot already connected.")
            return True, "Already connected"
        try:
            self.robot_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.robot_socket.settimeout(5)
            print(f"Attempting to connect to robot at {self.target_host}:{self.target_port}...")
            self.robot_socket.connect((self.target_host, self.target_port))
            self.robot_socket.settimeout(None)
            self.is_connected = True
            print("Successfully connected to the robot/simulator.")
            return True, "Successfully connected"
        except socket.error as e:
            self.robot_socket = None
            self.is_connected = False
            print(f"Error connecting to robot: {e}")
            return False, f"Error connecting: {e}"

    def disconnect_robot(self, graceful=True):
        if not self.is_connected:
            print("Robot is not connected.")
            return True, "Was not connected."

        if graceful:
            print("Attempting graceful disconnect (going home first)...")
            home_success, home_msg = self.go_home() # go_home now attempts to connect if not connected.
                                                 # We should only call it if already connected for disconnect.
            if self.is_connected: # Check again, as go_home might have connected if it wasn't
                if not home_success:
                    print(f"Warning: Failed to go home before disconnecting: {home_msg}")
                else:
                    print("Successfully moved to home position.")
                    print("Waiting for 3 seconds before closing socket...")
                    time.sleep(3)

            else: # This case means go_home was called when not connected AND it failed to connect.
                print(f"Cannot complete graceful disconnect (go home) as robot is not connected: {home_msg}")


        if self.robot_socket:
            try:
                self.robot_socket.close()
            except socket.error as e:
                print(f"Error closing socket: {e}")
            finally:
                self.robot_socket = None
                self.is_connected = False
                print("Socket closed. Disconnected from robot.")
        else: # If robot_socket is None but is_connected was somehow true (should not happen with current logic)
            self.is_connected = False 
            print("No active socket to close. Marked as disconnected.")
            
        return True, "Disconnected from robot."

    def send_command_raw(self, command_str):
        if not self.is_connected or not self.robot_socket:
            return False, "Not connected"
        try:
            print(f"Sending command: {command_str}")
            self.robot_socket.sendall(command_str.encode('utf-8'))
            
            response_r = self.robot_socket.recv(1024).decode('utf-8').strip()
            print(f"Received R-phase: '{response_r}'")
            if response_r.upper() != "R":
                return False, f"Robot did not acknowledge (R). Got: {response_r}"

            response_d_or_e = self.robot_socket.recv(1024).decode('utf-8').strip()
            print(f"Received D/E-phase: '{response_d_or_e}'")
            if response_d_or_e.upper() == "D":
                return True, f"Command '{command_str}' successful."
            elif response_d_or_e.upper() == "E":
                return False, f"Command '{command_str}' failed: Robot reported error (E)."
            else:
                return False, f"Robot did not signal done (D) or error (E). Got: {response_d_or_e}"
                
        except socket.timeout:
            print(f"Socket timeout during send/recv for command: {command_str}")
            self.is_connected = False 
            self.robot_socket = None
            return False, "Socket timeout"
        except socket.error as e:
            print(f"Socket error during send/recv: {e}")
            self.is_connected = False
            self.robot_socket = None
            return False, f"Socket error: {e}"
        except Exception as e:
            print(f"An unexpected error occurred: {e}")
            self.is_connected = False
            self.robot_socket = None
            return False, f"Unexpected error: {e}"

    def go_home(self):
        if not self.is_connected:
            conn_success, conn_msg = self.connect_robot()
            if not conn_success:
                return False, f"Cannot go home. Connection failed: {conn_msg}"
        
        print("Sending robot to home position...")
        x, z, y = config.ROBOT_HOME_POSITION_PY
        cmd_str = self._format_command(x, z, y)
        return self.send_command_raw(cmd_str)

    def move_to_position_py(self, x_py, z_py, y_py):
        if not self.is_connected:
            conn_success, conn_msg = self.connect_robot()
            if not conn_success:
                return False, f"Cannot move. Connection failed: {conn_msg}"

        cmd_str = self._format_command(x_py, z_py, y_py)
        return self.send_command_raw(cmd_str)

# Main guard for direct testing (if __name__ == '__main__') remains the same
# ... (previous if __name__ == '__main__' block)
--- END OF FILE: backend/robot_interface.py ---
--- START OF FILE: backend/voice_assistant.py ---
# backend/voice_assistant.py
import whisper
import os
import time
from llama_cpp import Llama
import config # Import your project's config
import logging # For better logging
import json # For parsing structured commands

# --- Whisper STT Model ---
WHISPER_MODEL_SIZE = "base" 
whisper_model = None # Global variable for the Whisper model instance

def load_whisper_model():
    """Loads the Whisper model. Call this once when the server starts."""
    global whisper_model 
    if whisper_model is None:
        logging.info(f"Attempting to load Whisper model ({WHISPER_MODEL_SIZE})...")
        try:
            whisper_model = whisper.load_model(WHISPER_MODEL_SIZE)
            logging.info(f"Whisper model ({WHISPER_MODEL_SIZE}) loaded successfully.")
            return whisper_model 
        except Exception as e:
            logging.error(f"Error loading Whisper model: {e}", exc_info=True)
            whisper_model = None 
            return None
    logging.info("Whisper model already loaded.")
    return whisper_model

def transcribe_audio(audio_filepath):
    """Transcribes the given audio file using the loaded Whisper model."""
    global whisper_model 
    if whisper_model is None:
        logging.error("Whisper model is not loaded. Cannot transcribe.")
        if load_whisper_model() is None: # Attempt to load if not loaded
            logging.error("Failed to load Whisper model on demand.")
            return None
    
    if not os.path.exists(audio_filepath):
        logging.error(f"Audio file not found for transcription: {audio_filepath}")
        return None

    try:
        logging.info(f"Transcribing audio file: {audio_filepath} with Whisper model {WHISPER_MODEL_SIZE}...")
        start_time = time.time()
        # Ensure fp16 is False if CPU only, can be True if GPU supports it and it's configured
        result = whisper_model.transcribe(audio_filepath, fp16=False) 
        transcription = result["text"]
        end_time = time.time()
        logging.info(f"Transcription complete in {end_time - start_time:.2f} seconds.")
        logging.info(f"Transcription: {transcription}")
        return transcription
    except Exception as e:
        logging.error(f"Error during audio transcription: {e}", exc_info=True)
        return None

# --- Llama LLM ---
llm_instance = None # Global variable for the Llama model instance, set by load_llm_model
llm_chat_history = [] 

def load_llm_model():
    """Loads the Llama GGUF model. Call this once when the server starts."""
    global llm_instance 
    if llm_instance is None:
        model_filename = config.LLM_MODEL_FILENAME
        # Construct model path relative to this file's directory, then into 'models'
        base_dir = os.path.dirname(os.path.abspath(__file__)) 
        model_path = os.path.join(base_dir, "models", model_filename)
        
        logging.info(f"Attempting to load LLM model: {model_filename} from path: {model_path}")
        if not os.path.exists(model_path):
            logging.error(f"LLM model file NOT FOUND at: {model_path}")
            logging.error(f"Please ensure the model is downloaded to '{os.path.join('backend', 'models')}' and LLM_MODEL_FILENAME in config.py ('{model_filename}') is correct.")
            llm_instance = None
            return None
        
        logging.info(f"LLM model file found. Initializing Llama from: {model_path} ...")
        try:
            llm_instance = Llama(
                model_path=model_path,
                n_ctx=config.LLM_N_CTX,         
                n_gpu_layers=config.LLM_N_GPU_LAYERS, 
                chat_format="chatml", 
                verbose=True # llama.cpp verbose logging
            )
            logging.info(f"LLM model ({model_filename}) loaded successfully into voice_assistant.llm_instance with chat_format='chatml'.")
            return llm_instance 
        except Exception as e:
            logging.error(f"Error loading LLM model from {model_path} with chat_format='chatml': {e}", exc_info=True)
            try:
                logging.warning(f"Retrying LLM load for {model_filename} without explicit chat_format (auto-detection)...")
                llm_instance = Llama(
                    model_path=model_path,
                    n_ctx=config.LLM_N_CTX,         
                    n_gpu_layers=config.LLM_N_GPU_LAYERS, 
                    verbose=True 
                )
                logging.info(f"LLM model ({model_filename}) loaded successfully (fallback, auto-detected chat format).")
                return llm_instance
            except Exception as e2:
                logging.error(f"Error loading LLM model (fallback attempt) from {model_path}: {e2}", exc_info=True)
                llm_instance = None
                return None

    logging.info("LLM model already loaded (voice_assistant.llm_instance).")
    return llm_instance

def process_command_with_llm_stream(text_input):
    """
    Processes the transcribed text with the LLM and yields response chunks (streaming).
    Attempts to extract a structured command from the LLM's full response.
    """
    global llm_instance, llm_chat_history 
    
    logging.info(f"--- voice_assistant.process_command_with_llm_stream called with input: '{text_input}' ---")

    if llm_instance is None:
        logging.error("LLM model (voice_assistant.llm_instance) is not loaded. Attempting to load now.")
        if load_llm_model() is None: # Try to load it if it's not already
            logging.error("Failed to load LLM model on demand in process_command_with_llm_stream.")
            yield {"error": "LLM not available (failed to load).", "done": True}
            return 

    MAX_HISTORY_TURNS = 1 # Keep history very short for simpler models
    if len(llm_chat_history) > MAX_HISTORY_TURNS * 2: 
        llm_chat_history = llm_chat_history[-(MAX_HISTORY_TURNS * 2):]

    llm_chat_history.append({"role": "user", "content": text_input})
    
    # Simplified System Prompt - Focus on Command Extraction
    system_prompt = (
        "## YOU ARE ROBOTIST - ROBOT CONTROLLER ##\n"
        "Your primary function is to understand user commands and translate them into structured JSON for a robot arm. "
        "You also provide brief spoken feedback.\n\n"
        "### CORE ROBOT ACTIONS & REQUIRED OUTPUT FORMAT ###\n"
        "For the following specific user intents, your output MUST be in this exact two-part format:\n"
        "1.  **Spoken Confirmation:** A very short, direct confirmation.\n"
        "2.  **System Directive (`ACTION_CMD:`):** IMMEDIATELY after the spoken confirmation, append `ACTION_CMD:` followed by the precise JSON shown below. This JSON part is for the system and IS NOT SPOKEN.\n\n"
        "**MANDATORY EXAMPLES - FOLLOW THESE EXACTLY:**\n\n"
        "  - User input contains: \"home\", \"go home\", \"move to home position\"\n"
        "    Your Output: `Okay, moving home. ACTION_CMD: {\"type\": \"move\", \"parameters\": {\"target\": \"home\"}}`\n\n"
        "  - User input contains: \"center\", \"go to center\", \"move to center position\", \"middle of paper\"\n"
        "    Your Output: `Alright, moving to the center. ACTION_CMD: {\"type\": \"move\", \"parameters\": {\"target\": \"center\"}}`\n\n"
        "  - User input (after image upload is confirmed by system): \"draw it\", \"start drawing\", \"go ahead and draw\"\n"
        "    Your Output: `Starting the drawing. ACTION_CMD: {\"type\": \"draw_uploaded_image\"}`\n\n"
        "**IMPORTANT:**\n"
        "- If the user's command clearly matches one of the above intents, you MUST output both the spoken confirmation AND the corresponding `ACTION_CMD:` block. NO EXCEPTIONS.\n"
        "- If the user asks to draw something from a verbal description (e.g., \"draw a cat\"), respond: `I need an image to draw from. Please upload one. ACTION_CMD: {\"type\": \"draw_request_clarification\", \"details\": \"User asked to draw from description. Needs image.\"}`\n"
        "- For any other input (greetings, questions, unclear commands), provide a very brief, helpful response as Robotist. DO NOT output `ACTION_CMD:` for these. Example: User: \"Hello\" -> Your Output: `Hello! Robotist here.` User: \"What can you do?\" -> Your Output: `I can control the robot to move and draw from images.`\n\n"
        "Be direct and prioritize the `ACTION_CMD:` for recognized actions. You are Robotist."
    )
    
    messages_for_llm = [
        {"role": "system", "content": system_prompt},
    ] + llm_chat_history

    logging.info(f"Streaming to LLM ({config.LLM_MODEL_FILENAME}) with {len(messages_for_llm)} total messages in context. Last user message: '{text_input}'")

    full_assistant_response = ""
    try:
        start_time = time.time()
        
        stream = llm_instance.create_chat_completion(
            messages=messages_for_llm,
            max_tokens=config.LLM_MAX_TOKENS, # Max tokens for the LLM's response
            temperature=config.LLM_TEMPERATURE, # Controls randomness: 0.0 for deterministic, ~0.7 for creative
            stream=True 
        )
        
        logging.info("LLM stream initiated with llama.cpp.")
        chunk_count = 0
        for chunk_index, chunk_data in enumerate(stream):
            chunk_count += 1
            delta = chunk_data['choices'][0]['delta']
            content_piece = delta.get('content')
            
            if content_piece: 
                logging.debug(f"LLM Content Piece from chunk {chunk_index}: '{content_piece}'")
                yield {"chunk": content_piece, "done": False}
                full_assistant_response += content_piece
            else:
                logging.debug(f"LLM Chunk {chunk_index} had no 'content' in delta. Delta: {delta}")
            
            if chunk_data['choices'][0].get('finish_reason') is not None:
                logging.info(f"LLM stream finished by model. Reason: {chunk_data['choices'][0]['finish_reason']}. Total chunks processed: {chunk_count}")
                break 
        
        end_time = time.time()
        logging.info(f"LLM full response assembled/streamed in {end_time - start_time:.2f} seconds. Total chunks: {chunk_count}")
        logging.info(f"LLM Final Assembled Output (raw from stream): {full_assistant_response}")

        parsed_action_command = None
        final_natural_language_response = full_assistant_response.strip() 

        action_cmd_marker = "ACTION_CMD:"
        if action_cmd_marker in final_natural_language_response:
            parts = final_natural_language_response.split(action_cmd_marker, 1)
            spoken_part = parts[0].strip()
            action_json_str = parts[1].strip()
            
            logging.info(f"Found ACTION_CMD marker. Potential spoken part: '{spoken_part}'. JSON string part: '{action_json_str}'")
            try:
                json_start = action_json_str.find('{')
                json_end = action_json_str.rfind('}')
                if json_start != -1 and json_end != -1 and json_end > json_start:
                    potential_json = action_json_str[json_start : json_end+1]
                    logging.info(f"Attempting to parse JSON from ACTION_CMD: {potential_json}")
                    parsed_action_command = json.loads(potential_json)
                    logging.info(f"Successfully parsed ACTION_CMD: {parsed_action_command}")
                else:
                    logging.warning(f"Could not properly isolate JSON object within ACTION_CMD string: '{action_json_str}'")
            except json.JSONDecodeError as e:
                logging.warning(f"JSONDecodeError parsing ACTION_CMD: {e}. String was: '{action_json_str}'")
            except Exception as e: 
                logging.warning(f"Generic error parsing ACTION_CMD JSON: {e}. String was: '{action_json_str}'")

            if not spoken_part and parsed_action_command:
                final_natural_language_response = "Okay, processing that." 
                logging.info(f"ACTION_CMD was present but spoken part was empty. Using generic response: '{final_natural_language_response}'")
            else:
                final_natural_language_response = spoken_part
        
        if final_natural_language_response:
            llm_chat_history.append({"role": "assistant", "content": final_natural_language_response})
        elif full_assistant_response and not parsed_action_command: 
             llm_chat_history.append({"role": "assistant", "content": full_assistant_response.strip()})
             final_natural_language_response = full_assistant_response.strip() 
        elif not full_assistant_response and not parsed_action_command : 
            logging.warning("LLM produced an empty response and no action command.")
            final_natural_language_response = "I'm sorry, I didn't quite understand. Could you please rephrase?" 
            llm_chat_history.append({"role": "assistant", "content": final_natural_language_response})


        final_response_payload = {
            "chunk": "", 
            "done": True, 
            "final_message": final_natural_language_response 
        }
        if parsed_action_command:
            final_response_payload["parsed_action"] = parsed_action_command
        
        logging.info(f"Yielding final 'done' payload: {final_response_payload}")
        yield final_response_payload

    except Exception as e:
        logging.error(f"Error during LLM streaming in process_command_with_llm_stream: {e}", exc_info=True)
        if llm_chat_history and llm_chat_history[-1]["role"] == "user":
            llm_chat_history.pop() 
        yield {"error": f"LLM streaming failed due to server error: {str(e)}", "done": True}


if __name__ == '__main__':
    logging.basicConfig(level=logging.DEBUG) 
    
    logging.info("--- Voice Assistant Module Direct Test ---")
    
    logging.info("\n--- Testing Whisper STT ---")
    if load_whisper_model():
        logging.info("Whisper model loaded. Transcription test would require an audio file.")
    else:
        logging.error("Whisper model failed to load. Cannot test transcription.")

    logging.info("\n--- Testing LLM Streaming ---")
    if load_llm_model(): 
        test_inputs = [
            "Hello Robotist",
            "What can you do?",
            "Robotist draw a red square",
            "Move home",
            "go to center of paper", 
            "move to home position" 
        ]
        for test_input_idx, test_input_text in enumerate(test_inputs):
            logging.info(f"\n--- Test Input {test_input_idx + 1}: '{test_input_text}' ---")
            llm_chat_history.clear() 
            
            print(f"Robotist Response (Streaming for '{test_input_text}'): ", end="", flush=True)
            
            for response_part in process_command_with_llm_stream(test_input_text):
                if response_part.get("error"):
                    print(f"\nLLM Stream Error: {response_part['error']}")
                    break
                if response_part.get("chunk"): 
                    print(response_part["chunk"], end="", flush=True) 
                
                if response_part.get("done"):
                    print("\n--- LLM Stream Ended for this test input ---")
                    if response_part.get("final_message"):
                         logging.debug(f"Test: Final natural message from payload: '{response_part.get('final_message')}'")
                    if response_part.get("parsed_action"):
                        logging.info(f"Test: Extracted Parsed Action: {response_part.get('parsed_action')}")
                    else:
                        logging.info(f"Test: No parsed action extracted for this input.")
                    break 
            print("\n") 
        llm_chat_history.clear() 
    else:
        logging.error("LLM model not loaded, skipping LLM direct test.")

    logging.info("--- Voice Assistant Module Direct Test Complete ---")

--- END OF FILE: backend/voice_assistant.py ---
--- START OF FILE: frontend/README.md ---
# JavaScript/TypeScript frontend React framework

--- END OF FILE: frontend/README.md ---
--- START OF FILE: frontend/s2a-drawing-ui/.eslintrc.cjs ---
module.exports = {
  root: true,
  env: { browser: true, es2020: true },
  extends: [
    'eslint:recommended',
    'plugin:@typescript-eslint/recommended',
    'plugin:react-hooks/recommended',
  ],
  ignorePatterns: ['dist', '.eslintrc.cjs'],
  parser: '@typescript-eslint/parser',
  plugins: ['react-refresh'],
  rules: {
    'react-refresh/only-export-components': [
      'warn',
      { allowConstantExport: true },
    ],
  },
}

--- END OF FILE: frontend/s2a-drawing-ui/.eslintrc.cjs ---
--- START OF FILE: frontend/s2a-drawing-ui/.gitignore ---
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?

--- END OF FILE: frontend/s2a-drawing-ui/.gitignore ---
--- START OF FILE: frontend/s2a-drawing-ui/dist-electron/main.js ---
import { app, BrowserWindow } from "electron";
import { createRequire } from "node:module";
import { fileURLToPath } from "node:url";
import path from "node:path";
createRequire(import.meta.url);
const __dirname = path.dirname(fileURLToPath(import.meta.url));
process.env.APP_ROOT = path.join(__dirname, "..");
const VITE_DEV_SERVER_URL = process.env["VITE_DEV_SERVER_URL"];
const MAIN_DIST = path.join(process.env.APP_ROOT, "dist-electron");
const RENDERER_DIST = path.join(process.env.APP_ROOT, "dist");
process.env.VITE_PUBLIC = VITE_DEV_SERVER_URL ? path.join(process.env.APP_ROOT, "public") : RENDERER_DIST;
let win;
function createWindow() {
  win = new BrowserWindow({
    icon: path.join(process.env.VITE_PUBLIC, "electron-vite.svg"),
    webPreferences: {
      preload: path.join(__dirname, "preload.mjs")
    }
  });
  win.webContents.on("did-finish-load", () => {
    win == null ? void 0 : win.webContents.send("main-process-message", (/* @__PURE__ */ new Date()).toLocaleString());
  });
  if (VITE_DEV_SERVER_URL) {
    win.loadURL(VITE_DEV_SERVER_URL);
  } else {
    win.loadFile(path.join(RENDERER_DIST, "index.html"));
  }
}
app.on("window-all-closed", () => {
  if (process.platform !== "darwin") {
    app.quit();
    win = null;
  }
});
app.on("activate", () => {
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow();
  }
});
app.whenReady().then(createWindow);
export {
  MAIN_DIST,
  RENDERER_DIST,
  VITE_DEV_SERVER_URL
};

--- END OF FILE: frontend/s2a-drawing-ui/dist-electron/main.js ---
--- START OF FILE: frontend/s2a-drawing-ui/dist-electron/preload.mjs ---
"use strict";
const electron = require("electron");
electron.contextBridge.exposeInMainWorld("ipcRenderer", {
  on(...args) {
    const [channel, listener] = args;
    return electron.ipcRenderer.on(channel, (event, ...args2) => listener(event, ...args2));
  },
  off(...args) {
    const [channel, ...omit] = args;
    return electron.ipcRenderer.off(channel, ...omit);
  },
  send(...args) {
    const [channel, ...omit] = args;
    return electron.ipcRenderer.send(channel, ...omit);
  },
  invoke(...args) {
    const [channel, ...omit] = args;
    return electron.ipcRenderer.invoke(channel, ...omit);
  }
  // You can expose other APTs you need here.
  // ...
});

--- END OF FILE: frontend/s2a-drawing-ui/dist-electron/preload.mjs ---
--- START OF FILE: frontend/s2a-drawing-ui/electron/electron-env.d.ts ---
/// <reference types="vite-plugin-electron/electron-env" />

declare namespace NodeJS {
  interface ProcessEnv {
    /**
     * The built directory structure
     *
     * ```tree
     * ├─┬─┬ dist
     * │ │ └── index.html
     * │ │
     * │ ├─┬ dist-electron
     * │ │ ├── main.js
     * │ │ └── preload.js
     * │
     * ```
     */
    APP_ROOT: string
    /** /dist/ or /public/ */
    VITE_PUBLIC: string
  }
}

// Used in Renderer process, expose in `preload.ts`
interface Window {
  ipcRenderer: import('electron').IpcRenderer
}

--- END OF FILE: frontend/s2a-drawing-ui/electron/electron-env.d.ts ---
--- START OF FILE: frontend/s2a-drawing-ui/electron/main.ts ---
import { app, BrowserWindow } from 'electron'
import { createRequire } from 'node:module'
import { fileURLToPath } from 'node:url'
import path from 'node:path'

const require = createRequire(import.meta.url)
const __dirname = path.dirname(fileURLToPath(import.meta.url))

// The built directory structure
//
// ├─┬─┬ dist
// │ │ └── index.html
// │ │
// │ ├─┬ dist-electron
// │ │ ├── main.js
// │ │ └── preload.mjs
// │
process.env.APP_ROOT = path.join(__dirname, '..')

// 🚧 Use ['ENV_NAME'] avoid vite:define plugin - Vite@2.x
export const VITE_DEV_SERVER_URL = process.env['VITE_DEV_SERVER_URL']
export const MAIN_DIST = path.join(process.env.APP_ROOT, 'dist-electron')
export const RENDERER_DIST = path.join(process.env.APP_ROOT, 'dist')

process.env.VITE_PUBLIC = VITE_DEV_SERVER_URL ? path.join(process.env.APP_ROOT, 'public') : RENDERER_DIST

let win: BrowserWindow | null

function createWindow() {
  win = new BrowserWindow({
    icon: path.join(process.env.VITE_PUBLIC, 'electron-vite.svg'),
    webPreferences: {
      preload: path.join(__dirname, 'preload.mjs'),
    },
  })

  // Test active push message to Renderer-process.
  win.webContents.on('did-finish-load', () => {
    win?.webContents.send('main-process-message', (new Date).toLocaleString())
  })

  if (VITE_DEV_SERVER_URL) {
    win.loadURL(VITE_DEV_SERVER_URL)
  } else {
    // win.loadFile('dist/index.html')
    win.loadFile(path.join(RENDERER_DIST, 'index.html'))
  }
}

// Quit when all windows are closed, except on macOS. There, it's common
// for applications and their menu bar to stay active until the user quits
// explicitly with Cmd + Q.
app.on('window-all-closed', () => {
  if (process.platform !== 'darwin') {
    app.quit()
    win = null
  }
})

app.on('activate', () => {
  // On OS X it's common to re-create a window in the app when the
  // dock icon is clicked and there are no other windows open.
  if (BrowserWindow.getAllWindows().length === 0) {
    createWindow()
  }
})

app.whenReady().then(createWindow)

--- END OF FILE: frontend/s2a-drawing-ui/electron/main.ts ---
--- START OF FILE: frontend/s2a-drawing-ui/electron/preload.ts ---
import { ipcRenderer, contextBridge } from 'electron'

// --------- Expose some API to the Renderer process ---------
contextBridge.exposeInMainWorld('ipcRenderer', {
  on(...args: Parameters<typeof ipcRenderer.on>) {
    const [channel, listener] = args
    return ipcRenderer.on(channel, (event, ...args) => listener(event, ...args))
  },
  off(...args: Parameters<typeof ipcRenderer.off>) {
    const [channel, ...omit] = args
    return ipcRenderer.off(channel, ...omit)
  },
  send(...args: Parameters<typeof ipcRenderer.send>) {
    const [channel, ...omit] = args
    return ipcRenderer.send(channel, ...omit)
  },
  invoke(...args: Parameters<typeof ipcRenderer.invoke>) {
    const [channel, ...omit] = args
    return ipcRenderer.invoke(channel, ...omit)
  },

  // You can expose other APTs you need here.
  // ...
})

--- END OF FILE: frontend/s2a-drawing-ui/electron/preload.ts ---
--- START OF FILE: frontend/s2a-drawing-ui/electron-builder.json5 ---
// @see - https://www.electron.build/configuration/configuration
{
  "$schema": "https://raw.githubusercontent.com/electron-userland/electron-builder/master/packages/app-builder-lib/scheme.json",
  "appId": "YourAppID",
  "asar": true,
  "productName": "YourAppName",
  "directories": {
    "output": "release/${version}"
  },
  "files": [
    "dist",
    "dist-electron"
  ],
  "mac": {
    "target": [
      "dmg"
    ],
    "artifactName": "${productName}-Mac-${version}-Installer.${ext}"
  },
  "win": {
    "target": [
      {
        "target": "nsis",
        "arch": [
          "x64"
        ]
      }
    ],
    "artifactName": "${productName}-Windows-${version}-Setup.${ext}"
  },
  "nsis": {
    "oneClick": false,
    "perMachine": false,
    "allowToChangeInstallationDirectory": true,
    "deleteAppDataOnUninstall": false
  },
  "linux": {
    "target": [
      "AppImage"
    ],
    "artifactName": "${productName}-Linux-${version}.${ext}"
  }
}

--- END OF FILE: frontend/s2a-drawing-ui/electron-builder.json5 ---
--- START OF FILE: frontend/s2a-drawing-ui/index.html ---
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Vite + React + TS</title>
  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>

--- END OF FILE: frontend/s2a-drawing-ui/index.html ---
--- START OF FILE: frontend/s2a-drawing-ui/package.json ---
{
  "name": "s2a-drawing-ui",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build && electron-builder",
    "lint": "eslint . --ext ts,tsx --report-unused-disable-directives --max-warnings 0",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "socket.io-client": "^4.8.1"
  },
  "devDependencies": {
    "@types/react": "^18.2.64",
    "@types/react-dom": "^18.2.21",
    "@typescript-eslint/eslint-plugin": "^7.1.1",
    "@typescript-eslint/parser": "^7.1.1",
    "@vitejs/plugin-react": "^4.2.1",
    "electron": "^30.0.1",
    "electron-builder": "^24.13.3",
    "eslint": "^8.57.0",
    "eslint-plugin-react-hooks": "^4.6.0",
    "eslint-plugin-react-refresh": "^0.4.5",
    "typescript": "^5.2.2",
    "vite": "^6.3.5",
    "vite-plugin-electron": "^0.28.6",
    "vite-plugin-electron-renderer": "^0.14.5"
  },
  "main": "dist-electron/main.js"
}

--- END OF FILE: frontend/s2a-drawing-ui/package.json ---
--- START OF FILE: frontend/s2a-drawing-ui/README.md ---
# React + TypeScript + Vite

This template provides a minimal setup to get React working in Vite with HMR and some ESLint rules.

Currently, two official plugins are available:

- [@vitejs/plugin-react](https://github.com/vitejs/vite-plugin-react/blob/main/packages/plugin-react/README.md) uses [Babel](https://babeljs.io/) for Fast Refresh
- [@vitejs/plugin-react-swc](https://github.com/vitejs/vite-plugin-react-swc) uses [SWC](https://swc.rs/) for Fast Refresh

## Expanding the ESLint configuration

If you are developing a production application, we recommend updating the configuration to enable type aware lint rules:

- Configure the top-level `parserOptions` property like this:

```js
export default {
  // other rules...
  parserOptions: {
    ecmaVersion: 'latest',
    sourceType: 'module',
    project: ['./tsconfig.json', './tsconfig.node.json'],
    tsconfigRootDir: __dirname,
  },
}
```

- Replace `plugin:@typescript-eslint/recommended` to `plugin:@typescript-eslint/recommended-type-checked` or `plugin:@typescript-eslint/strict-type-checked`
- Optionally add `plugin:@typescript-eslint/stylistic-type-checked`
- Install [eslint-plugin-react](https://github.com/jsx-eslint/eslint-plugin-react) and add `plugin:react/recommended` & `plugin:react/jsx-runtime` to the `extends` list

--- END OF FILE: frontend/s2a-drawing-ui/README.md ---
--- START OF FILE: frontend/s2a-drawing-ui/src/App.css ---
#root {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}

.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
  transition: filter 300ms;
}
.logo:hover {
  filter: drop-shadow(0 0 2em #646cffaa);
}
.logo.react:hover {
  filter: drop-shadow(0 0 2em #61dafbaa);
}

@keyframes logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}

@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
    animation: logo-spin infinite 20s linear;
  }
}

.card {
  padding: 2em;
}

.read-the-docs {
  color: #888;
}

--- END OF FILE: frontend/s2a-drawing-ui/src/App.css ---
--- START OF FILE: frontend/s2a-drawing-ui/src/App.tsx ---
// frontend/s2a-drawing-ui/src/App.tsx
import React, { useState, useEffect, useRef, useCallback } from 'react';
import { io, Socket } from 'socket.io-client';
import './App.css'; // Ensure this file exists, even if minimal

const PYTHON_BACKEND_URL = 'http://localhost:5555';

let socket: Socket;
let mediaRecorder: MediaRecorder | null = null;
let audioChunks: Blob[] = [];

// Simple Icon Components
const MicIcon = () => (
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
    <path d="M5 3a3 3 0 0 1 6 0v5a3 3 0 0 1-6 0V3z"/>
    <path d="M3.5 6.5A.5.5 0 0 1 4 7v1a4 4 0 0 0 8 0V7a.5.5 0 0 1 1 0v1a5 5 0 0 1-4.5 4.975V15h3a.5.5 0 0 1 0 1h-7a.5.5 0 0 1 0-1h3v-2.025A5 5 0 0 1 3 8V7a.5.5 0 0 1 .5-.5z"/>
  </svg>
);

const StopIcon = () => (
 <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 16 16">
    <path d="M5 3.5h6A1.5 1.5 0 0 1 12.5 5v6a1.5 1.5 0 0 1-1.5 1.5H5A1.5 1.5 0 0 1 3.5 11V5A1.5 1.5 0 0 1 5 3.5z"/>
  </svg>
);

interface ThresholdOption {
  key: string;
  label: string;
  t1: number;
  t2: number;
}

const THRESHOLD_OPTIONS: ThresholdOption[] = Array.from({ length: 10 }, (_, i) => ({
  key: `opt${i + 1}`,
  label: `Style ${i + 1}`,
  t1: (i + 1) * 10 + 20, 
  t2: (i + 1) * 20 + 40, 
}));

interface DrawingHistoryItem {
    drawing_id: string;
    original_filename: string;
    status: string; // e.g., "completed", "interrupted", "in_progress", "aborted_manual_override"
    progress: number; // Percentage
    last_updated: string; // ISO date string
    robot_commands_tuples?: any[]; 
    current_command_index?: number;
    total_commands?: number;
}


function App() {
  const [isConnectedToBackend, setIsConnectedToBackend] = useState(false);
  const [isRobotConnected, setIsRobotConnected] = useState(false);
  const [robotStatusMessage, setRobotStatusMessage] = useState('Robot: Not connected');
  const [lastCommandResponse, setLastCommandResponse] = useState('');

  const [useRealRobot, setUseRealRobot] = useState(false); // New state for robot type selection

  const [qrCodeImage, setQrCodeImage] = useState<string | null>(null);
  const [qrUploadUrl, setQrUploadUrl] = useState<string>('');
  
  const [selectedFile, setSelectedFile] = useState<File | null>(null);
  const [imagePreviewUrl, setImagePreviewUrl] = useState<string | null>(null);
  const [isDragging, setIsDragging] = useState(false);
  const fileInputRef = useRef<HTMLInputElement>(null);

  const [lastUploadedImageInfo, setLastUploadedImageInfo] = useState<string>('');
  const [uploadedFilePathFromBackend, setUploadedFilePathFromBackend] = useState<string | null>(null);

  const [isDrawingActive, setIsDrawingActive] = useState(false); 
  const [activeDrawingId, setActiveDrawingId] = useState<string | null>(null); 
  const [drawingProgressMessage, setDrawingProgressMessage] = useState('');
  const [drawingProgressPercent, setDrawingProgressPercent] = useState(0);
  
  const [drawingHistory, setDrawingHistory] = useState<DrawingHistoryItem[]>([]);


  const [isRecording, setIsRecording] = useState(false);
  const [interactionStatus, setInteractionStatus] = useState('Tap mic or type command.');
  const [rawTranscribedText, setRawTranscribedText] = useState(''); 
  const [editableCommandText, setEditableCommandText] = useState(''); 
  const [llmResponse, setLlmResponse] = useState('');
  const audioStreamRef = useRef<MediaStream | null>(null);

  const [xCoord, setXCoord] = useState('');
  const [yCoord, setYCoord] = useState('');
  const [zCoord, setZCoord] = useState('');

  const [showThresholdModal, setShowThresholdModal] = useState(false);
  const [selectedThresholdKey, setSelectedThresholdKey] = useState<string>(THRESHOLD_OPTIONS[2].key); 
  const [thresholdPreviewImage, setThresholdPreviewImage] = useState<string | null>(null);
  const [isPreviewLoading, setIsPreviewLoading] = useState(false);

  const clearActiveDrawingState = useCallback(() => { 
    setIsDrawingActive(false);
    setActiveDrawingId(null);
    setDrawingProgressMessage('Idle');
    setDrawingProgressPercent(0);
  }, []); 

  useEffect(() => {
    socket = io(PYTHON_BACKEND_URL, { transports: ['websocket'] });

    socket.on('connect', () => {
      console.log('Frontend: Connected to Python backend via Socket.IO!');
      setIsConnectedToBackend(true);
      setInteractionStatus('Tap mic or type command.');
    });

    socket.on('disconnect', () => {
      console.log('Frontend: Disconnected from Python backend.');
      setIsConnectedToBackend(false);
      setIsRobotConnected(false);
      setRobotStatusMessage('Robot: Disconnected (backend offline)');
      setInteractionStatus('Backend offline. Please refresh or check server.');
      setShowThresholdModal(false); 
    });

    socket.on('robot_connection_status', (data: { success: boolean, message: string }) => {
      setIsRobotConnected(data.success);
      setRobotStatusMessage(`Robot: ${data.message}`);
    });

    socket.on('command_response', (data: { success: boolean, message: string, command_sent?: string }) => {
      setLastCommandResponse(`Cmd: ${data.command_sent || 'N/A'} -> Resp: ${data.message} (Success: ${data.success})`);
    });

    socket.on('qr_code_data', (data: { qr_image_base64?: string, upload_url?: string, error?: string }) => {
      if (data.error) {
        setQrUploadUrl(`Error generating QR: ${data.error}`);
        setQrCodeImage(null);
      } else if (data.qr_image_base64 && data.upload_url) {
        setQrCodeImage(`data:image/png;base64,${data.qr_image_base64}`);
        setQrUploadUrl(data.upload_url);
        setSelectedFile(null); setImagePreviewUrl(null);
      }
      setLastUploadedImageInfo(''); setUploadedFilePathFromBackend(null);
    });

    const handleImageUploadSuccess = (data: { success: boolean, message: string, original_filename?: string, filepath_on_server?: string}) => {
      if (data.success && data.filepath_on_server) {
        setLastUploadedImageInfo(`Received: ${data.original_filename || 'image'}. Ready for processing.`);
        setUploadedFilePathFromBackend(data.filepath_on_server);
        setQrCodeImage(null); setQrUploadUrl('');
        setSelectedFile(null); setImagePreviewUrl(null); 
      } else {
        setLastUploadedImageInfo(`Upload Info: ${data.message}`);
        setUploadedFilePathFromBackend(null);
      }
    };

    socket.on('qr_image_received', handleImageUploadSuccess);
    socket.on('direct_image_upload_response', handleImageUploadSuccess); 

    socket.on('drawing_status_update', (data: { 
        active: boolean, 
        message: string, 
        progress?: number, 
        resumable?: boolean, 
        drawing_id?: string,
        original_filename?: string 
      }) => {
      
      setDrawingProgressMessage(data.message);
      if (data.progress !== undefined) {
        setDrawingProgressPercent(data.progress);
      }

      if (data.active) {
        setIsDrawingActive(true); 
        if (data.drawing_id) {
          setActiveDrawingId(data.drawing_id); 
        }
      } else { 
        clearActiveDrawingState(); 
      }
    });

    socket.on('drawing_history_updated', (history: DrawingHistoryItem[]) => {
        console.log("Received drawing_history_updated:", history);
        setDrawingHistory(history || []);
    });


    socket.on('transcription_result', (data: { text?: string, error?: string }) => {
        if (data.error) {
            setInteractionStatus(`Transcription Error: ${data.error}`);
            setRawTranscribedText('');
            setEditableCommandText('');
            setLlmResponse('');
        } else if (data.text) {
            setRawTranscribedText(data.text); 
            setEditableCommandText(data.text); 
            setLlmResponse(''); 
            setInteractionStatus('Edit command below or send to Robotist.');
        }
    });
    
    socket.on('llm_response_chunk', (data: { chunk?: string, error?: string, done: boolean, final_message?: string }) => {
        if (data.error) {
            setLlmResponse(prev => prev + `\n[Error: ${data.error}]`);
            setInteractionStatus('LLM processing error.');
        } else if (data.chunk) {
            setLlmResponse(prev => prev + data.chunk);
            if (!data.done) {
                setInteractionStatus('Robotist is typing...');
            }
        }
        
        if (data.done) {
            if (data.final_message && !data.error) {
                setLlmResponse(data.final_message);
            }
            setInteractionStatus('Ready for next command.');
            if (data.error) {
                 setInteractionStatus(`LLM Error: ${data.error}`);
            } else if (!data.final_message && !data.chunk && llmResponse === "") { 
                 setInteractionStatus('Robotist finished.');
            }
        }
    });

    socket.on('threshold_preview_image_response', (data: { image_base64?: string, error?: string }) => {
        setIsPreviewLoading(false);
        if (data.error) {
            console.error("Error getting threshold preview:", data.error);
            setThresholdPreviewImage(null);
            alert(`Error generating preview: ${data.error}`);
        } else if (data.image_base64) {
            setThresholdPreviewImage(`data:image/png;base64,${data.image_base64}`);
        }
    });

    return () => { 
        if (socket) socket.disconnect(); 
        if (audioStreamRef.current) {
            audioStreamRef.current.getTracks().forEach(track => track.stop());
        }
    };
  // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [clearActiveDrawingState]); 

  const requestThresholdPreview = useCallback((key: string) => {
    const selectedOpt = THRESHOLD_OPTIONS.find(opt => opt.key === key);
    if (selectedOpt && uploadedFilePathFromBackend && socket) {
        setIsPreviewLoading(true);
        setThresholdPreviewImage(null); 
        console.log(`Requesting preview for T1=${selectedOpt.t1}, T2=${selectedOpt.t2}`);
        socket.emit('request_threshold_preview', {
            filepath: uploadedFilePathFromBackend,
            t1: selectedOpt.t1,
            t2: selectedOpt.t2,
        });
    }
  }, [uploadedFilePathFromBackend]);

  useEffect(() => {
    if (showThresholdModal && selectedThresholdKey && uploadedFilePathFromBackend) {
        requestThresholdPreview(selectedThresholdKey);
    }
  }, [selectedThresholdKey, showThresholdModal, uploadedFilePathFromBackend, requestThresholdPreview]); 


  const handleConnectRobot = () => { 
    if (!isDrawingActive && socket) {
      // Send the useRealRobot state to the backend
      socket.emit('robot_connect_request', { use_real_robot: useRealRobot }); 
    }
  }
  const handleDisconnectRobot = () => { if (!isDrawingActive && socket) socket.emit('robot_disconnect_request', {}); }
  const sendGoHomeCommand = () => { 
    if (!isDrawingActive && socket) {
      socket.emit('send_robot_command', { type: 'go_home' }); 
    } else if (isDrawingActive) {
      alert("Cannot send 'Go Home' command while drawing is active.");
    }
  }
  const sendSafeCenterCommand = () => { 
    if (!isDrawingActive && socket) {
      socket.emit('send_robot_command', { type: 'move_to_safe_center' }); 
    } else if (isDrawingActive) {
      alert("Cannot send 'Safe Center' command while drawing is active.");
    }
  }
  
  const requestQrCode = () => {
    if (socket && isConnectedToBackend && !isDrawingActive) {
      setQrCodeImage(null); setQrUploadUrl('Requesting QR Code...');
      setSelectedFile(null); setImagePreviewUrl(null); 
      setLastUploadedImageInfo(''); setUploadedFilePathFromBackend(null);
      socket.emit('request_qr_code', {});
    } else if (isDrawingActive) { alert("Cannot request QR code while drawing is in progress."); }
  };

  const processNewFile = (file: File | null) => {
    if (file && file.type.startsWith('image/')) {
      setSelectedFile(file); setImagePreviewUrl(URL.createObjectURL(file));
      setQrCodeImage(null); setQrUploadUrl('');
      setLastUploadedImageInfo(''); setUploadedFilePathFromBackend(null);
    } else {
      setSelectedFile(null); setImagePreviewUrl(null);
      if (file) { alert('Please select/drop an image file.'); }
    }
  };
  const handleFileSelect = (event: React.ChangeEvent<HTMLInputElement>) => { processNewFile(event.target.files?.[0] || null); };
  const handleDrop = useCallback((event: React.DragEvent<HTMLDivElement>) => {
    event.preventDefault(); event.stopPropagation(); setIsDragging(false);
    processNewFile(event.dataTransfer.files?.[0] || null);
  }, []);
  const handleDragOver = useCallback((event: React.DragEvent<HTMLDivElement>) => {
    event.preventDefault(); event.stopPropagation();
    if (!isDrawingActive && !isDragging) setIsDragging(true);
  }, [isDrawingActive, isDragging]);
  const handleDragLeave = useCallback((event: React.DragEvent<HTMLDivElement>) => {
    event.preventDefault(); event.stopPropagation(); setIsDragging(false);
  }, []);
  const triggerFileInput = () => { if (!isDrawingActive) { fileInputRef.current?.click(); } };
  const sendSelectedFileToBackend = () => {
    if (!selectedFile || !socket || !isConnectedToBackend || isDrawingActive) {
      alert("Cannot send file. Check connection, file selection, or drawing status."); return;
    }
    const reader = new FileReader();
    reader.onload = (e) => {
      const base64Data = (e.target?.result as string)?.split(',')[1];
      if (base64Data) {
        setLastUploadedImageInfo(`Sending ${selectedFile.name} to backend...`);
        socket.emit('direct_image_upload', { filename: selectedFile.name, fileData: base64Data });
      } else { alert("Could not read file data."); setLastUploadedImageInfo("Error reading file.");}
    };
    reader.onerror = () => { alert("Error reading file."); setLastUploadedImageInfo("Error reading file.");};
    reader.readAsDataURL(selectedFile); 
  };

  const handleProcessAndDrawUploadedImage = () => {
    if (isDrawingActive) { alert("A drawing is already in progress."); return; }
    if (!isRobotConnected) { alert("Please connect to the robot first."); setLastCommandResponse("Error: Robot not connected."); return; }
    if (uploadedFilePathFromBackend) {
      setSelectedThresholdKey(THRESHOLD_OPTIONS[2].key); 
      setThresholdPreviewImage(null); 
      setShowThresholdModal(true); 
    } else { 
      alert("No image has been successfully uploaded to the backend yet."); 
      setLastCommandResponse("Error: No backend image path available.");
    }
  };

  const confirmAndStartDrawingWithThresholds = () => {
    if (!uploadedFilePathFromBackend) {
        alert("Error: No image path available for drawing.");
        setShowThresholdModal(false);
        return;
    }
    const selectedOpt = THRESHOLD_OPTIONS.find(opt => opt.key === selectedThresholdKey);
    if (!selectedOpt) {
        alert("Invalid threshold option selected.");
        return;
    }
    const originalFilename = lastUploadedImageInfo.includes("Received: ") ? lastUploadedImageInfo.split("Received: ")[1].split(". Ready")[0] : "uploaded_image";
    socket.emit('process_image_for_drawing', { 
        filepath: uploadedFilePathFromBackend, 
        original_filename: originalFilename,
        canny_t1: selectedOpt.t1,
        canny_t2: selectedOpt.t2
    });
    setLastCommandResponse(`Sent request to process & draw: ${originalFilename} with T1=${selectedOpt.t1}, T2=${selectedOpt.t2}`);
    setDrawingProgressMessage("Requesting image processing and drawing..."); 
    setDrawingProgressPercent(0);
    setShowThresholdModal(false); 
  };

  const handleResumeDrawingFromHistory = (drawingId: string) => {
    if (isDrawingActive) {
        alert("Another drawing is already active. Cannot resume now.");
        return;
    }
    if (socket && isConnectedToBackend) {
        console.log(`Frontend: Emitting 'resume_drawing_request' for ID: ${drawingId}`);
        socket.emit('resume_drawing_request', { drawing_id: drawingId });
    } else {
        alert("Cannot resume. Backend not connected.");
    }
  };

  const handleRestartDrawingFromHistory = (drawingId: string) => {
    if (isDrawingActive) {
        alert("Another drawing is already active. Cannot restart now.");
        return;
    }
    if (socket && isConnectedToBackend) {
        console.log(`Frontend: Emitting 'restart_drawing_request' for ID: ${drawingId}`);
        socket.emit('restart_drawing_request', { drawing_id: drawingId });
    } else {
        alert("Cannot restart. Backend not connected.");
    }
  };


  const startRecording = async () => {
    if (isDrawingActive || !isConnectedToBackend) {
        alert("Cannot record voice while drawing is active or backend is disconnected.");
        return;
    }
    setRawTranscribedText('');
    setEditableCommandText('');
    setLlmResponse('');
    setInteractionStatus('Requesting mic permission...');

    try {
        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioStreamRef.current = stream; 
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' }); 
        audioChunks = [];

        mediaRecorder.ondataavailable = (event) => { audioChunks.push(event.data); };
        mediaRecorder.onstop = () => {
            setInteractionStatus('Sending audio for transcription...');
            const audioBlob = new Blob(audioChunks, { type: mediaRecorder?.mimeType });
            const reader = new FileReader();
            reader.onloadend = () => {
                const base64Audio = (reader.result as string)?.split(',')[1];
                if (socket && base64Audio) {
                    socket.emit('audio_chunk', { audioData: base64Audio, mimeType: mediaRecorder?.mimeType });
                } else { setInteractionStatus("Error: Could not send audio data."); }
            };
            reader.onerror = () => { setInteractionStatus("Error reading audio blob."); };
            reader.readAsDataURL(audioBlob);
            if (audioStreamRef.current) {
                audioStreamRef.current.getTracks().forEach(track => track.stop());
                audioStreamRef.current = null;
            }
        };
        mediaRecorder.start();
        setIsRecording(true);
        setInteractionStatus('Recording... Tap mic to stop.');
    } catch (err) {
        console.error("Error accessing microphone:", err);
        setInteractionStatus('Mic permission denied or error.');
        if (audioStreamRef.current) { 
            audioStreamRef.current.getTracks().forEach(track => track.stop());
            audioStreamRef.current = null;
        }
    }
  };

  const stopRecording = () => {
    if (mediaRecorder && isRecording) {
        mediaRecorder.stop();
        setIsRecording(false);
    }
  };

  const handleMicButtonClick = () => {
    if (isRecording) stopRecording();
    else startRecording();
  };

  const submitTextToLLM = (text: string) => {
    if (!text.trim()) {
      alert("Command text cannot be empty.");
      setInteractionStatus('Command empty. Tap mic or type command.');
      return;
    }
    if (socket && isConnectedToBackend && socket.connected) { 
      socket.emit('submit_text_to_llm', { text_command: text });
      setLlmResponse(''); 
      setInteractionStatus('Robotist is thinking...');
      if (text !== rawTranscribedText) setRawTranscribedText('');
    } else {
      alert("Cannot send command. Backend not connected or socket issue.");
      setInteractionStatus('Backend disconnected or socket issue.');
    }
  };

  const handleSendEditableCommand = () => { submitTextToLLM(editableCommandText); };

  const handleSendCustomCoordinates = () => {
    if (!isRobotConnected) {
        alert("Robot not connected.");
        return;
    }
    if (isDrawingActive) {
        alert("Cannot send coordinates while drawing is active.");
        return;
    }
    const x = parseFloat(xCoord);
    const y = parseFloat(yCoord); 
    const z = parseFloat(zCoord); 

    if (isNaN(x) || isNaN(y) || isNaN(z)) {
        alert("Invalid coordinates. Please enter numbers for X, Y (depth), and Z (side-to-side).");
        return;
    }
    if (socket) {
        socket.emit('send_custom_coordinates', { x_py: x, z_py: y, y_py: z });
        setLastCommandResponse(`Sent custom coords: X=${x}, Depth=${y}, Side=${z}`);
    }
  };

  const styles: { [key: string]: React.CSSProperties } = {
    appContainer: { maxWidth: '1400px', margin: '0 auto', padding: '20px', fontFamily: 'Arial, sans-serif', color: '#e0e0e0', backgroundColor: '#1e1e1e' }, 
    header: { textAlign: 'center' as const, marginBottom: '30px', borderBottom: '1px solid #444', paddingBottom: '20px' },
    mainTitle: { fontSize: '2.5em', color: '#61dafb', margin: '0 0 10px 0' },
    statusText: { fontSize: '0.9em', color: isConnectedToBackend ? '#76ff03' : '#ff5252' },
    mainLayoutContainer: { display: 'flex', flexDirection: 'column', gap: '25px' }, 
    topRowGrid: { display: 'grid', gridTemplateColumns: '1fr 2fr 1.5fr', gap: '25px', alignItems: 'start', marginBottom: '25px' }, 
    section: { backgroundColor: '#2a2a2a', padding: '20px', borderRadius: '8px', boxShadow: '0 4px 8px rgba(0,0,0,0.2)', display: 'flex', flexDirection: 'column', minHeight: '300px' }, 
    sectionTitle: { fontSize: '1.5em', color: '#61dafb', borderBottom: '1px solid #444', paddingBottom: '10px', marginBottom: '15px' },
    button: { backgroundColor: '#007bff', color: 'white', border: 'none', padding: '10px 15px', borderRadius: '5px', cursor: 'pointer', fontSize: '1em', margin: '5px', transition: 'background-color 0.2s ease' },
    buttonDisabled: { backgroundColor: '#555', cursor: 'not-allowed', opacity: 0.6 }, 
    micButton: { backgroundColor: isRecording ? '#dc3545' : '#007bff', width: '60px', height: '60px', borderRadius: '50%', display: 'flex', alignItems: 'center', justifyContent: 'center' },
    textarea: { width: 'calc(100% - 22px)', padding: '10px', marginBottom: '10px', borderRadius: '4px', border: '1px solid #444', backgroundColor: '#333', color: '#fff', minHeight: '60px' },
    imageUploadContainer: { display: 'flex', flexDirection: 'column', gap: '20px'}, 
    uploadBox: { border: '1px dashed #555', padding: '20px', borderRadius: '8px', textAlign: 'center' as const, backgroundColor: '#333', transition: 'background-color 0.2s, border-color 0.2s', flex: 1 },
    uploadBoxDragging: { borderColor: '#007bff', backgroundColor: '#3a3a3a' },
    imagePreview: { maxWidth: '100%', maxHeight: '150px', border: '1px solid #444', borderRadius: '4px', marginTop: '10px' },
    progressBarContainer: { width: '100%', backgroundColor: '#444', borderRadius: '4px', overflow: 'hidden', marginTop: '10px' },
    progressBar: { width: `${drawingProgressPercent}%`, backgroundColor: '#61dafb', height: '20px', textAlign: 'center' as const, lineHeight: '20px', color: '#1e1e1e', transition: 'width 0.3s ease' },
    robotStatus: { padding: '10px', backgroundColor: '#333', borderRadius: '4px', fontSize: '0.9em', marginTop: '10px' },
    llmResponseBox: { marginTop: '15px', padding: '15px', border: '1px solid #444', borderRadius: '4px', backgroundColor: '#333', whiteSpace: 'pre-wrap' as const, maxHeight: '200px', overflowY: 'auto' as const, flexGrow: 1},
    coordInputContainer: { display: 'flex', flexDirection: 'column', gap: '10px', marginTop: '15px', marginBottom: '15px' },
    coordInputGroup: { display: 'flex', alignItems: 'center', gap: '10px' },
    coordLabel: { minWidth: '70px', textAlign: 'right' as const, color: '#bbb' },
    coordInput: { flexGrow: 1, padding: '8px', borderRadius: '4px', border: '1px solid #444', backgroundColor: '#333', color: '#fff' },
    checkboxContainer: { display: 'flex', alignItems: 'center', justifyContent: 'center', margin: '10px 0', color: '#ccc' }, // Style for checkbox
    checkboxInput: { marginRight: '8px', accentColor: '#61dafb' }, // Style for checkbox input
    modalOverlay: { position: 'fixed', top: 0, left: 0, right: 0, bottom: 0, backgroundColor: 'rgba(0,0,0,0.7)', display: 'flex', alignItems: 'center', justifyContent: 'center', zIndex: 1000 },
    modalContent: { backgroundColor: '#2a2a2a', padding: '30px', borderRadius: '8px', boxShadow: '0 5px 15px rgba(0,0,0,0.3)', width: 'auto', minWidth: '750px', maxWidth: '900px', color: '#e0e0e0' },
    modalTitle: { fontSize: '1.8em', color: '#61dafb', marginBottom: '20px', textAlign: 'center' as const },
    modalColumns: { display: 'flex', gap: '20px' },
    modalColumn: { flex: 1 },
    modalRadioGroup: { maxHeight: '550px', overflowY: 'auto', paddingRight: '10px' }, 
    modalRadioLabel: { display: 'block', marginBottom: '8px', cursor: 'pointer', padding: '8px', borderRadius: '4px', transition: 'background-color 0.2s' },
    modalRadioLabelSelected: { backgroundColor: '#007bff', color: 'white' },
    modalPreviewArea: { textAlign: 'center' as const, borderLeft: '1px solid #444', paddingLeft: '20px', display: 'flex', flexDirection: 'column', alignItems: 'center', justifyContent: 'center' },
    modalPreviewImage: { maxWidth: '350px', maxHeight: '350px', border: '1px solid #555', borderRadius: '4px', backgroundColor: '#1e1e1e', minHeight: '250px' }, 
    modalActions: { marginTop: '25px', textAlign: 'right' as const },
    historySection: { },
    historyList: { listStyle: 'none', padding: 0, maxHeight: '400px', overflowY: 'auto'},
    historyItem: { backgroundColor: '#333', padding: '15px', borderRadius: '6px', marginBottom: '10px', borderLeft: '5px solid #007bff' },
    historyItemCompleted: { borderLeftColor: '#28a745' },
    historyItemInterrupted: { borderLeftColor: '#ffc107' },
    historyItemInProgress: { borderLeftColor: '#17a2b8' },
    historyDetails: { fontSize: '0.9em', color: '#bbb', marginBottom: '8px' },
    historyActions: { marginTop: '10px' },
  };

  return (
    <div style={styles.appContainer}>
      <header style={styles.header}>
        <h1 style={styles.mainTitle}>CamTech Robotic Drawing Control</h1>
        <p style={styles.statusText}>Backend: {isConnectedToBackend ? 'Connected' : 'Disconnected'}</p>
      </header>

      <div style={styles.mainLayoutContainer}>
        <div style={styles.topRowGrid}>
          {/* Column 1: Robot Control */}
          <section style={styles.section}>
            <h2 style={styles.sectionTitle}>Robot Control</h2>
            <div style={styles.checkboxContainer}> {/* Checkbox for robot type */}
              <input 
                type="checkbox" 
                id="robotType" 
                checked={useRealRobot} 
                onChange={(e) => setUseRealRobot(e.target.checked)}
                disabled={isRobotConnected || isDrawingActive || isRecording}
                style={styles.checkboxInput}
              />
              <label htmlFor="robotType" style={{cursor: (isRobotConnected || isDrawingActive || isRecording) ? 'not-allowed' : 'pointer'}}>
                Connect to Real Robot (Unchecked = Simulation)
              </label>
            </div>
            <div style={{textAlign: 'center'}}>
              <button onClick={handleConnectRobot} disabled={!isConnectedToBackend || isRobotConnected || isDrawingActive || isRecording} style={{...styles.button, ...((!isConnectedToBackend || isRobotConnected || isDrawingActive || isRecording) && styles.buttonDisabled)}}> Connect to Robot </button>
              <button onClick={handleDisconnectRobot} disabled={!isConnectedToBackend || !isRobotConnected || isDrawingActive || isRecording} style={{...styles.button, backgroundColor: '#ffc107', color: '#1e1e1e', ...((!isConnectedToBackend || !isRobotConnected || isDrawingActive || isRecording) && styles.buttonDisabled)}}> Disconnect Robot</button>
              <br />
              <button onClick={sendGoHomeCommand} disabled={!isConnectedToBackend || !isRobotConnected || isDrawingActive || isRecording} style={{...styles.button, marginTop: '10px', ...((!isConnectedToBackend || !isRobotConnected || isDrawingActive || isRecording) && styles.buttonDisabled)}}> Send Robot to Home </button>
              <button onClick={sendSafeCenterCommand} disabled={!isConnectedToBackend || !isRobotConnected || isDrawingActive || isRecording} style={{...styles.button, marginTop: '10px', ...((!isConnectedToBackend || !isRobotConnected || isDrawingActive || isRecording) && styles.buttonDisabled)}}> Send to Safe Center </button>
            </div>

            <div style={styles.coordInputContainer}>
              <h3 style={{fontSize: '1.2em', color: '#ccc', marginBottom: '10px', textAlign: 'center'}}>Move to Specific Position:</h3>
              <div style={styles.coordInputGroup}>
                <label htmlFor="x-coord" style={styles.coordLabel}>X (mm):</label>
                <input type="number" id="x-coord" value={xCoord} onChange={(e) => setXCoord(e.target.value)} placeholder="e.g., 100" style={styles.coordInput} disabled={!isRobotConnected || isDrawingActive} />
              </div>
              <div style={styles.coordInputGroup}>
                <label htmlFor="y-coord" style={styles.coordLabel}>Y/Depth (mm):</label>
                <input type="number" id="y-coord" value={yCoord} onChange={(e) => setYCoord(e.target.value)} placeholder="e.g., -150" style={styles.coordInput} disabled={!isRobotConnected || isDrawingActive} />
              </div>
              <div style={styles.coordInputGroup}>
                <label htmlFor="z-coord" style={styles.coordLabel}>Z/Side (mm):</label>
                <input type="number" id="z-coord" value={zCoord} onChange={(e) => setZCoord(e.target.value)} placeholder="e.g., 50" style={styles.coordInput} disabled={!isRobotConnected || isDrawingActive} />
              </div>
              <button onClick={handleSendCustomCoordinates} disabled={!isRobotConnected || isDrawingActive || !xCoord || !yCoord || !zCoord} style={{...styles.button, marginTop: '10px', backgroundColor: '#17a2b8', ...((!isRobotConnected || isDrawingActive || !xCoord || !yCoord || !zCoord) && styles.buttonDisabled)}}>
                Send Custom Coordinates
              </button>
            </div>

            <div style={styles.robotStatus}>
                <p style={{margin: 0, color: isRobotConnected ? '#76ff03' : '#ffc107'}}>{robotStatusMessage}</p>
            </div>
            {lastCommandResponse && <p style={{fontSize: '0.9em', color: '#aaa', marginTop: '10px', textAlign: 'center'}}>Last Command: {lastCommandResponse}</p>}
          </section>

          {/* Column 2: Robotist Interaction */}
          <section style={styles.section}>
            <h2 style={styles.sectionTitle}>Robotist Interaction</h2>
            <div style={{ display: 'flex', alignItems: 'center', marginBottom: '15px' }}>
              <button 
                  onClick={handleMicButtonClick} 
                  disabled={!isConnectedToBackend || isDrawingActive}
                  style={{...styles.button, ...styles.micButton, ...( (!isConnectedToBackend || isDrawingActive) && styles.buttonDisabled) }}
                  title={isRecording ? "Stop Recording" : "Start Voice Command"}
              >
                  {isRecording ? <StopIcon /> : <MicIcon />}
              </button>
              <p style={{ margin: '0 0 0 15px', flexGrow: 1, color: '#bbbbbb' }}>{interactionStatus}</p>
            </div>

            {rawTranscribedText && <p style={{fontSize: '0.9em', color: '#aaa', fontStyle: 'italic', marginBottom: '10px'}}>You said: "{rawTranscribedText}"</p>}
            
            <textarea 
                value={editableCommandText}
                onChange={(e) => setEditableCommandText(e.target.value)}
                placeholder="Type command or edit transcribed text here..."
                style={styles.textarea}
                disabled={!isConnectedToBackend || isDrawingActive || isRecording}
            />
            <button 
                onClick={handleSendEditableCommand} 
                disabled={!editableCommandText.trim() || !isConnectedToBackend || isDrawingActive || isRecording}
                style={{...styles.button, ...( (!editableCommandText.trim() || !isConnectedToBackend || isDrawingActive || isRecording) && styles.buttonDisabled) }}
            >
                Send Command to Robotist
            </button>

            {llmResponse && (
              <div style={styles.llmResponseBox}>
                <p style={{ margin: 0 }}><b>Robotist:</b> {llmResponse}</p>
              </div>
            )}
          </section>
          
          {/* Column 3: Image Input */}
          <section style={styles.section}>
            <h2 style={styles.sectionTitle}>Image Input</h2>
            <div style={styles.imageUploadContainer}> 
              <div style={styles.uploadBox}>
                <h3>Upload via QR Code</h3>
                <button onClick={requestQrCode} disabled={!isConnectedToBackend || isDrawingActive || isRecording} style={{...styles.button, ...((!isConnectedToBackend || isDrawingActive || isRecording) && styles.buttonDisabled)}}>
                  Get QR Code
                </button>
                {qrUploadUrl && !qrCodeImage && <p style={{fontSize: '0.8em', wordBreak: 'break-all', color: '#aaa'}}><small>{qrUploadUrl}</small></p>}
                {qrCodeImage && ( <div> <p style={{fontSize: '0.8em', color: '#aaa'}}><small>Scan to upload. URL: {qrUploadUrl}</small></p> <img src={qrCodeImage} alt="QR Code for Upload" style={styles.imagePreview} /> </div> )}
              </div>
              <div 
                style={{...styles.uploadBox, ...(isDragging && styles.uploadBoxDragging), opacity: (isDrawingActive || isRecording) ? 0.6 : 1, pointerEvents: (isDrawingActive || isRecording) ? 'none' : 'auto' }}
                onDragOver={handleDragOver} onDragLeave={handleDragLeave} onDrop={handleDrop} 
              >
                <h3>Upload from Desktop</h3>
                <input type="file" accept="image/*" onChange={handleFileSelect} ref={fileInputRef} style={{ display: 'none' }} disabled={isDrawingActive || isRecording} />
                <button onClick={triggerFileInput} disabled={isDrawingActive || isRecording} style={{...styles.button, ...((isDrawingActive || isRecording) && styles.buttonDisabled)}}> Choose Image File </button>
                <p style={{fontSize: '0.9em', marginTop: '10px', color: '#aaa'}}>Or drag & drop image here</p>
                {imagePreviewUrl && selectedFile && ( <div style={{marginTop: '15px'}}> <p style={{color: '#bbb'}}>Preview:</p> <img src={imagePreviewUrl} alt="Selected preview" style={styles.imagePreview}/> <p style={{fontSize: '0.8em', color: '#aaa'}}>{selectedFile.name}</p> <button onClick={sendSelectedFileToBackend} disabled={!selectedFile || isDrawingActive || !isConnectedToBackend || isRecording} style={{...styles.button, marginTop: '10px', ...((!selectedFile || isDrawingActive || !isConnectedToBackend || isRecording) && styles.buttonDisabled)}} > Upload This Image </button> </div> )}
              </div>
            </div>
            {lastUploadedImageInfo && <p style={{color: lastUploadedImageInfo.startsWith("Received:") ? "#76ff03" : (lastUploadedImageInfo.startsWith("Error") ? "#ff5252" : "#ffc107"), fontWeight: 'bold', textAlign: 'center', marginTop: '15px'}}>{lastUploadedImageInfo}</p>}
            {uploadedFilePathFromBackend && ( <button onClick={handleProcessAndDrawUploadedImage} disabled={isDrawingActive || !isRobotConnected || !isConnectedToBackend || isRecording} style={{...styles.button, backgroundColor: '#28a745', display: 'block', margin: '20px auto', padding: '12px 25px', fontSize: '1.1em', ...((isDrawingActive || !isRobotConnected || !isConnectedToBackend || isRecording) && styles.buttonDisabled)}} > Process & Draw Uploaded Image </button> )}
            
            {isDrawingActive && activeDrawingId && (
              <div style={{marginTop: '20px'}}>
                <p style={{color: "#61dafb", fontWeight: "bold", textAlign: 'center'}}>{drawingProgressMessage}</p>
                <div style={styles.progressBarContainer}>
                  <div style={styles.progressBar}>{drawingProgressPercent.toFixed(0)}%</div>
                </div>
              </div>
            )}
            {!isDrawingActive && drawingProgressMessage && !lastUploadedImageInfo.startsWith("Received:") && <p style={{textAlign: 'center', marginTop: '15px', color: '#aaa'}}>{drawingProgressMessage}</p>}
          </section>
        </div>

        {/* Drawing History Section */}
        {drawingHistory.length > 0 && (
            <section style={{...styles.section, ...styles.historySection, marginTop: '25px'}}>
                <h2 style={styles.sectionTitle}>Drawing History (Last {drawingHistory.length})</h2>
                <ul style={styles.historyList}>
                    {drawingHistory.map(item => (
                        <li 
                            key={item.drawing_id} 
                            style={{
                                ...styles.historyItem, 
                                ...(item.status === 'completed' ? styles.historyItemCompleted : {}),
                                ...(item.status === 'interrupted' || item.status === 'interrupted_error' ? styles.historyItemInterrupted : {}),
                                ...(item.status && item.status.startsWith('in_progress') ? styles.historyItemInProgress : {}),
                            }}
                        >
                            <p style={{margin: '0 0 5px 0', fontWeight: 'bold', color: '#f0f0f0'}}>{item.original_filename}</p>
                            <p style={styles.historyDetails}>Status: {item.status.replace(/_/g, ' ')}</p>
                            {(item.status.includes('in_progress') || item.status.includes('interrupted')) && (
                                <p style={styles.historyDetails}>Progress: {item.progress.toFixed(0)}%</p>
                            )}
                            <p style={styles.historyDetails}>Last Update: {new Date(item.last_updated).toLocaleString()}</p>
                            <div style={styles.historyActions}>
                                {(item.status.includes('interrupted') || item.status.includes('in_progress')) && item.status !== 'completed' && (
                                    <button 
                                        onClick={() => handleResumeDrawingFromHistory(item.drawing_id)}
                                        style={{...styles.button, backgroundColor: '#ffc107', color: '#1e1e1e'}}
                                        disabled={isDrawingActive || !isConnectedToBackend || !isRobotConnected}
                                    >
                                        Resume
                                    </button>
                                )}
                                <button 
                                    onClick={() => handleRestartDrawingFromHistory(item.drawing_id)}
                                    style={{...styles.button, backgroundColor: '#17a2b8'}}
                                    disabled={isDrawingActive || !isConnectedToBackend || !isRobotConnected}
                                >
                                    Restart
                                </button>
                            </div>
                        </li>
                    ))}
                </ul>
            </section>
        )}

      </div>

      {/* Threshold Selection Modal */}
      {showThresholdModal && (
        <div style={styles.modalOverlay}>
          <div style={styles.modalContent}>
            <h3 style={styles.modalTitle}>Select Drawing Details</h3>
            <div style={styles.modalColumns}>
                <div style={{...styles.modalColumn, ...styles.modalRadioGroup}}>
                    {THRESHOLD_OPTIONS.map(option => (
                        <label 
                            key={option.key} 
                            htmlFor={option.key}
                            style={{
                                ...styles.modalRadioLabel,
                                ...(selectedThresholdKey === option.key ? styles.modalRadioLabelSelected : {})
                            }}
                            onMouseEnter={(e) => (e.currentTarget.style.backgroundColor = selectedThresholdKey === option.key ? '#0056b3' : '#444')}
                            onMouseLeave={(e) => (e.currentTarget.style.backgroundColor = selectedThresholdKey === option.key ? '#007bff' : 'transparent')}
                        >
                            <input 
                                type="radio" 
                                id={option.key} 
                                name="thresholdOption" 
                                value={option.key}
                                checked={selectedThresholdKey === option.key}
                                onChange={() => setSelectedThresholdKey(option.key)}
                                style={{ marginRight: '10px', accentColor: '#61dafb' }}
                            />
                            {option.label} (T1: {option.t1}, T2: {option.t2})
                        </label>
                    ))}
                </div>
                <div style={{...styles.modalColumn, ...styles.modalPreviewArea}}>
                    <h4>Preview:</h4>
                    {isPreviewLoading && <p style={{color: '#aaa'}}>Loading preview...</p>}
                    {!isPreviewLoading && thresholdPreviewImage && (
                        <img src={thresholdPreviewImage} alt="Edge preview" style={styles.modalPreviewImage} />
                    )}
                    {!isPreviewLoading && !thresholdPreviewImage && (
                        <div style={{...styles.modalPreviewImage, display: 'flex', alignItems: 'center', justifyContent: 'center', color: '#777'}}>
                            <span>No preview available</span>
                        </div>
                    )}
                </div>
            </div>
            <div style={styles.modalActions}>
              <button 
                onClick={() => setShowThresholdModal(false)} 
                style={{...styles.button, backgroundColor: '#6c757d', marginRight: '10px'}}
              >
                Cancel
              </button>
              <button 
                onClick={confirmAndStartDrawingWithThresholds} 
                style={{...styles.button, backgroundColor: '#28a745'}}
                disabled={isPreviewLoading}
              >
                Start Drawing
              </button>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}

export default App;

--- END OF FILE: frontend/s2a-drawing-ui/src/App.tsx ---
--- START OF FILE: frontend/s2a-drawing-ui/src/index.css ---
:root {
  font-family: Inter, system-ui, Avenir, Helvetica, Arial, sans-serif;
  line-height: 1.5;
  font-weight: 400;

  color-scheme: light dark;
  color: rgba(255, 255, 255, 0.87);
  background-color: #242424;

  font-synthesis: none;
  text-rendering: optimizeLegibility;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

a {
  font-weight: 500;
  color: #646cff;
  text-decoration: inherit;
}
a:hover {
  color: #535bf2;
}

body {
  margin: 0;
  display: flex;
  place-items: center;
  min-width: 320px;
  min-height: 100vh;
}

h1 {
  font-size: 3.2em;
  line-height: 1.1;
}

button {
  border-radius: 8px;
  border: 1px solid transparent;
  padding: 0.6em 1.2em;
  font-size: 1em;
  font-weight: 500;
  font-family: inherit;
  background-color: #1a1a1a;
  cursor: pointer;
  transition: border-color 0.25s;
}
button:hover {
  border-color: #646cff;
}
button:focus,
button:focus-visible {
  outline: 4px auto -webkit-focus-ring-color;
}

@media (prefers-color-scheme: light) {
  :root {
    color: #213547;
    background-color: #ffffff;
  }
  a:hover {
    color: #747bff;
  }
  button {
    background-color: #f9f9f9;
  }
}

--- END OF FILE: frontend/s2a-drawing-ui/src/index.css ---
--- START OF FILE: frontend/s2a-drawing-ui/src/main.tsx ---
import React from 'react'
import ReactDOM from 'react-dom/client'
import App from './App.tsx'
import './index.css'

ReactDOM.createRoot(document.getElementById('root')!).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
)

// Use contextBridge
window.ipcRenderer.on('main-process-message', (_event, message) => {
  console.log(message)
})

--- END OF FILE: frontend/s2a-drawing-ui/src/main.tsx ---
--- START OF FILE: frontend/s2a-drawing-ui/src/vite-env.d.ts ---
/// <reference types="vite/client" />

--- END OF FILE: frontend/s2a-drawing-ui/src/vite-env.d.ts ---
--- START OF FILE: frontend/s2a-drawing-ui/tsconfig.json ---
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true
  },
  "include": ["src", "electron"],
  "references": [{ "path": "./tsconfig.node.json" }]
}

--- END OF FILE: frontend/s2a-drawing-ui/tsconfig.json ---
--- START OF FILE: frontend/s2a-drawing-ui/tsconfig.node.json ---
{
  "compilerOptions": {
    "composite": true,
    "skipLibCheck": true,
    "module": "ESNext",
    "moduleResolution": "bundler",
    "allowSyntheticDefaultImports": true,
    "strict": true
  },
  "include": ["vite.config.ts"]
}

--- END OF FILE: frontend/s2a-drawing-ui/tsconfig.node.json ---
--- START OF FILE: frontend/s2a-drawing-ui/vite.config.ts ---
import { defineConfig } from 'vite'
import path from 'node:path'
import electron from 'vite-plugin-electron/simple'
import react from '@vitejs/plugin-react'

// https://vitejs.dev/config/
export default defineConfig({
  plugins: [
    react(),
    electron({
      main: {
        // Shortcut of `build.lib.entry`.
        entry: 'electron/main.ts',
      },
      preload: {
        // Shortcut of `build.rollupOptions.input`.
        // Preload scripts may contain Web assets, so use the `build.rollupOptions.input` instead `build.lib.entry`.
        input: path.join(__dirname, 'electron/preload.ts'),
      },
      // Ployfill the Electron and Node.js API for Renderer process.
      // If you want use Node.js in Renderer process, the `nodeIntegration` needs to be enabled in the Main process.
      // See 👉 https://github.com/electron-vite/vite-plugin-electron-renderer
      renderer: process.env.NODE_ENV === 'test'
        // https://github.com/electron-vite/vite-plugin-electron-renderer/issues/78#issuecomment-2053600808
        ? undefined
        : {},
    }),
  ],
})

--- END OF FILE: frontend/s2a-drawing-ui/vite.config.ts ---
--- START OF FILE: README.md ---
# Speech to Action Robotic Drawing Application (Locally)

## Introduction to the project

The "Speech to Action Robotic Drawing" application enables users to control a GOFA CRB 15000 robot arm using natural voice commands to draw images. It features a desktop application with a JavaScript/TypeScript frontend (built with Electron) for a rich user interface and a Python backend to handle core logic including speech recognition, natural language understanding via a local LLM, image processing, and robot control. This document provides guidance for developers on setting up and contributing to the project.
---

## Showcase (Update Later)

*(This section will be updated with screenshots, GIFs, or videos demonstrating the application's capabilities once available.)*

---

## Set up and Run (User Guide - Update Later)

*(This section will detail how an end-user can set up and run the packaged application once it's ready for distribution. This is different from the developer setup below.)*

---

# Developer Notes

This section provides step-by-step instructions for developers to set up the project on a new machine, contribute to the codebase, and run/test the application.

**Current Development Goal: Streaming STT and LLM Output**
To enhance the conversational feel of the application, a key development goal is to implement streaming Speech-to-Text (STT) and streaming Large Language Model (LLM) output. This means processing audio as it's received to get faster partial transcriptions, and sending the LLM's response token-by-token to the frontend. This will allow the application to start providing feedback and even begin Text-to-Speech (TTS) output more immediately, reducing perceived latency and making interactions feel more natural and human-like.

## 1. Set up Git: Clone and Configure for a New PC

These steps assume you have Git installed on your new PC. If not, download and install it from [https://git-scm.com/](https://git-scm.com/).

### 1.1. Clone the Repository
Open your preferred terminal (Git Bash, Command Prompt, PowerShell, or a Linux/macOS terminal).
```bash
# Navigate to the directory where you want to store the project
cd path/to/your/development/folder

# Clone the repository using HTTPS (recommended for simplicity)
git clone https://github.com/CholsaKosal/Speech_to_Action_Robotic_Drawing_Application_Locally.git

# Or clone using SSH (if you have SSH keys set up with GitHub)
# git clone git@github.com:CholsaKosal/Speech_to_Action_Robotic_Drawing_Application.git

# Navigate into the cloned project directory
cd Speech_to_Action_Robotic_Drawing_Application
```

### 1.2. Configure Your Git Identity

Git needs to know who you are to associate your commits correctly. If this is a new machine or Git hasn't been configured globally:

```bash
git config --global user.name "Your Name"
git config --global user.email "your_email@example.com"
```

Replace `"Your Name"` and `"your_email@example.com"` with your actual Git/GitHub username and email.

### 1.3. Check Remote Configuration

Verify that the remote `origin` is correctly pointing to the GitHub repository:

```bash
git remote -v
```

You should see output similar to:

```
origin  https://github.com/CholsaKosal/Speech_to_Action_Robotic_Drawing_Application_Locally.git (fetch)
origin  https://github.com/CholsaKosal/Speech_to_Action_Robotic_Drawing_Application_Locally.git (push)
```

### 1.4. Pushing Changes

After making commits, you can push your changes to the `master` branch (or any other branch you are working on):

```bash
git push origin master
```

## 2. Set up Developing Environment

This project has a Python backend and a JavaScript/TypeScript frontend (using Electron with Vite).

### 2.1. Check Desktop Specifications

Before proceeding, ensure your desktop has adequate resources. Run the following script in **Windows Command Prompt (`cmd`)** to gather system information. This script will also create a `dxdiag_output.txt` file in the current directory with more detailed graphics information.
```cmd
@echo off
echo --- Checking System Overview (OS, CPU, RAM) ---
systeminfo | findstr /B /C:"OS Name" /C:"OS Version" /C:"System Manufacturer" /C:"System Model" /C:"Processor(s)" /C:"Total Physical Memory" /C:"Available Physical Memory"
echo.
echo --- CPU Detailed Information ---
wmic cpu get name, numberofcores, numberoflogicalprocessors, maxclockspeed
echo.
echo --- GPU (Graphics Card) Information ---
wmic path win32_videocontroller get name, adapterram, driverversion, VideoModeDescription
echo.
echo --- NVIDIA GPU Detailed Information (if NVIDIA card and drivers are installed) ---
echo Attempting to run nvidia-smi... If this command fails, it likely means you don't have an NVIDIA GPU or the NVIDIA drivers are not installed correctly in the system PATH.
nvidia-smi
echo.

echo --- Disk Drive Space Information (Size and FreeSpace are in Bytes) ---
wmic logicaldisk get caption, description, drivetype, freespace, size, volumename
echo.
echo --- Generating DirectX Diagnostic Report (this may take a moment) ---
dxdiag /t dxdiag_output.txt
echo.
echo A detailed DirectX diagnostic report has been saved to the file "dxdiag_output.txt"
echo in your current directory.
echo Please open "dxdiag_output.txt" with a text editor to view detailed graphics card VRAM.
echo Look under "Display Devices" in that file for VRAM information (e.g., "Display Memory" or "Dedicated Memory").
@echo on
```

**Minimum Recommended Specs (for smoother development & running AI models):**

  * **CPU:** Modern multi-core (e.g., Intel Core i5/i7 8th gen+, AMD Ryzen 5/7 3000 series+)
  * **RAM:** 16GB (32GB+ recommended for larger LLMs)
  * **GPU:** NVIDIA GeForce RTX series with at least 6-8GB VRAM (more is better for LLM offloading). AMD GPUs can work but may require more setup for AI acceleration.
  * **Disk:** SSD with at least 50-100GB free space.

### 2.2. Python Backend Setup

1.  **Install Python:** If not already installed, download and install Python (version 3.9+ recommended) from [https://www.python.org/](https://www.python.org/). Ensure Python and Pip are added to your system's PATH during installation.

2.  **Install FFmpeg (Required for Whisper):**
    * Download FFmpeg from [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html) (e.g., "release essentials" from gyan.dev for Windows).
    * Extract it to a folder (e.g., `C:\ffmpeg`).
    * Add the `bin` subdirectory (e.g., `C:\ffmpeg\bin`) to your system's PATH environment variable.
    * Verify by opening a *new* terminal and typing `ffmpeg -version`.

3.  **Install Microsoft C++ Build Tools (Required for `llama-cpp-python` on Windows):**
    * Go to the Visual Studio downloads page: [https://visualstudio.microsoft.com/downloads/](https://visualstudio.microsoft.com/downloads/)
    * Download "Build Tools for Visual Studio".
    * Run the installer and select the "**Desktop development with C++**" workload. This installs the necessary C++ compilers (MSVC), CMake, and `nmake`.
    * Restart your terminal after installation.

4.  **Navigate to the backend directory:**
    ```bash
    cd backend
    ```
5.  **Create and activate a virtual environment:**
    ```bash
    python -m venv venv
    # On Windows cmd:
    venv\Scripts\activate
    # On PowerShell:
    # .\venv\Scripts\Activate.ps1
    # On Git Bash / Linux / macOS:
    # source venv/bin/activate
    ```
    Your terminal prompt should now be prefixed with `(venv)`.
6.  **Install Python dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Note: `requirements.txt` should be kept up-to-date with all necessary backend libraries like Flask, opencv-python, Pillow, qrcode, numpy, `openai-whisper`, `llama-cpp-python`, etc.)*
7.  **Download AI Models:**
    * **Whisper models** are typically downloaded automatically by the `openai-whisper` library on first use (e.g., the "base" model).
    * **LLM model (e.g., deepseek-llm-7b-chat GGUF GGUF):**
        * Download the desired GGUF model file (e.g., a Q4\_K\_M quantized version of deepseek-llm-7b-chat GGUF) from Hugging Face Hub.
        * Create a directory `backend/models/`.
        * Place the downloaded `.gguf` file into `backend/models/`.
        * Ensure the `LLM_MODEL_FILENAME` in `backend/config.py` matches the name of this file.
        * Note: The `backend/models/` directory should be in your `.gitignore`.

8.  The `backend` directory should contain subdirectories like `models` (for AI models), `qr_uploads` (for images uploaded via QR code), and `audio_tmp` (for temporary audio files). These are typically ignored by Git but needed for runtime.

### 2.3. JavaScript/TypeScript Frontend Setup (Electron with Vite)

The frontend is located in `frontend/s2a-drawing-ui/`.
1.  **Install Node.js and npm:** If not already installed, download and install Node.js (which includes npm) from [https://nodejs.org/](https://nodejs.org/) (LTS version recommended).
2.  **Navigate to the frontend project directory:**
    ```bash
    cd frontend/s2a-drawing-ui
    ```
3.  **Install Node.js dependencies:**
    ```bash
    npm install
    ```
    This will install packages listed in `package.json`, including Electron, Vite, React, TypeScript, etc.
      * If you encounter warnings about deprecated packages or vulnerabilities, you can try:
        ```bash
        npm audit fix
        ```
        Be cautious with `npm audit fix --force` as it might introduce breaking changes.

## 3. Run and Test Application (Steps and Scripts)

### 3.0. Network Configuration for QR Code Image Upload (Current Method)
Important: For the QR code image upload feature (from phone to PC) to work with the current setup, your PC and your phone must be on the same local network, and that network must allow direct device-to-device communication. Guest networks or networks with "Client Isolation" / "AP Isolation" enabled will likely not work.
Using a Mobile Hotspot (Recommended & Tested):
Enable the mobile hotspot feature on your phone.
Connect your development PC to this mobile hotspot Wi-Fi network.
When the Python backend server starts, it will attempt to generate a QR code URL using the PC's IP address on this hotspot network (e.g., 192.168.43.x).
Scanning the QR code with the phone (which is the hotspot provider) will then allow it to connect to the PC.
Using a Private Wi-Fi Network:
If using a home/private Wi-Fi router, ensure both devices are connected to it.
Crucially, ensure that "AP Isolation," "Client Isolation," or similar features (which prevent connected devices from communicating with each other) are disabled on your router.
This direct local network approach is for the current development phase. Future updates might explore other methods for image uploads.

### 3.1. Running the Python Backend

1.  Ensure your Python virtual environment is activated in the `backend` directory:
    ```bash
    # (If not already in backend/)
    cd path/to/project/backend
    # (If venv not active)
    # Windows cmd:
    venv\Scripts\activate
    # PowerShell:
    # .\venv\Scripts\Activate.ps1
    # Git Bash / Linux / macOS:
    # source venv/bin/activate
    ```
2.  Run the main backend orchestrator script:
    ```bash
    python main_orchestrator.py
    ```
    This should start any necessary servers (e.g., Flask-SocketIO for WebSockets, QR code uploads, and AI model loading). Monitor the terminal for logs and status messages.

### 3.2. Running the Electron Frontend (Development Mode)

1.  Open a **new terminal** window/tab.
2.  Navigate to the frontend project directory:
    ```bash
    cd path/to/project/frontend/s2a-drawing-ui
    ```
3.  Start the Vite development server and Electron application:
    ```bash
    npm run dev
    ```
    This command (defined in `package.json`) typically launches the Vite dev server for the renderer process (UI) and starts the Electron main process, opening the application window.

### 3.3. Generating `code_base.txt` (for sharing/review)

This script helps generate a snapshot of the current codebase, excluding large or unnecessary directories.
1.  **Environment:** Use **WSL (Windows Subsystem for Linux)** or **Git Bash** on Windows, or a standard terminal on Linux/macOS.
2.  **Ensure `tree` command is available:**
      * In WSL, if `tree` is not found but available via Snap:
        ```bash
        export PATH=$PATH:/snap/bin # For current session
        # For permanent fix, add to ~/.bashrc: export PATH="$PATH:/snap/bin"
        ```
3.  **Navigate to the project root directory (`Speech_to_Action_Robotic_Drawing_Application`).**
4.  **Make the script executable (if not already):**
    ```bash
    chmod +x generate_code_base.sh
    ```
5.  **Run the script:**
    ```bash
    # Clean up old files first (optional, script also does this)
    # rm -f code_base.txt temp_all_contents.txt filter_rules.sed
    ./generate_code_base.sh
    ```
    This will create `code_base.txt` in the project root. Review `exclude_patterns.conf` to ensure it correctly lists directories/files to exclude from this output.

### 3.4. Testing Robot Communication

1.  Ensure your GOFA CRB 15000 robot controller is powered on and connected to the same network as your development PC.
2.  Verify the robot controller's IP address and port match the settings in your backend's `config.py`.
3.  Use the application's UI or voice commands to initiate actions that involve robot communication.
4.  Monitor backend logs for connection status and command exchange.
5.  If using RobotStudio for simulation, ensure it's running and configured to listen for socket connections from your application.

## 4. Other Necessary Information for Development

  * **Branching Strategy:** (Define your team's branching strategy, e.g., feature branches, develop branch, master/main for releases). For solo development, working on `master` or a `develop` branch is common.
  * **Coding Standards & Linting:**
      * **Python:** Consider using tools like Black for code formatting and Flake8 or Pylint for linting.
      * **TypeScript/JavaScript:** The frontend project (created with `electron-vite`) likely includes ESLint and Prettier configurations. Adhere to these.
  * **API Documentation (Frontend-Backend):** As the WebSocket/HTTP API between the frontend and backend evolves, document the message formats, endpoints, and expected data structures.
  * **LLM and STT Model Management:**
      * Models are stored locally (e.g., in `backend/models/`, which is gitignored).
      * Document which specific models and quantization levels are being used (e.g., Whisper 'base', deepseek-llm-7b-chat GGUF Q4\_K\_M GGUF).
  * **Dependencies:** Keep `backend/requirements.txt` and `frontend/s2a-drawing-ui/package.json` up-to-date.
  * **Troubleshooting:**
      * Check backend logs for Python errors.
      * Use browser developer tools in Electron (usually `Ctrl+Shift+I` or via the View menu) to debug frontend JavaScript/TypeScript and inspect network requests.
      * Monitor system resource usage (CPU, RAM, VRAM) using Task Manager (Windows) or equivalent tools.
---

--- END OF FILE: README.md ---
